acl_id,title,abstract,year,A,B,C,D,E,F,G,raw_response,input_tokens,output_tokens,total_tokens
Q13-1035,Measuring Machine Translation Errors in New Domains,"We develop two techniques for analyzing the effect of porting a machine translation system to a new domain. One is a macro-level analysis that measures how domain shift affects corpus-level evaluation; the second is a microlevel analysis for word-level errors. We apply these methods to understand what happens when a Parliament-trained phrase-based machine translation system is applied in four very different domains: news, medical texts, scientific articles and movie subtitles. We present quantitative and qualitative experiments that highlight opportunities for future research in domain adaptation for machine translation.",2013,False,False,False,False,True,False,True,"E, G",221,3,224
W13-0808,Synchronous Linear Context-Free Rewriting Systems for Machine Translation,"We propose synchronous linear context-free rewriting systems as an extension to synchronous context-free grammars in which synchronized non-terminals span k ≥ 1 continuous blocks on each side of the bitext. Such discontinuous constituents are required for inducing certain alignment configurations that occur relatively frequently in manually annotated parallel corpora and that cannot be generated with less expressive grammar formalisms. As part of our investigations concerning the minimal k that is required for inducing manual alignments, we present a hierarchical aligner in form of a deduction system. We find that by restricting k to 2 on both sides, 100% of the data can be covered.",2013,False,True,False,False,True,False,False,"B, E",244,3,247
2013.iwslt-evaluation.21,The Heidelberg University machine translation systems for {IWSLT}2013,"We present our systems for the machine translation evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2013. We submitted systems for three language directions: German-to-English, Russianto-English and English-to-Russian. The focus of our approaches lies on effective usage of the in-domain parallel training data. Therefore, we use the training data to tune parameter weights for millions of sparse lexicalized features using efficient parallelized stochastic learning techniques. For German-to-English we incorporate syntax features. We combine all of our systems with large language models. For the systems involving Russian we also incorporate more data into building of the translation models.",2013,False,False,False,True,False,False,True,"D, G",246,3,249
W13-2239,Positive Diversity Tuning for Machine Translation System Combination,"We present Positive Diversity Tuning, a new method for tuning machine translation models specifically for improved performance during system combination. System combination gains are often limited by the fact that the translations produced by the different component systems are too similar to each other. We propose a method for reducing excess cross-system similarity by optimizing a joint objective that simultaneously rewards models for producing translations that are similar to reference translations, while also punishing them for translations that are too similar to those produced by other systems. The formulation of the Positive Diversity objective is easy to implement and allows for its quick integration with most machine translation tuning pipelines. We find that individual systems tuned on the same data to Positive Diversity can be even more diverse than systems built using different data sets, while still obtaining good BLEU scores. When these individual systems are used together for system combination, our approach allows for significant gains of 0.8 BLEU even when the combination is performed using a small number of otherwise identical individual systems.",2013,False,True,False,True,False,False,False,"B, D",311,3,314
W13-3305,Detecting Narrativity to Improve {E}nglish to {F}rench Translation of Simple Past Verbs,"The correct translation of verb tenses ensures that the temporal ordering of events in the source text is maintained in the target text. This paper assesses the utility of automatically labeling English Simple Past verbs with a binary discursive feature, narrative vs. non-narrative, for statistical machine translation (SMT) into French. The narrativity feature, which helps deciding which of the French past tenses is a correct translation of the English Simple Past, can be assigned with about 70% accuracy (F1). The narrativity feature improves SMT by about 0.2 BLEU points when a factored SMT system is trained and tested on automatically labeled English-French data. More importantly, manual evaluation shows that verb tense translation and verb choice are improved by respectively 9.7% and 3.4% (absolute), leading to an overall improvement of verb translation of 17% (relative).",2013,False,False,False,True,False,False,True,"D, G",298,3,301
D13-1022,Optimal Beam Search for Machine Translation,"Beam search is a fast and empirically effective method for translation decoding, but it lacks formal guarantees about search error. We develop a new decoding algorithm that combines the speed of beam search with the optimal certificate property of Lagrangian relaxation, and apply it to phrase-and syntax-based translation decoding. The new method is efficient, utilizes standard MT algorithms, and returns an exact solution on the majority of translation examples in our test data. The algorithm is 3.5 times faster than an optimized incremental constraint-based decoder for phrase-based translation and 4 times faster for syntax-based translation.",2013,False,True,True,False,False,False,False,"B, C",233,3,236
N13-1035,Applying Pairwise Ranked Optimisation to Improve the Interpolation of Translation Models,"In Statistical Machine Translation we often have to combine different sources of parallel training data to build a good system. One way of doing this is to build separate translation models from each data set and linearly interpolate them, and to date the main method for optimising the interpolation weights is to minimise the model perplexity on a heldout set. In this work, rather than optimising for this indirect measure, we directly optimise for BLEU on the tuning set and show improvements in average performance over two data sets and 8 language pairs.",2013,False,False,False,True,False,False,True,"D, G",224,3,227
W13-2212,{E}dinburgh{'}s Machine Translation Systems for {E}uropean Language Pairs,"We validated various novel and recently proposed methods for statistical machine translation on 10 language pairs, using large data resources. We saw gains from optimizing parameters, training with sparse features, the operation sequence model, and domain adaptation techniques. We also report on utilizing a huge language model trained on 126 billion tokens. The annual machine translation evaluation campaign for European languages organized around the ACL Workshop on Statistical Machine Translation offers the opportunity to test recent advancements in machine translation in large data condition across several diverse language pairs. Building on our own developments and external contributions to the Moses open source toolkit, we carried out extensive experiments that, by early indications, led to a strong showing in the evaluation campaign. We would like to stress especially two contributions: the use of the new operation sequence model (Section 3) within Moses, and -in a separate unconstraint track submission -the use of a huge language model trained on 126 billion tokens with a new training tool (Section 4).",2013,False,True,False,True,False,False,False,"B, D",311,3,314
N13-1115,Multi-Metric Optimization Using Ensemble Tuning,"This paper examines tuning for statistical machine translation (SMT) with respect to multiple evaluation metrics. We propose several novel methods for tuning towards multiple objectives, including some based on ensemble decoding methods. Pareto-optimality is a natural way to think about multi-metric optimization (MMO) and our methods can effectively combine several Pareto-optimal solutions, obviating the need to choose one. Our best performing ensemble tuning method is a new algorithm for multi-metric optimization that searches for Pareto-optimal ensemble models. We study the effectiveness of our methods through experiments on multiple as well as single reference(s) datasets. Our experiments show simultaneous gains across several metrics (BLEU, RIBES), without any significant reduction in other metrics. This contrasts the traditional tuning where gains are usually limited to a single metric. Our human evaluation results confirm that in order to produce better MT output, optimizing multiple metrics is better than optimizing only one.",2013,False,False,True,True,False,False,False,"C, D",306,3,309
P13-1059,Name-aware Machine Translation,"We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline 1 .",2013,False,True,False,True,False,False,False,"B, D",234,3,237
P13-2061,Bilingual Data Cleaning for {SMT} using Graph-based Random Walk,"The quality of bilingual data is a key factor in Statistical Machine Translation (SMT). Low-quality bilingual data tends to produce incorrect translation knowledge and also degrades translation modeling performance. Previous work often used supervised learning methods to filter lowquality data, but a fair amount of human labeled examples are needed which are not easy to obtain. To reduce the reliance on labeled examples, we propose an unsupervised method to clean bilingual data. The method leverages the mutual reinforcement between the sentence pairs and the extracted phrase pairs, based on the observation that better sentence pairs often lead to better phrase extraction and vice versa. End-to-end experiments show that the proposed method substantially improves the performance in largescale Chinese-to-English translation tasks.",2013,False,False,False,True,False,False,True,"D, G",261,3,264
P13-2062,Automatically Predicting Sentence Translation Difficulty,"In this paper we introduce Translation Difficulty Index (TDI), a measure of difficulty in text translation. We first define and quantify translation difficulty in terms of TDI. We realize that any measure of TDI based on direct input by translators is fraught with subjectivity and adhocism. We, rather, rely on cognitive evidences from eye tracking. TDI is measured as the sum of fixation (gaze) and saccade (rapid eye movement) times of the eye. We then establish that TDI is correlated with three properties of the input sentence, viz. length (L), degree of polysemy (DP) and structural complexity (SC). We train a Support Vector Regression (SVR) system to predict TDIs for new sentences using these features as input. The prediction done by our framework is well correlated with the empirical gold standard data, which is a repository of < L, DP, SC > and T DI pairs for a set of sentences. The primary use of our work is a way of ""binning"" sentences (to be translated) in ""easy"", ""medium"" and ""hard"" categories as per their predicted TDI. This can decide pricing of any translation task, especially useful in a scenario where parallel corpora for Machine Translation are built through translation crowdsourcing/outsourcing. This can also provide a way of monitoring progress of second language learners.",2013,False,False,False,False,False,False,False,catching classes that do not inherit from BaseException is not allowed,0,0,0
W13-2264,An {MT} Error-Driven Discriminative Word Lexicon using Sentence Structure Features,"The Discriminative Word Lexicon (DWL) is a maximum-entropy model that predicts the target word probability given the source sentence words. We present two ways to extend a DWL to improve its ability to model the word translation probability in a phrase-based machine translation (PBMT) system. While DWLs are able to model the global source information, they ignore the structure of the source and target sentence. We propose to include this structure by modeling the source sentence as a bag-of-n-grams and features depending on the surrounding target words. Furthermore, as the standard DWL does not get any feedback from the MT system, we change the DWL training process to explicitly focus on addressing MT errors. By using these methods we are able to improve the translation performance by up to 0.8 BLEU points compared to a system that uses a standard DWL.",2013,False,True,False,True,False,False,False,"B, D",293,3,296
I13-1139,Using Transliteration of Proper Names from {A}rabic to {L}atin Script to Improve {E}nglish-{A}rabic Word Alignment,"Bilingual lexicons of proper names play a vital role in machine translation and cross-language information retrieval. Word alignment approaches are generally used to construct bilingual lexicons automatically from parallel corpora. Aligning proper names is a task particularly difficult when the source and target languages of the parallel corpus do not share a same written script. We present in this paper a system to transliterate automatically proper names from Arabic to Latin script, and a tool to align single and compound words from English-Arabic parallel texts. We particularly focus on the impact of using transliteration to improve the performance of the word alignment tool. We have evaluated the word alignment tool integrating transliteration of proper names from Arabic to Latin script using two methods: A manual evaluation of the alignment quality and an evaluation of the impact of this alignment on the translation quality by using the open source statistical machine translation system Moses. Experiments show that integrating transliteration of proper names into the alignment process improves the Fmeasure of word alignment from 72% to 81% and the translation BLEU score from 20.15% to 20.63%.",2013,False,False,False,True,False,False,True,"D, G",338,3,341
W13-2203,The Feasibility of {HMEANT} as a Human {MT} Evaluation Metric,"There has been a recent surge of interest in semantic machine translation, which standard automatic metrics struggle to evaluate. A family of measures called MEANT has been proposed which uses semantic role labels (SRL) to overcome this problem. The human variant, HMEANT, has largely been evaluated using correlation with human contrastive evaluations, the standard human evaluation metric for the WMT shared tasks. In this paper we claim that for a human metric to be useful, it needs to be evaluated on intrinsic properties. It needs to be reliable; it needs to work across different language pairs; and it needs to be lightweight. Most importantly, however, a human metric must be discerning. We conclude that HMEANT is a step in the right direction, but has some serious flaws. The reliance on verbs as heads of frames, and the assumption that annotators need minimal guidelines are particularly problematic.",2013,False,False,False,False,True,True,False,"E, F",294,3,297
2013.mtsummit-wptp.12,Online production of {HQ} parallel corpora and permanent task-based evaluation of multiple {MT} systems: both can be obtained through i{MAG}s with no added cost,"An interactive Multilingual Access Gateway (iMAG) dedicated to a website S (iMAG-S) is a good tool to make S accessible in many languages immediately and without editorial responsibility. Visitors of S as well as paid or unpaid posteditors and moderators contribute to the continuous and incremental improvement of the most important textual segments, and eventually of all. In this approach, pre-translations are produced by one or more free machine translation (MT) systems. Continuous use since 2008 on many websites and for several access languages shows that a quality comparable to that of a first draft by junior professional translators is obtained in about 40% of the (human) time, sometimes less. There are two interesting side effects obtainable without any added cost: iMAGs can be used to produce highquality parallel corpora, and to set up a permanent task-based evaluation of one or more MT systems.",2013,False,False,False,True,True,False,False,"D, E",297,3,300
P13-2057,Using Context Vectors in Improving a Machine Translation System with Bridge Language,"Mapping phrases between languages as translation of each other by using an intermediate language (pivot language) may generate translation pairs that are wrong. Since a word or a phrase has different meanings in different contexts, we should map source and target phrases in an intelligent way. We propose a pruning method based on the context vectors to remove those phrase pairs that connect to each other by a polysemous pivot phrase or by weak translations. We use context vectors to implicitly disambiguate the phrase senses and to recognize irrelevant phrase translation pairs. Using the proposed method a relative improvement of 2.8 percent in terms of BLEU score is achieved.",2013,False,True,False,True,False,False,False,"D, B",243,3,246
P13-1139,Models of Translation Competitions,"What do we want to learn from a translation competition and how do we learn it with confidence? We argue that a disproportionate focus on ranking competition participants has led to lots of different rankings, but little insight about which rankings we should trust. In response, we provide the first framework that allows an empirical comparison of different analyses of competition results. We then use this framework to compare several analytical models on data from the Workshop on Machine Translation (WMT).",2013,False,False,False,False,True,True,False,"E, F",208,3,211
2013.mtsummit-papers.16,The Effects of Factorizing Root and Pattern Mapping in Bidirectional {T}unisian - {S}tandard {A}rabic Machine Translation,"The development of natural language processing tools for dialects faces the severe problem of lack of resources. In cases of diglossia, as in Arabic, one variant, Modern Standard Arabic (MSA), has many resources that can be used to build natural language processing tools. Whereas other variants, Arabic dialects, are resource poor. Taking advantage of the closeness of MSA and its dialects, one way to solve the problem of limited resources, consists in performing a translation of the dialect into MSA in order to use the tools developed for MSA. We describe in this paper an architecture for such a translation and we evaluate it on Tunisian Arabic verbs. Our approach relies on modeling the translation process over the deep morphological representations of roots and patterns, commonly used to model Semitic morphology. We compare different techniques for how to perform the cross-lingual mapping. Our evaluation demonstrates that the use of a decent coverage root+pattern lexicon of Tunisian and MSA with a backoff that assumes independence of mapping roots and patterns is optimal in reducing overall ambiguity and increasing recall.",2013,False,False,False,True,True,False,False,"D, E",335,3,338
W13-3604,{NAIST} at 2013 {C}o{NLL} Grammatical Error Correction Shared Task,"This paper describes the Nara Institute of Science and Technology (NAIST) error correction system in the CoNLL 2013 Shared Task. We constructed three systems: a system based on the Treelet Language Model for verb form and subjectverb agreement errors; a classifier trained on both learner and native corpora for noun number errors; a statistical machine translation (SMT)-based model for preposition and determiner errors. As for subject-verb agreement errors, we show that the Treelet Language Model-based approach can correct errors in which the target verb is distant from its subject. Our system ranked fourth on the official run.",2013,False,False,False,True,False,False,True,"D, G",244,3,247
2013.mtsummit-posters.3,Language-independent Model for Machine Translation Evaluation with Reinforced Factors,"The conventional machine translation evaluation metrics tend to perform well on certain language pairs but weak on other language pairs. Furthermore, some evaluation metrics could only work on certain language pairs not language-independent. Finally, no considering of linguistic information usually leads the metrics result in low correlation with human judgments while too many linguistic features or external resources make the metrics complicated and difficult in replicability. To address these problems, a novel language-independent evaluation metric is proposed in this work with enhanced factors and optional linguistic information (part-of-speech, n-grammar) but not very much. To make the metric perform well on different language pairs, extensive factors are designed to reflect the translation quality and the assigned parameter weights are tunable according to the special characteristics of focused language pairs. Experiments show that this novel evaluation metric yields better performances compared with several classic evaluation metrics (including BLEU, TER and METEOR) and two state-of-the-art ones including ROSE and MPF.",2013,False,True,False,True,False,False,False,"B, D",309,3,312
2013.mtsummit-wptp.1,This translation is not too bad: an analysis of post-editor choices in a machine-translation post-editing task,"Variation between post-editors of machine translation is a well-known issue. This variation shows itself in post-editing speed, amount of editing and differing final translations. However, relatively few studies exploring the differences have been reported. This paper describes a postediting task involving controlled language tourist phrases translated from English into Finnish. Post-editors select the best out of three machine translated suggestions, which they can accept without editing or post-edit as necessary. Agreement between editors is analyzed and reported in terms of selecting the best suggestion, deciding its acceptability, and producing a final post-edited version. Editors are compared in terms of post-editing time, edit distance and final translations created. With a qualitative analysis, we examine differences between the selected and rejected suggestions as well as differences between the post-edited versions created by different editors. Examples of editor preferences are also discussed.",2013,False,False,False,False,True,True,False,"E,F",289,2,291
P13-1110,Online Relative Margin Maximization for Statistical Machine Translation,"Recent advances in large-margin learning have shown that better generalization can be achieved by incorporating higher order information into the optimization, such as the spread of the data. However, these solutions are impractical in complex structured prediction problems such as statistical machine translation. We present an online gradient-based algorithm for relative margin maximization, which bounds the spread of the projected data while maximizing the margin. We evaluate our optimizer on Chinese-English and Arabic-English translation tasks, each with small and large feature sets, and show that our learner is able to achieve significant improvements of 1.2-2 BLEU and 1.7-4.3 TER on average over state-of-the-art optimizers with the large feature set.",2013,False,False,True,True,False,False,False,"C, D",260,3,263
N13-1025,Large-Scale Discriminative Training for Statistical Machine Translation Using Held-Out Line Search,"We introduce a new large-scale discriminative learning algorithm for machine translation that is capable of learning parameters in models with extremely sparse features. To ensure their reliable estimation and to prevent overfitting, we use a two-phase learning algorithm. First, the contribution of individual sparse features is estimated using large amounts of parallel data. Second, a small development corpus is used to determine the relative contributions of the sparse features and standard dense features. Not only does this two-phase learning approach prevent overfitting, the second pass optimizes corpus-level BLEU of the Viterbi translation of the decoder. We demonstrate significant improvements using sparse rule indicator features in three different translation tasks. To our knowledge, this is the first large-scale discriminative training algorithm capable of showing improvements over the MERT baseline with only rule indicator features in addition to the standard MERT features.",2013,False,False,True,True,False,False,False,"C, D",287,3,290
P13-1031,Fast and Adaptive Online Training of Feature-Rich Translation Models,"We present a fast and scalable online method for tuning statistical machine translation models with large feature sets. The standard tuning algorithm-MERT-only scales to tens of features. Recent discriminative algorithms that accommodate sparse features have produced smaller than expected translation quality gains in large systems. Our method, which is based on stochastic gradient descent with an adaptive learning rate, scales to millions of features and tuning sets with tens of thousands of sentences, while still converging after only a few epochs. Large-scale experiments on Arabic-English and Chinese-English show that our method produces significant translation quality gains by exploiting sparse features. Equally important is our analysis, which suggests techniques for mitigating overfitting and domain mismatch, and applies to other recent discriminative methods for machine translation.",2013,False,True,False,False,False,True,False,"B, F",265,3,268
2013.iwslt-evaluation.1,Report on the 10th {IWSLT} evaluation campaign,"The paper overviews the tenth evaluation campaign organized by the IWSLT workshop. The 2013 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included two automatic speech recognition tracks, on English and German, three speech translation tracks, from English to French, English to German, and German to English, and three text translation track, also from English to French, English to German, and German to English. In addition to the official tracks, speech and text translation optional tracks were offered involving 12 other languages: Arabic, Spanish, Portuguese (B), Italian, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 18 teams participated in the evaluation for a total of 217 primary runs submitted. All runs were evaluated with objective metrics on a current test set and two progress test sets, in order to compare the progresses against systems of the previous years. In addition, submissions of one of the official machine translation tracks were also evaluated with human post-editing.",2013,True,False,False,False,True,False,False,"A, E",333,3,336
2013.mtsummit-posters.2,Promoting Flexible Translations in Statistical Machine Translation,"While SMT systems can learn to translate multiword expressions (MWEs) from parallel text, they typically have no notion of non-compositionality, and thus overgeneralise translations that are only used in certain contexts. This paper describes a novel approach to measure the flexibility of a phrase pair, i.e. its tendency to occur in many contexts, in contrast to phrase pairs that are only valid in one or a few fixed expressions. The measure learns from the parallel training text, is simple to implement and language independent. We argue that flexible phrase pairs should be preferred over inflexible ones, and present experiments with phrase-based and hierarchical translation models in which we observe performance gains of up to 0.9 BLEU points.",2013,False,False,False,True,False,True,False,"D, F",263,3,266
R13-1094,Edit Distance: A New Data Selection Criterion for Domain Adaptation in {SMT},"This paper aims at effective use of training data by extracting sentences from large generaldomain corpora to adapt statistical machine translation systems to domain-specific data. We regard this task as a problem of filtering training sentences with respect to the target domain 1 via different similarity metrics. Thus, we give new insights into when data selection model can best benefit the in-domain translation. Based on the investigation of the state-ofthe-art similarity metrics, we propose edit distance as a new data selection criterion for this topic. To evaluate this proposal, we compare it with other methods on a large dataset. Comparative experiments are conducted on Chinese-English travel dialog domain and the results indicate that the proposed approach achieves a significant improvement over the baseline system (+4.36 BLEU) as well as the best rival model (+1.23 BLEU) using a much smaller training subset. This study may have a significant impact on mining very large corpora in a computationally-limited environment.",2013,False,False,False,True,True,False,False,"D, E",310,3,313
W13-5203,Mining translations from the web of open linked data,"In this paper we consider the prospect of extracting translations for words from the web of linked data. By searching for entities that have labels in both English and German we extract 665,000 translations. We then also consider a linguistic linked data resource, lemonUby, from which we extract a further 115,000 translations. We combine these translations with the Moses statistical machine translation, and we show that the translations extracted from the linked data can be used to improve the translation of unknown words.",2013,True,False,False,False,False,False,True,"A, G",216,3,219
P13-1135,Dirt Cheap Web-Scale Parallel Text from the {C}ommon {C}rawl,"Parallel text is the fuel that drives modern machine translation systems. The Web is a comprehensive source of preexisting parallel text, but crawling the entire web is impossible for all but the largest companies. We bring web-scale parallel text to the masses by mining the Common Crawl, a public Web crawl hosted on Amazon's Elastic Cloud. Starting from nothing more than a set of common two-letter language codes, our open-source extension of the STRAND algorithm mined 32 terabytes of the crawl in just under a day, at a cost of about $500. Our large-scale experiment uncovers large amounts of parallel text in dozens of language pairs across a variety of domains and genres, some previously unavailable in curated datasets. Even with minimal cleaning and filtering, the resulting data boosts translation performance across the board for five different language pairs in the news domain, and on open domain test sets we see improvements of up to 5 BLEU. We make our code and data available for other researchers seeking to mine this rich new data resource. 1",2013,True,False,False,False,False,False,True,"A, G",323,3,326
I13-1049,Hypothesis Refinement Using Agreement Constraints in Machine Translation,"Phrase-based machine translation like other data driven approaches, are often plagued by irregularities in the translations of words in morphologically rich languages. The phrase-pairs and the language models are unable to capture the long range dependencies which decide the inflection. This paper makes the first attempt at learning constraints between the language-pair where, the target language lacks rich linguistic resources, by automatically learning classifiers that prevent implausible phrases from being part of decoding and at the same time adds consistent phrases. The paper also shows that this approach improves translation quality on the English-Hindi language pair.",2013,False,False,False,True,False,False,True,"D, G",233,3,236
W13-5630,Combining Statistical Machine Translation and Translation Memories with Domain Adaptation,"Since the emergence of translation memory software, translation companies and freelance translators have been accumulating translated text for various languages and domains. This data has the potential of being used for training domain-specific machine translation systems for corporate or even personal use. But while the resulting systems usually perform well in translating domain-specific language, their out-of-domain vocabulary coverage is often insufficient due to the limited size of the translation memories. In this paper, we demonstrate that small in-domain translation memories can be successfully complemented with freely available general-domain parallel corpora such that (a) the number of out-of-vocabulary words (OOV) is reduced while (b) the in-domain terminology is preserved. In our experiments, a German-French and a German-Italian statistical machine translation system geared to marketing texts of the automobile industry has been significantly improved using Europarl and OpenSubtitles data, both in terms of automatic evaluation metrics and human judgement.",2013,False,False,False,True,False,False,True,"D, G",301,3,304
D13-1008,Paraphrasing 4 Microblog Normalization,"Compared to the edited genres that have played a central role in NLP research, microblog texts use a more informal register with nonstandard lexical items, abbreviations, and free orthographic variation. When confronted with such input, conventional text analysis tools often perform poorly. Normalization -replacing orthographically or lexically idiosyncratic forms with more standard variants -can improve performance. We propose a method for learning normalization rules from machine translations of a parallel corpus of microblog messages. To validate the utility of our approach, we evaluate extrinsically, showing that normalizing English tweets and then translating improves translation quality (compared to translating unnormalized text) using three standard web translation services as well as a phrase-based translation system trained on parallel microblog data.",2013,False,False,False,True,False,False,True,"D, G",271,3,274
P13-2073,Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation,"An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs. One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations. In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT. The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table. We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.",2013,False,False,False,True,False,False,True,"D, G",252,3,255
P13-1124,Two-Neighbor Orientation Model with Cross-Boundary Global Contexts,"Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.",2013,False,True,False,True,False,False,False,"B, D",278,3,281
2013.mtsummit-papers.17,Meta-Evaluation of a Diagnostic Quality Metric for Machine Translation,"Diagnostic evaluation of machine translation (MT) is an approach to evaluation that provides finer-grained information compared to state-of-the-art automatic metrics. This paper evaluates DELiC4MT, a diagnostic metric that assesses the performance of MT systems on user-defined linguistic phenomena. We present the results obtained using this diagnostic metric when evaluating three MT systems that translate from English to French, with a comparison against both human judgements and a set of representative automatic evaluation metrics. In addition, as the diagnostic metric relies on word alignments, the paper compares the margin of error in diagnostic evaluation when using automatic word alignments as opposed to gold standard manual alignments. We observed that this diagnostic metric is capable of accurately reflecting translation quality, can be used reliably with automatic word alignments and, in general, correlates well with automatic metrics and, more importantly, with human judgements.",2013,False,False,False,False,True,True,False,"E, F",291,3,294
W13-2227,The {CNGL}-{DCU}-{P}rompsit Translation Systems for {WMT}13,"This paper presents the experiments conducted by the Machine Translation group at DCU and Prompsit Language Engineering for the WMT13 translation task. Three language pairs are considered: Spanish-English and French-English in both directions and German-English in that direction. For the Spanish-English pair, the use of linguistic information to select parallel data is investigated. For the French-English pair, the usefulness of the small indomain parallel corpus is evaluated, compared to an out-of-domain parallel data sub-sampling method. Finally, for the German-English system, we describe our work in addressing the long distance reordering problem and a system combination strategy.",2013,False,False,False,True,False,False,True,"D, G",242,3,245
2013.mtsummit-papers.24,{PEP}r: Post-Edit Propagation Using Phrase-based Statistical Machine Translation,"Translators who work by post-editing machine translation output often find themselves repeatedly correcting the same errors. We propose a method for Post-edit Propagation (PEPr), which learns posteditor corrections and applies them on-thefly to further MT output. Our proposal is based on a phrase-based SMT system, used in an automatic post-editing (APE) setting with online learning. Simulated experiments on a variety of data sets show that for documents with high levels of internal repetition, the proposed mechanism could substantially reduce the post-editing effort.",2013,False,False,False,True,False,False,True,"D, G",226,3,229
W13-2242,Referential Translation Machines for Quality Estimation,"We introduce referential translation machines (RTM) for quality estimation of translation outputs. RTMs are a computational model for identifying the translation acts between any two data sets with respect to a reference corpus selected in the same domain, which can be used for estimating the quality of translation outputs, judging the semantic similarity between text, and evaluating the quality of student answers. RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality. RTMs remove the need to access any SMT system specific information or prior knowledge of the training data or models used when generating the translations. We develop novel techniques for solving all subtasks in the WMT13 quality estimation (QE) task (QET 2013) based on individual RTM models. Our results achieve improvements over last year's QE task results (QET 2012), as well as our previous results, provide new features and techniques for QE, and rank 1st or 2nd in all of the subtasks.",2013,False,True,False,True,False,False,False,"B, D",328,3,331
P13-1002,Integrating Translation Memory into Phrase-Based Machine Translation during Decoding,"Since statistical machine translation (SMT) and translation memory (TM) complement each other in matched and unmatched regions, integrated models are proposed in this paper to incorporate TM information into phrase-based SMT. Unlike previous multi-stage pipeline approaches, which directly merge TM result into the final output, the proposed models refer to the corresponding TM information associated with each phrase at SMT decoding. On a Chinese-English TM database, our experiments show that the proposed integrated Model-III is significantly better than either the SMT or the TM systems when the fuzzy match score is above 0.4. Furthermore, integrated Model-III achieves overall 3.48 BLEU points improvement and 2.62 TER points reduction in comparison with the pure SMT system. Besides, the proposed models also outperform previous approaches significantly.",2013,False,True,False,True,False,False,False,"B, D",274,3,277
2013.iwslt-papers.3,Constructing a speech translation system using simultaneous interpretation data,"There has been a fair amount of work on automatic speech translation systems that translate in real-time, serving as a computerized version of a simultaneous interpreter. It has been noticed in the field of translation studies that simultaneous interpreters perform a number of tricks to make the content easier to understand in real-time, including dividing their translations into small chunks, or summarizing less important content. However, the majority of previous work has not specifically considered this fact, simply using translation data (made by translators) for learning of the machine translation system. In this paper, we examine the possibilities of additionally incorporating simultaneous interpretation data (made by simultaneous interpreters) in the learning process. First we collect simultaneous interpretation data from professional simultaneous interpreters of three levels, and perform an analysis of the data. Next, we incorporate the simultaneous interpretation data in the learning of the machine translation system. As a result, the translation style of the system becomes more similar to that of a highly experienced simultaneous interpreter. We also find that according to automatic evaluation metrics, our system achieves performance similar to that of a simultaneous interpreter that has 1 year of experience.",2013,True,False,False,True,False,False,False,"A, D",340,3,343
W13-2305,Continuous Measurement Scales in Human Evaluation of Machine Translation,"We explore the use of continuous rating scales for human evaluation in the context of machine translation evaluation, comparing two assessor-intrinsic qualitycontrol techniques that do not rely on agreement with expert judgments. Experiments employing Amazon's Mechanical Turk service show that quality-control techniques made possible by the use of the continuous scale show dramatic improvements to intra-annotator agreement of up to +0.101 in the kappa coefficient, with inter-annotator agreement increasing by up to +0.144 when additional standardization of scores is applied.",2013,False,False,False,True,True,False,False,"D, E",223,3,226
F13-5001,Mining a Bilingual Lexicon of {M}ulti{W}ord Expressions : A Statistical Machine Translation Evaluation Perspective (Acquisition de lexique bilingue d{'}expressions polylexicales: Une application {\`a} la traduction automatique statistique) [in {F}rench],"Cet article décrit une méthode permettant d'acquérir un lexique bilingue d'expressions polylexicales (EPLS) à partir d'un corpus parallèle français-anglais. Nous identifions dans un premier temps les EPLS dans chaque partie du corpus parallèle. Ensuite, nous proposons un algorithme d'alignement assurant la mise en correspondance bilingue d'EPLS. Pour mesurer l'apport du lexique construit, une évaluation basée sur la tâche de Traduction Automatique Statistique (TAS) est menée. Nous étudions les performances de trois stratégies dynamiques et d'une stratégie statique pour intégrer le lexique bilingue d'expressions polylexicales dans un système de TAS. Les expériences menées dans ce cadre montrent que ces unités améliorent significativement la qualité de traduction.",2013,True,False,False,True,False,False,False,"A, D",289,3,292
R13-1076,Towards a Hybrid Rule-based and Statistical {A}rabic-{F}rench Machine Translation System,"Arabic is a morphologically rich and complex language, which presents significant challenges for natural language processing and machine translation. In this paper, we describe an ongoing effort to build our first Arabic-French phrasebased machine translation system using the Moses decoder among other linguistic tools. The results show an improvement in the quality of translation and a gain in terms of Bleu score after introducing a pre-processing scheme for Arabic and applying some rules based on morphological variations of the source language. The proposed approach is completed without increasing the amount of training data or changing radically the algorithms that can affect the translation or training engines.",2013,False,False,False,True,False,False,True,"G, D",235,3,238
2013.iwslt-evaluation.3,{E}nglish {SLT} and {MT} system description for the {IWSLT} 2013 evaluation,"This paper gives a description of the University of Edinburgh's (UEDIN) systems for IWSLT 2013. We participated in all the MT tracks and the German-to-English and Englishto-French SLT tracks. Our SLT submissions experimented with including ASR uncertainty into the decoding process via confusion networks, and looked at different ways of punctuating ASR output. Our MT submissions are mainly based on a system used in the recent evaluation campaign at the Workshop on Statistical Machine Translation [1] . We additionally explored the use of generalized representations (Brown clusters, POS and morphological tags) translating out of English into European languages.",2013,False,False,False,True,False,False,True,"D, G",246,3,249
I13-1116,Influence of Part-of-Speech and Phrasal Category Universal Tag-set in Tree-to-Tree Translation Models,"Tree-to-tree Statistical Machine Translation models require the use of syntactic tree structures of both the source and target side in learning rules to guide the translation process. In order to accomplish the task, available treebanks for different languages are used as the main resources to collect necessary information to handle the translation task. However, since each treebank has its own defined tags, a barrier is inherently created in highlighting alignment relationships at different syntactic levels for different tag-sets. Moreover, these models are typically over constrained. This paper presents a unified tagset for all languages at Part-of-Speech and Phrasal Category level in tree-to-tree models. Different experiments are conducted to study for its feasibility, efficiency, and translation quality.",2013,True,False,False,False,True,False,False,"A, E",262,3,265
W13-2249,{DCU}-{S}ymantec at the {WMT} 2013 Quality Estimation Shared Task,"We describe the two systems submitted by the DCU-Symantec team to Task 1.1. of the WMT 2013 Shared Task on Quality Estimation for Machine Translation. Task 1.1 involve estimating postediting effort for English-Spanish translation pairs in the news domain. The two systems use a wide variety of features, of which the most effective are the word-alignment, n-gram frequency, language model, POS-tag-based and pseudoreferences ones. Both systems perform at a similarly high level in the two tasks of scoring and ranking translations, although there is some evidence that the systems are over-fitting to the training data.",2013,False,False,False,True,False,False,True,"D, G",249,3,252
I13-1163,Accurate Parallel Fragment Extraction from Quasi{--}Comparable Corpora using Alignment Model and Translation Lexicon,"Although parallel sentences rarely exist in quasi-comparable corpora, there could be parallel fragments that are also helpful for statistical machine translation (SMT). Previous studies cannot accurately extract parallel fragments from quasi-comparable corpora. To solve this problem, we propose an accurate parallel fragment extraction system that uses an alignment model to locate the parallel fragment candidates, and uses an accurate lexicon filter to identify the truly parallel ones. Experimental results indicate that our system can accurately extract parallel fragments, and our proposed method significantly outperforms a state-of-the-art approach. Furthermore, we investigate the factors that may affect the performance of our system in detail.",2013,False,True,False,False,False,True,False,"B, F",244,3,247
W13-2225,The {U}niversity of {C}ambridge {R}ussian-{E}nglish System at {WMT}13,"This paper describes the University of Cambridge submission to the Eighth Workshop on Statistical Machine Translation. We report results for the Russian-English translation task. We use multiple segmentations for the Russian input language. We employ the Hadoop framework to extract rules. The decoder is HiFST, a hierarchical phrase-based decoder implemented using weighted finitestate transducers. Lattices are rescored with a higher order language model and minimum Bayes-risk objective.",2013,False,False,False,True,False,False,True,"D, G",205,3,208
W13-1014,Identifying Pronominal Verbs: Towards Automatic Disambiguation of the Clitic {`}se{'} in {P}ortuguese,"A challenging topic in Portuguese language processing is the multifunctional and ambiguous use of the clitic pronoun se, which impacts NLP tasks such as syntactic parsing, semantic role labeling and machine translation. Aiming to give a step forward towards the automatic disambiguation of se, our study focuses on the identification of pronominal verbs, which correspond to one of the six uses of se as a clitic pronoun, when se is considered a CONSTITU-TIVE PARTICLE of the verb lemma to which it is bound, as a multiword unit. Our strategy to identify such verbs is to analyze the results of a corpus search and to rule out all the other possible uses of se. This process evidenced the features needed in a computational lexicon to automatically perform the disambiguation task. The availability of the resulting lexicon of pronominal verbs on the web enables their inclusion in broader lexical resources, such as the Portuguese versions of Wordnet, Propbank and VerbNet. Moreover, it will allow the revision of parsers and dictionaries already in use. *Has-SE already spoken a lot about this matter. One has already spoken a lot about this matter. marker of pronominal PASSIVE voice (synthetic passive voice): Sugeriram-se muitas alternativas. *Have-SE suggested many alternatives. Many alternatives have been suggested. REFLEXIVE pronoun (-self pronouns): Você deveria se olhar no espelho. *You should look-SE on the mirror. You should look at yourself on the mirror. RECIPROCAL pronoun (each other): Eles se cumprimentaram com um aperto de mão. *They greeted-SE with a handshake. They greeted each other with a handshake. marker of causative-INCHOATIVE alternation 2 : Esse esporte popularizou-se no Brasil. *This sport popularED-SE in Brazil. This sport became popular in Brazil. CONSTITUTIVE PARTICLE of the verb lexical item (pronominal verb): Eles se queixaram de dor no joelho. *They complained-SE about knee pain. They complained about knee pain.",2013,False,False,False,False,True,False,True,"E, G",538,3,541
W13-4703,A Three-Layer Architecture for Automatic Post Editing System Using Rule-Based Paradigm,This paper proposes a post-editing model in which our three-level rule-based automatic post-editing engine called Grafix is presented to refine the output of machine translation systems. The type of corrections on sentences varies from lexical transformation to complex syntactical rearrangement. The experimental results both in manual and automatic evaluations show that the proposed system is able to improve the quality of our state-of-the-art English-Persian SMT system.,2013,False,False,False,True,False,False,True,"D, G",202,3,205
R13-1068,High-Accuracy Phrase Translation Acquisition Through Battle-Royale Selection,"In this paper, we report on an unsupervised greedy-style process for acquiring phrase translations from sentence-aligned parallel corpora. Thanks to innovative selection strategies, this process can acquire multiple translations without size criteria, i.e. phrases can have several translations, can be of any size, and their size is not considered when selecting their translations. Even though the process is in an early development stage and has much room for improvements, evaluation shows that it yields phrase translations of high precision that are relevant to machine translation but also to a wider set of applications including memory-based translation or multi-word acquisition.",2013,False,False,True,True,False,False,False,"C, D",236,3,239
D13-1025,Interactive Machine Translation using Hierarchical Translation Models,"Current automatic machine translation systems are not able to generate error-free translations and human intervention is often required to correct their output. Alternatively, an interactive framework that integrates the human knowledge into the translation process has been presented in previous works. Here, we describe a new interactive machine translation approach that is able to work with phrase-based and hierarchical translation models, and integrates error-correction all in a unified statistical framework. In our experiments, our approach outperforms previous interactive translation systems, and achieves estimated effort reductions of as much as 48% relative over a traditional post-edition system.",2013,False,True,False,True,False,False,False,"B, D",233,3,236
W13-2808,{E}nglish to {H}ungarian Morpheme-based Statistical Machine Translation System with Reordering Rules,"Phrase-based statistical machine translation systems can generate translations of reasonable quality in the case of language pairs with similar structure and word order. However, if the languages are more distant from a grammatical point of view, the quality of translations is much behind the expectations, since the baseline translation system cannot cope with long distance reordering of words and the mapping of word internal grammatical structures. In our paper, we present a method that tries to overcome these problems in the case of English-Hungarian translation by applying reordering rules prior to the translation process and by creating morpheme-based and factored models. Although automatic evaluation scores do not reliably reflect the improvement in all cases, human evaluation of our systems shows that readability and accuracy of the translations were improved both by reordering and applying richer models.",2013,False,False,False,True,False,False,True,"D, G",274,3,277
W13-2510,{VARTRA}: A Comparable Corpus for Analysis of Translation Variation,"This paper presents a comparable translation corpus created to investigate translation variation phenomena in terms of contrasts between languages, text types and translation methods (machine vs. computer-aided vs. human). These phenomena are reflected in linguistic features of translated texts belonging to different registers and produced with different translation methods. For their analysis, we combine methods derived from translation studies, language variation and machine translation, concentrating especially on textual and lexico-grammatical variation. To our knowledge, none of the existing corpora can provide comparable resources for a comprehensive analysis of variation across text types and translation methods. Therefore, the corpus resources created, as well as our analysis results will find application in different research areas, such as translation studies, machine translation, and others.",2013,True,False,False,False,True,False,False,"A, E",265,3,268
I13-1122,Automated Grammar Correction Using Hierarchical Phrase-Based Statistical Machine Translation,"We introduce a novel technique that uses hierarchical phrase-based statistical machine translation (SMT) for grammar correction. SMT systems provide a uniform platform for any sequence transformation task. Thus grammar correction can be considered a translation problem from incorrect text to correct text. Over the years, grammar correction data in the electronic form (i.e., parallel corpora of incorrect and correct sentences) has increased manifolds in quality and quantity, making SMT systems feasible for grammar correction. Firstly, sophisticated translation models like hierarchical phrase-based SMT can handle errors as complicated as reordering or insertion, which were difficult to deal with previously throuh the mediation of rule based systems. Secondly, this SMT based correction technique is similar in spirit to human correction, because the system extracts grammar rules from the corpus and later uses these rules to translate incorrect sentences to correct sentences. We describe how to use Joshua, a hierarchical phrase-based SMT system for grammar correction. An accuracy of 0.77 (BLEU score) establishes the efficacy of our approach.",2013,False,False,False,True,False,False,True,"D, G",319,3,322
2013.mtsummit-posters.13,Topic Models for Translation Quality Estimation for Gisting Purposes,"This paper addresses the problem of predicting how adequate a machine translation is for gisting purposes. It focuses on the contribution of lexicalised features based on different types of topic models, as we believe these features are more robust than those used in previous work, which depend on linguistic processors that are often unreliable on automatic translations. Experiments with a number of datasets show promising results: the use of topic models outperforms the state-of-the-art approaches by a large margin in all datasets annotated for adequacy.",2013,False,False,False,True,False,True,False,"D, F",218,3,221
P13-4033,{D}ocent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation,"We describe Docent, an open-source decoder for statistical machine translation that breaks with the usual sentence-bysentence paradigm and translates complete documents as units. By taking translation to the document level, our decoder can handle feature models with arbitrary discourse-wide dependencies and constitutes an essential infrastructure component in the quest for discourse-aware SMT models.",2013,False,True,False,False,False,False,True,"B, G",182,3,185
D13-1050,Improving Pivot-Based Statistical Machine Translation Using Random Walk,"This paper proposes a novel approach that utilizes a machine learning method to improve pivot-based statistical machine translation (SMT). For language pairs with few bilingual data, a possible solution in pivot-based SMT using another language as a ""bridge"" to generate source-target translation. However, one of the weaknesses is that some useful sourcetarget translations cannot be generated if the corresponding source phrase and target phrase connect to different pivot phrases. To alleviate the problem, we utilize Markov random walks to connect possible translation phrases between source and target language. Experimental results on European Parliament data, spoken language data and web data show that our method leads to significant improvements on all the tasks over the baseline system.",2013,False,False,True,True,False,False,False,"C, D",253,3,256
W13-2228,{QCRI}-{MES} Submission at {WMT}13: Using Transliteration Mining to Improve Statistical Machine Translation,"This paper describes QCRI-MES's submission on the English-Russian dataset to the Eighth Workshop on Statistical Machine Translation. We generate improved word alignment of the training data by incorporating an unsupervised transliteration mining module to GIZA++ and build a phrase-based machine translation system. For tuning, we use a variation of PRO which provides better weights by optimizing BLEU+1 at corpus-level. We transliterate out-of-vocabulary words in a postprocessing step by using a transliteration system built on the transliteration pairs extracted using an unsupervised transliteration mining system. For the Russian to English translation direction, we apply linguistically motivated pre-processing on the Russian side of the data.",2013,False,False,False,True,False,False,True,"D, G",257,3,260
2013.mtsummit-posters.9,Statistical Machine Translation for Automobile Marketing Texts,"We describe a project on introducing an in-house statistical machine translation system for marketing texts from the automobile industry with the final aim of replacing manual translation with post-editing, based on the translation system. The focus of the paper is the suitability of such texts for SMT; we present experiments in domain adaptation and decompounding that improve the baseline translation systems, the results of which are evaluated using automatic metrics as well as manual evaluation.",2013,False,False,False,True,False,False,True,"D, G",203,3,206
I13-1166,Estimating the Quality of Translated User-Generated Content,Previous research on quality estimation for machine translation has demonstrated the possibility of predicting the translation quality of well-formed data. We present a first study on estimating the translation quality of user-generated content. Our dataset contains English technical forum comments which were translated into French by three automatic systems. These translations were rated in terms of both comprehensibility and fidelity by human annotators. Our experiments show that tried-and-tested quality estimation features work well on this type of data but that extending this set can be beneficial. We also show that the performance of particular types of features depends on the type of system used to produce the translation.,2013,True,False,False,False,True,False,False,"A, E",240,3,243
D13-1083,A Corpus Level {MIRA} Tuning Strategy for Machine Translation,"MIRA based tuning methods have been widely used in statistical machine translation (SMT) system with a large number of features. Since the corpus-level BLEU is not decomposable, these MIRA approaches usually define a variety of heuristic-driven sentencelevel BLEUs in their model losses. Instead, we present a new MIRA method, which employs an exact corpus-level BLEU to compute the model loss. Our method is simpler in implementation. Experiments on Chinese-to-English translation show its effectiveness over two state-of-the-art MIRA implementations.",2013,False,False,True,True,False,False,False,"C, D",225,3,228
W13-2807,Reordering rules for {E}nglish-{H}indi {SMT},"Reordering is pre-processing stage for Statistical Machine Translation (SMT) system where the words of the source sentence are reordered as per the syntax of the target language. We are proposing a rich set of rules for better reordering. The idea is to facilitate the training process by better alignments and parallel phrase extraction for a phrase based SMT system. Reordering also helps the decoding process and hence improving the machine translation quality. We have observed significant improvements in the translation quality by using our approach over the baseline SMT. We have used BLEU, NIST, multi-reference word error rate, multi-reference position independent error rate for judging the improvements. We have exploited open source SMT toolkit MOSES to develop the system.",2013,False,False,False,True,False,False,True,"D, G",260,3,263
N13-1069,Systematic Comparison of Professional and Crowdsourced Reference Translations for Machine Translation,"We present a systematic study of the effect of crowdsourced translations on Machine Translation performance. We compare Machine Translation systems trained on the same data but with translations obtained using Amazon's Mechanical Turk vs. professional translations, and show that the same performance is obtained from Mechanical Turk translations at 1/5th the cost. We also show that adding a Mechanical Turk reference translation of the development set improves parameter tuning and output evaluation.",2013,False,False,False,False,True,False,True,"E, G",201,3,204
W13-4301,{EVBC}orpus - A Multi-Layer {E}nglish-{V}ietnamese Bilingual Corpus for Studying Tasks in Comparative Linguistics,"Bilingual corpora play an important role as resources not only for machine translation research and development but also for studying tasks in comparative linguistics. Manual annotation of word alignments is of significance to provide a gold-standard for developing and evaluating machine translation models and comparative linguistics tasks. This paper presents research on building an English-Vietnamese parallel corpus, which is constructed for building a Vietnamese-English machine translation system. We describe the specification of collecting data for the corpus, linguistic tagging, bilingual annotation, and the tools specially developed for the manual annotation. An English-Vietnamese bilingual corpus of over 800,000 sentence pairs and 10,000,000 English words as well as Vietnamese words has been collected and aligned at the sentence level, and over 45,000 sentence pairs of this corpus have been aligned at the word level. Moreover, the 45,000 sentence pairs have been tagged using other linguistics tags, including word segmentation for Vietnamese text, chunker and named entity tags.",2013,True,False,False,False,False,False,True,"A, G",316,3,319
I13-1144,Orthographic and Morphological Processing for {P}ersian-to-{E}nglish Statistical Machine Translation,"In statistical machine translation, data sparsity is a challenging problem especially for languages with rich morphology and inconsistent orthography, such as Persian. We show that orthographic preprocessing and morphological segmentation of Persian verbs in particular improves the translation quality of Persian-English by 1.9 BLEU points on a blind test set.",2013,False,False,False,True,True,False,False,"D, E",180,3,183
W13-2235,Dramatically Reducing Training Data Size Through Vocabulary Saturation,"Our field has seen significant improvements in the quality of machine translation systems over the past several years. The single biggest factor in this improvement has been the accumulation of ever larger stores of data. However, we now find ourselves the victims of our own success, in that it has become increasingly difficult to train on such large sets of data, due to limitations in memory, processing power, and ultimately, speed (i.e., data to models takes an inordinate amount of time). Some teams have dealt with this by focusing on data cleaning to arrive at smaller data sets (Denkowski et al., 2012a; Rarrick et al., 2011) , ""domain adaptation"" to arrive at data more suited to the task at hand (Moore and Lewis, 2010; Axelrod et al., 2011) , or by specifically focusing on data reduction by keeping only as much data as is needed for building models e.g., (Eck et al., 2005) . This paper focuses on techniques related to the latter efforts. We have developed a very simple n-gram counting method that reduces the size of data sets dramatically, as much as 90%, and is applicable independent of specific dev and test data. At the same time it reduces model sizes, improves training times, and, because it attempts to preserve contexts for all n-grams in a corpus, the cost in quality is minimal (as measured by BLEU ). Further, unlike other methods created specifically for data reduction that have similar effects on the data, our method scales to very large data, up to tens to hundreds of millions of parallel sentences.",2013,False,False,True,True,False,False,False,"D, C",448,3,451
Q13-1014,Learning to translate with products of novices: a suite of open-ended challenge problems for teaching {MT},"Machine translation (MT) draws from several different disciplines, making it a complex subject to teach. There are excellent pedagogical texts, but problems in MT and current algorithms for solving them are best learned by doing. As a centerpiece of our MT course, we devised a series of open-ended challenges for students in which the goal was to improve performance on carefully constrained instances of four key MT tasks: alignment, decoding, evaluation, and reranking. Students brought a diverse set of techniques to the problems, including some novel solutions which performed remarkably well. A surprising and exciting outcome was that student solutions or their combinations fared competitively on some tasks, demonstrating that even newcomers to the field can help improve the state-ofthe-art on hard NLP problems while simultaneously learning a great deal. The problems, baseline code, and results are freely available. * The first five authors were instructors and the remaining authors were students in the worked described here. This research was conducted while Chris Callison-Burch was at Johns Hopkins University.",2013,True,False,False,False,False,False,True,"A, G",320,3,323
2013.mtsummit-user.6,{ROI} Analysis Model for Language Service Providers,"Return on Investment (ROI) analysis plays a primary role in business strategic planning; however it is not such a straightforward process in itself. From the perspective of a Language Service Provider's (LSP) case study, an economic impact analysis of machine translation (MT) technology usage is required. Potential initial development and customization costs are investigated, as well as estimations of financial consequences resulting from the use of MT in professional translation. Different courses of action are weighed up, and supporting arguments are presented for the strategy of choice.",2013,False,False,False,False,True,False,True,"E, G",222,3,225
W13-2214,Towards Efficient Large-Scale Feature-Rich Statistical Machine Translation,"We present the system we developed to provide efficient large-scale feature-rich discriminative training for machine translation. We describe how we integrate with MapReduce using Hadoop streaming to allow arbitrarily scaling the tuning set and utilizing a sparse feature set. We report our findings on German-English and Russian-English translation, and discuss benefits, as well as obstacles, to tuning on larger development sets drawn from the parallel training data.",2013,False,True,False,True,False,False,False,"B, D",198,3,201
D13-1111,A Systematic Exploration of Diversity in Machine Translation,"This paper addresses the problem of producing a diverse set of plausible translations. We present a simple procedure that can be used with any statistical machine translation (MT) system. We explore three ways of using diverse translations: (1) system combination, (2) discriminative reranking with rich features, and (3) a novel post-editing scenario in which multiple translations are presented to users. We find that diversity can improve performance on these tasks, especially for sentences that are difficult for MT.",2013,False,False,False,True,False,False,True,"D, G",216,3,219
S13-1020,{UPC}-{CORE}: What Can Machine Translation Evaluation Metrics and {W}ikipedia Do for Estimating Semantic Textual Similarity?,"In this paper we discuss our participation to the 2013 Semeval Semantic Textual Similarity task. Our core features include (i) a set of metrics borrowed from automatic machine translation, originally intended to evaluate automatic against reference translations and (ii) an instance of explicit semantic analysis, built upon opening paragraphs of Wikipedia 2010 articles. Our similarity estimator relies on a support vector regressor with RBF kernel. Our best approach required 13 machine translation metrics + explicit semantic analysis and ranked 65 in the competition. Our postcompetition analysis shows that the features have a good expression level, but overfitting and -mainly-normalization issues caused our correlation values to decrease.",2013,False,False,False,True,False,False,True,"D, G",255,3,258
2013.mtsummit-papers.15,"Design and Analysis of a Large Corpus of Post-Edited Translations: Quality Estimation, Failure Analysis and the Variability of Post-Edition","Machine Translation (MT) is now often used to produce approximate translations that are then corrected by trained professional post-editors. As a result, more and more datasets of post-edited translations are being collected. These datasets are very useful for training, adapting or testing existing MT systems. In this work, we present the design and content of one such corpus of post-edited translations, and consider less studied possible uses of these data, notably the development of an automatic Quality Estimation (QE) system and the detection of frequent errors in automatic translations. Both applications require a careful assessment of the variability in post-editions, that we study here.",2013,True,False,False,False,True,False,False,"A, E",246,3,249
O13-1005,機器翻譯為本的中文拼字改錯系統 ({C}hinese Spelling Checker Based on Statistical Machine Translation),"Chinese spell check is an important component for many NLP applications, including word processors, search engines, and automatic essay rating. However, compared to spell checkers for alphabetical languages (e.g., English or French), Chinese spell checkers are more difficult to develop, because there are no word boundaries in Chinese writing system, and errors may be caused by various Chinese input methods. Chinese spell check involves automatically detecting and correcting typos, roughly corresponding to misspelled words in English. Liu et al. (2011) show that people tend to unintentionally generate typos that sound similar (e.g., * 措折 [cuo zhe] and 挫折 [cuo zhe]), or look alike (e.g., *固難 [gu nan] and 困難 [kun nan]). The methods for spell check can be broadly classified into two types: rule-based methods (Ren et al., 2001; Jiang et al., 2012) and statistical methods (Hung & Wu, 2009; Chen, 2010) . Rule-based methods use knowledge resources such as a dictionary to identify a word as a typo. Statistical methods tend to use a large monolingual corpus to create a language model to validate the correction hypotheses. Consider the sentence ""心是很重要的。"" [xin shi hen zhong yao de] which is correct. However, ""心"" and ""是"" are likely to be regarded as an error by a rule-based model for the word ""心事"" with identical pronunciation. In statistical methods, ""心"" and ""是"" are a bigram which has high frequency in a monolingual corpus, so we may determine that ""心是"" is not a typo after all. In this paper, we propose a model that combines rule-based and statistical approaches. Probable errors, proposed by the rule-based detection module, are verified using statistical machine translation (SMT) model. Our model treats spell check and correction as a kind of translation, where typos are translated into correctly spelled words according to the translation probability and the language model probability. We describe three modules for solving the problem of Chinese spell check: word segmentation, error detection, and error correction. The first module segments the input sentence into word tokens in an attempt to reduce the search space and the probability of false alarm. The second module detects probable errors in the segmented tokens. Any sequences of two or more singleton words are considered likely to contain an error. However, over-segmentation might lead to falsely identified errors. For example, phrases like ""超世之 才"" [chao shi zhi cai] tend to be over-segmented to ""超世/之/才"" which might lead to false alarms. So we use additional lexicon items and reduce the chance of generating false alarms.",2013,False,True,False,True,False,False,False,"B, D",690,3,693
I13-1105,Mining {J}apanese Compound Words and Their Pronunciations from Web Pages and Tweets,"Mining compound words and their pronunciations is essential for Japanese input method editors (IMEs). We propose to use a chunk-based dependency parser to mine new words, collocations and predicate-argument phrases from largescale Japanese Web pages and tweets. The pronunciations of the compound words are automatically rewritten by a statistical machine translation (SMT) model. Experiments on applying the mined lexicon to a state-of-the-art Japanese IME system 1 show that the precision of Kana-Kanji conversion is significantly improved.",2013,True,False,False,False,False,False,True,"A, G",222,3,225
R13-1088,Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets,"This paper provides an analysis of character-level machine translation models used in pivot-based translation when applied to sparse and noisy datasets, such as crowdsourced movie subtitles. In our experiments, we find that such characterlevel models cut the number of untranslated words by over 40% and are especially competitive (improvements of 2-3 BLEU points) in the case of limited training data. We explore the impact of character alignment, phrase table filtering, bitext size and the choice of pivot language on translation quality. We further compare cascaded translation models to the use of synthetic training data via multiple pivots, and we find that the latter works significantly better. Finally, we demonstrate that neither word-nor character-BLEU correlate perfectly with human judgments, due to BLEU's sensitivity to length.",2013,False,False,False,False,True,True,False,"E, F",277,3,280
2013.mtsummit-user.8,Let{'}s{MT}! as a Learning Platform for {SMT},"This paper presents an overview of two pilot studies conducted at the University of Copenhagen during the spring of 2013. The studies are based on the use of the Let'sMT! platform, which is also presented in an overview. The purpose of the studies was to investigate whether experiments with the Let'sMT! platform would be adequate for the students as a learning activity during the machine translation components of their courses, and for the instructors to gain experience that would allow them to later integrate the platform properly into the courses. The studies show that the platform is very adequate both for undergraduate and graduate students.",2013,False,False,False,False,True,False,True,"G, E",235,3,238
D13-1037,Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction,"This paper addresses the task of predicting the correct French translations of third-person subject pronouns in English discourse, a problem that is relevant as a prerequisite for machine translation and that requires anaphora resolution. We present an approach based on neural networks that models anaphoric links as latent variables and show that its performance is competitive with that of a system with separate anaphora resolution while not requiring any coreference-annotated training data. This demonstrates that the information contained in parallel bitexts can successfully be used to acquire knowledge about pronominal anaphora in an unsupervised way.",2013,True,True,False,False,False,False,False,"A, B",237,3,240
W13-1740,Applying Machine Translation Metrics to Student-Written Translations,This paper discusses preliminary work investigating the application of Machine Translation (MT) metrics toward the evaluation of translations written by human novice (student) translators. We describe a study in which we apply the metric TERp (Translation Edit Rate Plus) to a corpus of student-written translations from Spanish to English and compare the judgments of TERp against assessments provided by a translation instructor.,2013,False,False,False,False,True,False,True,"E,G",191,2,193
2013.mtsummit-plenaries.1,The Operation Sequence Model: Integrating Translation and Reordering Operations in a Single Left-to-Right Model,"We present a novel machine translation model that combines the benefits of phrasebased and n-gram-based statistical machine translation (SMT) and remedies their drawbacks. The model is based on a joint source channel probability model that represents the translation process as a linear sequence of operations. The sequence includes not only translation operations but also reordering operations. As in ngram-based SMT, the model is: (i) based on minimal translation units, (ii) takes both source and target information into account, (iii) does not make a phrasal independence assumption and (iv) avoids the spurious phrasal segmentation problem. As in phrase-based SMT, the model (i) has the ability to memorize lexical reordering triggers, (ii) builds the search graph dynamically and (iii) decodes with large translation units during search. The model has two important properties. First, it strongly couples reordering and translation; this provides a better reordering mechanism for restricting the position to which a word or phrase can be moved and provides a single framework that handles both short and long distance reorderings effectively. Second, no hard reordering constraint needs to be imposed on the model; phrase-based models must impose such constraints because they model reordering poorly. Using BLEU as a metric of translation accuracy, we found that our system performs significantly better than state-of-the-art phrasebased systems (Moses and Phrasal) and n-gram-based systems (Ncode) on standard translation tasks.",2013,False,True,True,False,False,False,False,"B, C",416,3,419
W13-3607,Constrained Grammatical Error Correction using Statistical Machine Translation,"This paper describes our use of phrasebased statistical machine translation (PB-SMT) for the automatic correction of errors in learner text in our submission to the CoNLL 2013 Shared Task on Grammatical Error Correction. Since the limited training data provided for the task was insufficient for training an effective SMT system, we also explored alternative ways of generating pairs of incorrect and correct sentences automatically from other existing learner corpora. Our approach does not yield particularly high performance but reveals many problems that require careful attention when building SMT systems for error correction.",2013,True,False,False,False,False,False,True,"A, G",226,3,229
W13-3303,Implicitation of Discourse Connectives in (Machine) Translation,"Explicit discourse connectives in a source language text are not always translated to comparable words or phrases in the target language. The paper provides a corpus analysis and a method for semi-automatic detection of such cases. Results show that discourse connectives are not translated into comparable forms (or even any form at all), in up to 18% of human reference translations from English to French or German. In machine translation, this happens much less frequently (up to 8% only). Work in progress aims to capture this natural implicitation of discourse connectives in current statistical machine translation models.",2013,False,False,False,False,True,True,False,"E, F",234,3,237
P13-2001,Translating Dialectal {A}rabic to {E}nglish,"We present a dialectal Egyptian Arabic to English statistical machine translation system that leverages dialectal to Modern Standard Arabic (MSA) adaptation. In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes Egyptian to EG , which looks similar to MSA. The transformations include morphological, phonological and spelling changes. The transformation reduces the out-of-vocabulary (OOV) words from 5.2% to 2.6% and gives a gain of 1.87 BLEU points. Further, adapting large MSA/English parallel data increases the lexical coverage, reduces OOVs to 0.7% and leads to an absolute BLEU improvement of 2.73 points.",2013,False,False,False,True,False,False,True,"D, G",273,3,276
D13-1201,Regularized Minimum Error Rate Training,"Minimum Error Rate Training (MERT) remains one of the preferred methods for tuning linear parameters in machine translation systems, yet it faces significant issues. First, MERT is an unregularized learner and is therefore prone to overfitting. Second, it is commonly used on a noisy, non-convex loss function that becomes more difficult to optimize as the number of parameters increases. To address these issues, we study the addition of a regularization term to the MERT objective function. Since standard regularizers such as 2 are inapplicable to MERT due to the scale invariance of its objective function, we turn to two regularizers-0 and a modification of 2and present methods for efficiently integrating them during search. To improve search in large parameter spaces, we also present a new direction finding algorithm that uses the gradient of expected BLEU to orient MERT's exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets.",2013,False,False,True,True,False,False,False,"C, D",330,3,333
D13-1026,Max-Margin Synchronous Grammar Induction for Machine Translation,"Traditional synchronous grammar induction estimates parameters by maximizing likelihood, which only has a loose relation to translation quality. Alternatively, we propose a max-margin estimation approach to discriminatively inducing synchronous grammars for machine translation, which directly optimizes translation quality measured by BLEU. In the max-margin estimation of parameters, we only need to calculate Viterbi translations. This further facilitates the incorporation of various non-local features that are defined on the target side. We test the effectiveness of our max-margin estimation framework on a competitive hierarchical phrase-based system. Experiments show that our max-margin method significantly outperforms the traditional twostep pipeline for synchronous rule extraction by 1.3 BLEU points and is also better than previous max-likelihood estimation method.",2013,False,False,True,True,False,False,False,"C, D",265,3,268
S13-2021,{ECNUCS}: Recognizing Cross-lingual Textual Entailment Using Multiple Text Similarity and Text Difference Measures,"This paper presents our approach used for cross-lingual textual entailment task (task 8) organized within SemEval 2013. Crosslingual textual entailment (CLTE) tries to detect the entailment relationship between two text fragments in different languages. We solved this problem in three steps. Firstly, we use a off-the-shelf machine translation (MT) tool to convert the two input texts into the same language. Then after performing a text preprocessing, we extract multiple feature types with respect to surface text and grammar. We also propose novel feature types regarding to sentence difference and semantic similarity based on our observations in the preliminary experiments. Finally, we adopt a multiclass SVM algorithm for classification. The results on the cross-lingual data collections provided by SemEval 2013 show that (1) we can build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG.",2013,False,False,False,True,False,False,True,"D, G",327,3,330
P13-2121,Scalable Modified {K}neser-{N}ey Language Model Estimation,"We present an efficient algorithm to estimate large modified Kneser-Ney models including interpolation. Streaming and sorting enables the algorithm to scale to much larger models by using a fixed amount of RAM and variable amount of disk. Using one machine with 140 GB RAM for 2.8 days, we built an unpruned model on 126 billion tokens. Machine translation experiments with this model show improvement of 0.8 BLEU point over constrained systems for the 2013 Workshop on Machine Translation task in three language pairs. Our algorithm is also faster for small models: we estimated a model on 302 million tokens using 7.7% of the RAM and 14.0% of the wall time taken by SRILM. The code is open source as part of KenLM.",2013,False,False,True,False,False,False,True,"C, G",277,3,280
D13-1112,Max-Violation Perceptron and Forced Decoding for Scalable {MT} Training,"While large-scale discriminative training has triumphed in many NLP problems, its definite success on machine translation has been largely elusive. Most recent efforts along this line are not scalable (training on the small dev set with features from top ∼100 most frequent words) and overly complicated. We instead present a very simple yet theoretically motivated approach by extending the recent framework of ""violation-fixing perceptron"", using forced decoding to compute the target derivations. Extensive phrase-based translation experiments on both Chinese-to-English and Spanish-to-English tasks show substantial gains in BLEU by up to +2.3/+2.0 on dev/test over MERT, thanks to 20M+ sparse features. This is the first successful effort of large-scale online discriminative training for MT.",2013,False,True,True,False,False,False,False,"B, C",274,3,277
W13-2246,{MT} Quality Estimation: The {CMU} System for {WMT}{`}13,"In this paper we present our entry to the WMT'13 shared task: Quality Estimation (QE) for machine translation (MT). We participated in the 1.1, 1.2 and 1.3 sub-tasks with our QE system trained on features from diverse information sources like MT decoder features, n-best lists, mono-and bi-lingual corpora and giza training models. Our system shows competitive results in the workshop shared task.",2013,False,False,False,True,False,False,True,"D, G",212,3,215
2013.iwslt-evaluation.18,The speech recognition and machine translation system of {IOIT} for {IWSLT} 2013,"This paper describes the Automatic Speech Recognition (ASR) and Machine Translation (MT) systems developed by IOIT for the evaluation campaign of IWSLT2013. For the ASR task, using Kaldi toolkit, we developed the system based on weighted finite state transducer. The system is constructed by applying several techniques, notably, subspace Gaussian mixture models, speaker adaptation, discriminative training, system combination and SOUL, a neural network language model. The techniques used for automatic segmentation are also clarified. Besides, we compared different types of SOUL models in order to study the impact of words of previous sentences in predicting words in language modeling. For the MT task, the baseline system was built based on the open source toolkit N -code, then being augmented by using SOUL on top, i.e., in N -best rescoring phase.",2013,False,False,False,True,False,True,False,"D, F",289,3,292
P13-1078,Additive Neural Networks for Statistical Machine Translation,"Most statistical machine translation (SMT) systems are modeled using a loglinear framework. Although the log-linear model achieves success in SMT, it still suffers from some limitations: (1) the features are required to be linear with respect to the model itself; (2) features cannot be further interpreted to reach their potential. A neural network is a reasonable method to address these pitfalls. However, modeling SMT with a neural network is not trivial, especially when taking the decoding efficiency into consideration. In this paper, we propose a variant of a neural network, i.e. additive neural networks, for SMT to go beyond the log-linear translation model. In addition, word embedding is employed as the input to the neural network, which encodes each word as a feature vector. Our model outperforms the log-linear translation models with/without embedding features on Chinese-to-English and Japanese-to-English translation tasks.",2013,False,True,False,True,False,False,False,"B, D",297,3,300
P13-1141,{S}ense{S}potting: Never let your parallel data tie you to an old domain,"Words often gain new senses in new domains. Being able to automatically identify, from a corpus of monolingual text, which word tokens are being used in a previously unseen sense has applications to machine translation and other tasks sensitive to lexical semantics. We define a task, SENSESPOTTING, in which we build systems to spot tokens that have new senses in new domain text. Instead of difficult and expensive annotation, we build a goldstandard by leveraging cheaply available parallel corpora, targeting our approach to the problem of domain adaptation for machine translation. Our system is able to achieve F-measures of as much as 80%, when applied to word types it has never seen before. Our approach is based on a large set of novel features that capture varied aspects of how words change when used in new domains.",2013,True,False,False,True,False,False,False,"A, D",279,3,282
J13-1003,Parsing Morphologically Rich Languages: Introduction to the Special Issue,"Parsing is a key task in natural language processing. It involves predicting, for each natural language sentence, an abstract representation of the grammatical entities in the sentence and the relations between these entities. This representation provides an interface to compositional semantics and to the notions of ""who did what to whom."" The last two decades have seen great advances in parsing English, leading to major leaps also in the performance of applications that use parsers as part of their backbone, such as systems for information extraction, sentiment analysis, text summarization, and machine translation. Attempts to replicate the success of parsing English for other languages have often yielded unsatisfactory results. In particular, parsing languages with complex word structure and flexible word order has been shown to require non-trivial adaptation. This special issue reports on methods that successfully address the challenges involved in parsing a range of morphologically rich languages (MRLs). This introduction characterizes MRLs, describes the challenges in parsing MRLs, and outlines the contributions of the articles in the special issue. These contributions present up-to-date research efforts that address parsing in varied, cross-lingual settings. They show that parsing MRLs addresses challenges that transcend particular representational and algorithmic choices.",2013,False,False,False,False,True,True,False,"E, F",360,3,363
N13-2007,Reversing Morphological Tokenization in {E}nglish-to-{A}rabic {SMT},"Morphological tokenization has been used in machine translation for morphologically complex languages to reduce lexical sparsity. Unfortunately, when translating into a morphologically complex language, recombining segmented tokens to generate original word forms is not a trivial task, due to morphological, phonological and orthographic adjustments that occur during tokenization. We review a number of detokenization schemes for Arabic, such as rule-based and table-based approaches and show their limitations. We then propose a novel detokenization scheme that uses a character-level discriminative string transducer to predict the original form of a segmented word. In a comparison to a stateof-the-art approach, we demonstrate slightly better detokenization error rates, without the need for any hand-crafted rules. We also demonstrate the effectiveness of our approach in an English-to-Arabic translation task.",2013,False,True,False,False,False,False,True,"B, G",284,3,287
2013.mtsummit-user.4,Hybrid Domain Adaptation for a Rule Based {MT} System,"This study presents several experiments to show the power of domain-specific adaptation by means of hybrid terminology extraction mechanisms and the subsequent terminology integration into a rule based machine translation (RBMT) system, thus avoiding cumbersome human lexicon and grammar customization. Detailed evaluation reveals the great potential of this approach: Translation quality can be improved substantially in two domains.",2013,False,False,False,True,False,False,True,"D, G",185,3,188
W13-2206,Feature Decay Algorithms for Fast Deployment of Accurate Statistical Machine Translation Systems,We use feature decay algorithms (FDA) for fast deployment of accurate statistical machine translation systems taking only about half a day for each translation direction. We develop parallel FDA for solving computational scalability problems caused by the abundance of training data for SMT models and LM models and still achieve SMT performance that is on par with using all of the training data or better. Parallel FDA runs separate FDA models on randomized subsets of the training data and combines the instance selections later. Parallel FDA can also be used for selecting the LM corpus based on the training set selected by parallel FDA. The high quality of the selected training data allows us to obtain very accurate translation outputs close to the top performing SMT systems. The relevancy of the selected LM corpus can reach up to 86% reduction in the number of OOV tokens and up to 74% reduction in the perplexity. We perform SMT experiments in all language pairs in the WMT13 translation task and obtain SMT performance close to the top systems using significantly less resources for training and development.,2013,False,False,True,True,False,False,False,"C, D",320,3,323
2013.iwslt-evaluation.19,"{T{\""U}B{\.I}TAK} {T}urkish-{E}nglish submissions for {IWSLT} 2013","This paper describes the T ÜB İTAK Turkish-English submissions in both directions for the IWSLT'13 Evaluation Campaign TED Machine Translation (MT) track. We develop both phrase-based and hierarchical phrase-based statistical machine translation (SMT) systems based on Turkish wordand morpheme-level representations. We augment training data with content words extracted from itself and experiment with reverse word order for source languages. For the Turkish-to-English direction, we use Gigaword corpus as an additional language model with the training data. For the English-to-Turkish direction, we implemented a wide coverage Turkish word generator to generate words from the stem and morpheme sequences. Finally, we perform system combination of the different systems produced with different word alignments.",2013,False,False,False,True,False,False,True,"D, G",268,3,271
S13-1017,{ECNUCS}: Measuring Short Text Semantic Equivalence Using Multiple Similarity Measurements,"This paper reports our submissions to the Semantic Textual Similarity (STS) task in * SEM Shared Task 2013. We submitted three Support Vector Regression (SVR) systems in core task, using 6 types of similarity measures, i.e., string similarity, number similarity, knowledge-based similarity, corpus-based similarity, syntactic dependency similarity and machine translation similarity. Our third system with different training data and different feature sets for each test data set performs the best and ranks 35 out of 90 runs. We also submitted two systems in typed task using string based measure and Named Entity based measure. Our best system ranks 5 out of 15 runs.",2013,False,False,False,True,False,False,True,"G, D",251,3,254
W13-2233,Combining Bilingual and Comparable Corpora for Low Resource Machine Translation,"Statistical machine translation (SMT) performance suffers when models are trained on only small amounts of parallel data. The learned models typically have both low accuracy (incorrect translations and feature scores) and low coverage (high out-of-vocabulary rates). In this work, we use an additional data resource, comparable corpora, to improve both. Beginning with a small bitext and corresponding phrase-based SMT model, we improve coverage by using bilingual lexicon induction techniques to learn new translations from comparable corpora. Then, we supplement the model's feature space with translation scores estimated over comparable corpora in order to improve accuracy. We observe improvements between 0.5 and 1.7 BLEU translating Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu into English.",2013,False,False,False,True,False,False,True,"D, G",271,3,274
