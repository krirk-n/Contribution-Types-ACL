acl_id,title,abstract,A,B,C,D,E,F,G,raw_response
P95-1011,Encoding {L}exicalized {T}ree {A}djoining {G}rammars with a Nonmonotonic Inheritance Hierarchy,"This paper shows how DATR, a widely used formal language for lexical knowledge representation, can be used to define an I_TAG lexicon as an inheritance hierarchy with internal lexical rules. A bottom-up featural encoding is used for LTAG trees and this allows lexical rules to be implemented as covariation constraints within feature structures. Such an approach eliminates the considerable redundancy otherwise associated with an LTAG lexicon.",False,False,False,True,False,False,False,D
2019.jeptalnrecital-long.6,Curriculum d{'}apprentissage : reconnaissance d{'}entit{\'e}s nomm{\'e}es pour l{'}extraction de concepts s{\'e}mantiques (Curriculum learning : named entity recognition for semantic concept extraction),"Dans cet article, nous présentons une approche de bout en bout d'extraction de concepts sémantiques de la parole. En particulier, nous mettons en avant l'apport d'une chaîne d'apprentissage successif pilotée par une stratégie de curriculum d'apprentissage. Dans la chaîne d'apprentissage mise en place, nous exploitons des données françaises annotées en entités nommées que nous supposons être des concepts plus génériques que les concepts sémantiques liés à une application informatique spécifique. Dans cette étude, il s'agit d'extraire des concepts sémantiques dans le cadre de la tâche MEDIA. Pour renforcer le système proposé, nous exploitons aussi des stratégies d'augmentation de données, un modèle de langage 5-gramme, ainsi qu'un mode étoile aidant le système à se concentrer sur les concepts et leurs valeurs lors de l'apprentissage. Les résultats montrent un intérêt à l'utilisation des données d'entités nommées, permettant un gain relatif allant jusqu'à 6,5 %.",False,False,False,True,False,False,False,D
E17-3023,Marine Variable Linker: Exploring Relations between Changing Variables in Marine Science Literature,"We report on a demonstration system for text mining of literature in marine science and related disciplines. It automatically extracts variables (e.g. CO2) involved in events of change/increase/decrease (e.g increasing CO2), as well as cooccurrence and causal relations among these events (e.g. increasing CO2 causes a decrease in pH in seawater), resulting in a big knowledge graph. A web-based graphical user interface targeted at marine scientists facilitates searching, browsing and visualising events and their relations in an interactive way.",False,False,False,False,False,False,True,G
W09-3406,"Assas-band, an Affix-Exception-List Based {U}rdu Stemmer","Both Inflectional and derivational morphology lead to multiple surface forms of a word. Stemming reduces these forms back to its stem or root, and is a very useful tool for many applications. There has not been any work reported on Urdu stemming. The current work develops an Urdu stemmer or Assas-Band and improves the performance using more precise affix based exception lists, instead of the conventional lexical lookup employed for developing stemmers in other languages. Testing shows an accuracy of 91.2%. Further enhancements are also suggested.",False,False,False,True,False,False,True,"D, G"
2022.bionlp-1.5,Zero-Shot Aspect-Based Scientific Document Summarization using Self-Supervised Pre-training,"We study the zero-shot setting for the aspectbased scientific document summarization task. Summarizing scientific documents with respect to an aspect can remarkably improve document assistance systems and readers experience. However, existing large-scale datasets contain a limited variety of aspects, causing summarization models to over-fit to a small set of aspects and a specific domain. We establish baseline results in zero-shot performance (over unseen aspects and the presence of domain shift), paraphrasing, leave-one-out, and limited supervised samples experimental setups. We propose a self-supervised pre-training approach to enhance the zero-shot performance. We leverage the PubMed structured abstracts to create a biomedical aspect-based summarization dataset. Experimental results on the PubMed and FacetSum aspect-based datasets show promising performance when the model is pre-trained using unlabelled in-domain data. 1",True,False,False,True,False,False,False,"A, D"
2008.eamt-1.24,Comparing two different bidirectional versions of the limited-domain medical spoken language translator {M}ed{SLT},"This paper reports preliminary results of an evaluation during which two different bidirectional versions of the limited-domain medical spoken language translator MedSLT were compared in a hospital setting. The more restricted version (V.1) only allows Yes-No answers and short elliptical sentences, while the less restricted version (V.2) allows Yes-No answers, short elliptical sentences and full sentences. Although WER is marginally better for V.1, task performance is marginally worse. There appear to be two main reasons for this disparity; short sentences are often badly recognised and patients tend to find it difficult to limit themselves to ellipsis, even if they receive clear instructions about not using full sentences.",False,False,False,False,False,True,False,F
1998.eamt-1.3,A centralized approach to managing multiple lexical resources,"The rapid expansion of SAP in markets around the world has brought with it an urgent need within the company for high-quality translation that adheres to SAP-specific terminology standards. Both the trend toward outsourcing and the increased use of automatic translation tools depend critically on quick and reliable access to official company terminology. SAP is therefore implementing a strategy that will make a central terminology database easily accessible not just to all of the people who need it (internal employees, customers, consulting agencies), but to translation and terminology tools as well. This includes the MT systems, Metal and Logos, whose data will be interchangeable with SAP database data.",False,False,False,True,False,False,False,D
2021.bea-1.14,{E}stonian as a Second Language Teacher{'}s Tools,"The paper describes ""Teacher's Tools"" (et Õpetaja tööriistad) developed by the Institute of the Estonian Language for teachers and specialists of Estonian as a Second Language. The toolbox includes four modules: vocabulary, grammar, communicative language activities and text evaluation. The vocabulary module provides graded word lists for young (CEFR levels pre-A1-C1) and adult (CEFR levels A1-C1) learners. The grammar module provides descriptions of young learners' grammar competence. The communicative language activities module gives teachers an overview of the typical situations that learners should be able to cope with. The text evaluation module marks lemmas in texts according to their CEFR assignment in the vocabulary module. So far the grammar and the communicative language activities modules have been developed only for young learners (CEFR levels pre-A1-B2). The toolbox is aimed at providing support for the development of Estonian as an L2 courses, educational materials, exercises and tests within a CEFR-based framework. The project started in 2017 and is ongoing.",False,False,False,False,False,False,True,G
J01-1001,Using Suffix Arrays to Compute Term Frequency and Document Frequency for All Substrings in a Corpus,"Bigrams and trigrams are commonly used in statistical natural language processing; this paper will describe techniques for working with much longer n-grams. Suffix arrays (Manber and Myers 1990) were /irst introduced to compute the frequency and location of a substring (n-gram) in a sequence (corpus) of length N. To compute frequencies over all N(N + 1)/2 substrings in a corpus, the substrings are grouped into a manageable number of equivalence classes. In this way, a prohibitive computation over substrings is reduced to a manageable computation over classes. This paper presents both the algorithms and the code that were used to compute term frequency (tf) and document frequency (dr)for all n-grams in two large corpora, an English corpus of 50 million words of Wall Street Journal and a Japanese corpus of 216 million characters of Mainichi Shimbun. The second half of the paper uses these frequencies to find ""interesting"" substrings. Lexicographers have been interested in n-grams with high mutual information (MI) where the joint term frequency is higher than what would be expected by chance, assuming that the parts of the n-gram combine independently. Residual inverse document frequency (RIDF) compares document frequency to another model of chance where terms with a particular term frequency are distributed randomly throughout the collection. MI tends to pick out phrases with noncompositional semantics (which often violate the independence assumption) whereas RIDF tends to highlight technical terminology, names, and good keywords for information retrieval (which tend to exhibit nonrandom distributions over documents). The combination of both MI and RIDF is better than either by itself in a Japanese word extraction task.",False,False,True,False,False,False,False,C
2016.gwc-1.56,Detection of Compound Nouns and Light Verb Constructions using {I}ndo{W}ord{N}et,"Detection of MultiWord Expressions (MWEs) is one of the fundamental problems in Natural Language Processing. In this paper, we focus on two categories of MWEs -Compound Nouns and Light Verb Constructions. These two categories can be tackled using knowledge bases, rather than pure statistics. We investigate usability of IndoWordNet for the detection of MWEs. Our IndoWordNet based approach uses semantic and ontological features of words that can be extracted from IndoWordNet. This approach has been tested on Indian languages viz., Assamese, Bengali, Hindi, Konkani, Marathi, Odia and Punjabi. Results show that ontological features are found to be very useful for the detection of light verb constructions, while use of semantic properties for the detection of compound nouns is found to be satisfactory. This approach can be easily adapted by other Indian languages. Detected MWEs can be interpolated into WordNets as they help in representing semantic knowledge.",False,False,False,True,False,False,False,D
