acl_id,title,abstract,year,A,B,C,D,E,F,G,raw_response,input_tokens,output_tokens,total_tokens
U17-1001,Stock Market Prediction with Deep Learning: A Character-based Neural Language Model for Event-based Trading,"In the last few years, machine learning has become a very popular tool for analyzing financial text data, with many promising results in stock price forecasting from financial news, a development with implications for the Ecient Markets Hypothesis (EMH) that underpins much economic theory. In this work, we explore recurrent neural networks with character-level language model pre-training for both intraday and interday stock market forecasting. In terms of predicting directional changes in the Standard & Poor's 500 index, both for individual companies and the overall index, we show that this technique is competitive with other state-of-the-art approaches.",2017,False,False,False,True,False,False,True,"D, G",239,3,242
W17-5232,{E}mo{A}tt at {E}mo{I}nt-2017: Inner attention sentence embedding for Emotion Intensity,"In this paper we describe a deep learning system that has been designed and built for the WASSA 2017 Emotion Intensity Shared Task. We introduce a representation learning approach based on inner attention on top of an RNN. Results show that our model offers good capabilities and is able to successfully identify emotionbearing words to predict intensity without leveraging on lexicons, obtaining the 13 th place among 22 shared task competitors.",2017,False,True,False,False,False,False,True,"B, G",203,3,206
Y17-1001,Modeling Answering Strategies for the Polar Questions across Languages,"This paper provides a discourse-based account of polar questions and answering particles. Arguing against syntax-based ellipsis analyses, the paper suggests that polarity particles are anaphoric in nature and their interpretation is determined by the antecedent evoked by the context. It also suggests that the parametric differences between the polarity-based (e.g., English, Swedish, German) and the truthbased answering system (e.g., Korean, Chinese, Japanese) have to do with the tight interactions between the anaphoric nature of answering particles and discourse. (4) Q: Belgian ba si Paul? (Tagalog) Belgian is Paul 'Is Paul Belgian? A: Oo, Belgian siya. 'Yes, he's Belgian.' A : Hindi', hindi' siya Belgian. 'No, he isn't Belgian.' As seen earlier, parametric variations among languages come from responses to negative questions. Consider Swedish and Japanese examples (data from Holmberg 2016): (5) Q: Är du inte troött? (Swedish) are you not tired 'Are you not tired?' A: Nej (jag är inte trött) no I am not tired 'No (I'm not tired)' (6) Q: kimi tukarete nai (Japanese) you tired not 'Are you not tired?' A: hai/un 'yes' (=I am not tired.",2017,False,False,False,False,True,True,False,"E,F",390,2,392
K17-3023,Initial Explorations of {CCG} Supertagging for {U}niversal {D}ependency Parsing,In this paper we describe the system by METU team for universal dependency parsing of multilingual text. We use a neural network-based dependency parser that has a greedy transition approach to dependency parsing. CCG supertags contain rich structural information that proves useful in certain NLP tasks. We experiment with CCG supertags as additional features in our experiments. The neural network parser is trained together with dependencies and simplified CCG tags as well as other features provided.,2017,False,False,False,True,False,False,True,"D, G",206,3,209
I17-1023,Geographical Evaluation of Word Embeddings,Word embeddings are commonly compared either with human-annotated word similarities or through improvements in natural language processing tasks. We propose a novel principle which compares the information from word embeddings with reality. We implement this principle by comparing the information in the word embeddings with geographical positions of cities. Our evaluation linearly transforms the semantic space to optimally fit the real positions of cities and measures the deviation between the position given by word embeddings and the real position. A set of well-known word embeddings with state-of-the-art results were evaluated. We also introduce a visualization that helps with error analysis.,2017,False,False,False,False,True,True,False,"E, F",233,3,236
D17-2002,{A}rgotario: Computational Argumentation Meets Serious Games,"An important skill in critical thinking and argumentation is the ability to spot and recognize fallacies. Fallacious arguments, omnipresent in argumentative discourse, can be deceptive, manipulative, or simply leading to 'wrong moves' in a discussion. Despite their importance, argumentation scholars and NLP researchers with focus on argumentation quality have not yet investigated fallacies empirically. The nonexistence of resources dealing with fallacious argumentation calls for scalable approaches to data acquisition and annotation, for which the serious games methodology offers an appealing, yet unexplored, alternative. We present Argotario, a serious game that deals with fallacies in everyday argumentation. Argotario is a multilingual, open-source, platform-independent application with strong educational aspects, accessible at www.argotario.net.",2017,True,False,False,False,False,False,True,"A, G",275,3,278
D17-3002,Computational Sarcasm,"Sarcasm is a form of verbal irony that is intended to express contempt or ridicule. Motivated by challenges posed by sarcastic text to sentiment analysis, computational approaches to sarcasm have witnessed a growing interest at NLP forums in the past decade. Computational sarcasm refers to automatic approaches pertaining to sarcasm. The tutorial will provide a bird{'}s-eye view of the research in computational sarcasm for text, while focusing on significant milestones.The tutorial begins with linguistic theories of sarcasm, with a focus on incongruity: a useful notion that underlies sarcasm and other forms of figurative language. Since the most significant work in computational sarcasm is sarcasm detection: predicting whether a given piece of text is sarcastic or not, sarcasm detection forms the focus hereafter. We begin our discussion on sarcasm detection with datasets, touching on strategies, challenges and nature of datasets. Then, we describe algorithms for sarcasm detection: rule-based (where a specific evidence of sarcasm is utilised as a rule), statistical classifier-based (where features are designed for a statistical classifier), a topic model-based technique, and deep learning-based algorithms for sarcasm detection. In case of each of these algorithms, we refer to our work on sarcasm detection and share our learnings. Since information beyond the text to be classified, contextual information is useful for sarcasm detection, we then describe approaches that use such information through conversational context or author-specific context.We then follow it by novel areas in computational sarcasm such as sarcasm generation, sarcasm v/s irony classification, etc. We then summarise the tutorial and describe future directions based on errors reported in past work. The tutorial will end with a demonstration of our work on sarcasm detection.This tutorial will be of interest to researchers investigating computational sarcasm and related areas such as computational humour, figurative language understanding, emotion and sentiment sentiment analysis, etc. The tutorial is motivated by our continually evolving survey paper of sarcasm detection, that is available on arXiv at: Joshi, Aditya, Pushpak Bhattacharyya, and Mark James Carman. {``}Automatic Sarcasm Detection: A Survey.{''} arXiv preprint arXiv:1602.03426 (2016).",2017,False,False,False,False,True,True,False,"E, F",573,3,576
D17-1237,Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning,"Building a dialogue agent to fulfill complex tasks, such as travel planning, is challenging because the agent has to learn to collectively complete multiple subtasks. For example, the agent needs to reserve a hotel and book a flight so that there leaves enough time for commute between arrival and hotel check-in. This paper addresses this challenge by formulating the task in the mathematical framework of options over Markov Decision Processes (MDPs), and proposing a hierarchical deep reinforcement learning approach to learning a dialogue manager that operates at different temporal scales. The dialogue manager consists of: (1) a top-level dialogue policy that selects among subtasks or options, (2) a low-level dialogue policy that selects primitive actions to complete the subtask given by the top-level policy, and (3) a global state tracker that helps ensure all cross-subtask constraints be satisfied. Experiments on a travel planning task with simulated and real users show that our approach leads to significant improvements over three baselines, two based on handcrafted rules and the other based on flat deep reinforcement learning.",2017,False,True,True,False,False,False,False,"B, C",326,3,329
I17-4023,{JUNLP} at {IJCNLP}-2017 Task 3: A Rank Prediction Model for Review Opinion Diversification,"IJCNLP-17 Review Opinion Diversification (RevOpiD-2017) task has been designed for ranking the top-k reviews of a product from a set of reviews, which assists in identifying a summarized output to express the opinion of the entire review set. The task is divided into three independent subtasks as subtask-A, subtask-B, and subtask-C. Each of these three subtasks selects the top-k reviews based on helpfulness, representativeness, and exhaustiveness of the opinions expressed in the review set individually. In order to develop the modules and predict the rank of reviews for all three subtasks, we have employed two well-known supervised classifiers namely, Naïve Bayes and Logistic Regression on the top of several extracted features such as the number of nouns, number of verbs, and number of sentiment words etc from the provided datasets. Finally, the organizers have helped to validate the predicted outputs for all three subtasks by using their evaluation metrics. The metrics provide the scores of list size 5 as (0.80 (mth)) for subtask-A, (0.86 (cos), 0.87 (cos d), 0.71 (cpr), 4.98 (a-dcg), and 556.94 (wt)) for subtask B, and (10.94 (unwt) and 0.67 (recall)) for subtask C individually.",2017,True,False,False,False,False,False,True,"A, G",408,3,411
K17-1013,Automatic Selection of Context Configurations for Improved Class-Specific Word Representations,"This paper is concerned with identifying contexts useful for training word representation models for different word classes such as adjectives (A), verbs (V), and nouns (N). We introduce a simple yet effective framework for an automatic selection of class-specific context configurations. We construct a context configuration space based on universal dependency relations between words, and efficiently search this space with an adapted beam search algorithm. In word similarity tasks for each word class, we show that our framework is both effective and efficient. Particularly, it improves the Spearman's ρ correlation with human scores on SimLex-999 over the best previously proposed class-specific contexts by 6 (A), 6 (V) and 5 (N) ρ points. With our selected context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts, resulting in a reduced training time. Our results generalise: we show that the configurations our algorithm learns for one English training setup outperform previously proposed context types in another training setup for English. Moreover, basing the configuration space on universal dependencies, it is possible to transfer the learned configurations to German and Italian. We also demonstrate improved per-class results over other context types in these two languages.",2017,False,False,False,True,True,False,False,"D, E",377,3,380
2017.mtsummit-papers.21,A Multilingual Parallel Corpus for Improving Machine Translation on {S}outheast {A}sian Languages,"Current machine translation systems require large bilingual corpora for training data. With large bilingual corpora, phrase-based and neural-based methods can achieve state-of-the-art performance. Nevertheless, such large bilingual corpora are unavailable for most language pairs called low-resource languages, which causes a bottleneck for the development of machine translation on such languages. For Southeast Asian region, there is a large population with more than five hundred millions people and several languages that can be used popularly in the world, but there are few parallel data for such language pairs. In this work, we built a multilingual parallel corpus for several Southeast Asian languages. Wikipedia articles' titles and inter-language link records were used to extract parallel titles. Parallel articles were collected based on the parallel titles. For each article pair, parallel sentences were extracted based on a length-based and word correspondences sentence alignment method. A multilingual parallel corpus were built with more than 1.1 million parallel sentences of ten language pairs of Indonesian, Malay, Filipino, Vietnamese and the languages paired with English. Experiments were conducted on the Asian Language Treebank corpus and showed the promising performance. Additionally, the corpus was utilized for the IWSLT 2015 machine translation shared task on English-Vietnamese and achieved a significant improvement with +1.7 BLEU point on phrase-based systems and +4.5 BLEU point on a state-of-the-art neural-based system. The corpus can be used to improve machine translation and enhance the development of machine translation on the low-resource Southeast Asian languages.",2017,True,False,False,False,False,False,True,"A, G",422,3,425
W17-3902,{O} Poeta Artificial 2.0: Increasing Meaningfulness in a Poetry Generation {T}witter bot,"O Poeta Artificial is a bot that tweets poems, in Portuguese, inspired by the latest Twitter trends. Built on top of PoeTryMe, a poetry generation platform, so far it had only produced poems based on a set of keywords in tweets about a trend. This paper presents recently implemented features for increasing the connection between the produced text and the target trend through the reutilisation and production of new text fragments, for highlighting the trend, paraphrasing text by Twitter users, or based on extracted or inferred semantic relations.",2017,False,False,False,True,False,False,True,"D, G",222,3,225
W17-1003,Centroid-based Text Summarization through Compositionality of Word Embeddings,"The textual similarity is a crucial aspect for many extractive text summarization methods. A bag-of-words representation does not allow to grasp the semantic relationships between concepts when comparing strongly related sentences with no words in common. To overcome this issue, in this paper we propose a centroidbased method for text summarization that exploits the compositional capabilities of word embeddings. The evaluations on multi-document and multilingual datasets prove the effectiveness of the continuous vector representation of words compared to the bag-of-words model. Despite its simplicity, our method achieves good performance even in comparison to more complex deep learning models. Our method is unsupervised and it can be adopted in other summarization tasks.",2017,False,False,False,True,False,False,True,"D, G",252,3,255
U17-1006,Phonemic Transcription of Low-Resource Tonal Languages,"Transcription of speech is an important part of language documentation, and yet speech recognition technology has not been widely harnessed to aid linguists. We explore the use of a neural network architecture with the connectionist temporal classification loss function for phonemic and tonal transcription in a language documentation setting. In this framework, we explore jointly modelling phonemes and tones versus modelling them separately, and assess the importance of pitch information versus phonemic context for tonal prediction. Experiments on two tonal languages, Yongning Na and Eastern Chatino, show the changes in recognition performance as training data is scaled from 10 minutes to 150 minutes. We discuss the findings from incorporating this technology into the linguistic workflow for documenting Yongning Na, which show the method's promise in improving efficiency, minimizing typographical errors, and maintaining the transcription's faithfulness to the acoustic signal, while highlighting phonetic and phonemic facts for linguistic consideration.",2017,False,False,False,True,True,False,False,"D, E",299,3,302
W17-5803,Multivariate Linear Regression of Symptoms-related Tweets for Infectious Gastroenteritis Scale Estimation,"To date, various Twitter-based event detection systems have been proposed. Most of their targets, however, share common characteristics. They are seasonal or global events such as earthquakes and flu pandemics. In contrast, this study targets unseasonal and local disease events. Our system investigates the frequencies of disease-related words such as ""nausea,"" ""chill,"" and ""diarrhea"" and estimates the number of patients using regression of these word frequencies. Experiments conducted using Japanese 47 areas from January 2017 to April 2017 revealed that the detection of small and unseasonal event is extremely difficult (r = 0.13). However, we found that the event scale and the detection performance show high correlation in the specified cases (in the phase of patient increasing or decreasing). The results also suggest that when 150 and more patients appear in a high population area, we can expect that our social sensors detect this outbreak. Based on these results, we can infer that social sensors can reliably detect unseasonal and local disease events under certain conditions, just as they can for seasonal or global events.",2017,False,False,False,False,True,False,True,"E, G",342,3,345
W17-7546,Linguistic approach based Transfer Learning for Sentiment Classification in {H}indi,"Sentiment analysis in a resource scarce language is a tedious task. We propose a novel method for transfer learning from a target language to English. Our system doesn't rely on labeled data for the target language but instead links itself onto already existing and extensively labeled word-level lexical resource in English (ESWN 1 ) and a semantic parser. Our proposed system transparently needs no target language sentiment corpus, and exploits complex linguistic structure of the target language for sentiment prediction. This cross lingual approach gives net accuracy as 83.6%, an improvement of 5.4% over the baseline system.",2017,False,False,False,True,False,False,True,"D, G",236,3,239
W17-7514,Hybrid Approach for {M}arathi Named Entity Recognition,"This paper describes a named entity recognition system that combines hidden markov model, handcrafted rules, and gazetteers to recognize named entities in Marathi language. The objective of the system is to recognize twelve types of NEs from the Marathi text. Marathi is morphologically rich and inflectional language. The inflections in NEs are handled by using lemmatization. The difficulties of zero and poor probabilities caused due to the sparse data are handled using pseudo word replacement and smoothing techniques. Viterbi algorithm is used for decoding and word disambiguation. The performance of the system is improved using gazetteers and grammar rules.",2017,False,False,False,True,False,False,True,"D, G",243,3,246
D17-1073,Don{'}t Throw Those Morphological Analyzers Away Just Yet: Neural Morphological Disambiguation for {A}rabic,"This paper presents a model for Arabic morphological disambiguation based on Recurrent Neural Networks (RNN). We train Long Short-Term Memory (LSTM) cells in several configurations and embedding levels to model the various morphological features. Our experiments show that these models outperform state-of-theart systems without explicit use of feature engineering. However, adding learning features from a morphological analyzer to model the space of possible analyses provides additional improvement. We make use of the resulting morphological models for scoring and ranking the analyses of the morphological analyzer for morphological disambiguation. The results show significant gains in accuracy across several evaluation metrics. Our system results in 4.4% absolute increase over the state-of-the-art in full morphological analysis accuracy (30.6% relative error reduction), and 10.6% (31.5% relative error reduction) for out-of-vocabulary words.",2017,False,True,False,True,False,False,False,"B, D",291,3,294
W17-4213,Deception Detection in News Reports in the {R}ussian Language: Lexics and Discourse,"Different language markers can be used to reveal the differences between structures of truthful and deceptive (fake) news. Two experiments are held: the first one is based on lexics level markers, the second one on discourse level is based on rhetorical relations categories (frequencies). Corpus consists of 174 truthful and deceptive news stories in Russian. Support Vector Machines and Random Forest Classifier were used for text classification. The best results for lexical markers we got by using Support Vector Ma-chines with rbf kernel (f-measure 0.65). The model could be developed and be used as a preliminary filter for fake news detection.",2017,False,False,False,False,True,False,True,"E, G",244,3,247
W17-2314,Proactive Learning for Named Entity Recognition,"The goal of active learning is to minimise the cost of producing an annotated dataset, in which annotators are assumed to be perfect, i.e., they always choose the correct labels. However, in practice, annotators are not infallible, and they are likely to assign incorrect labels to some instances. Proactive learning is a generalisation of active learning that can model different kinds of annotators. Although proactive learning has been applied to certain labelling tasks, such as text classification, there is little work on its application to named entity (NE) tagging. In this paper, we propose a proactive learning method for producing NE annotated corpora, using two annotators with different levels of expertise, and who charge different amounts based on their levels of experience. To optimise both cost and annotation quality, we also propose a mechanism to present multiple sentences to annotators at each iteration. Experimental results for several corpora show that our method facilitates the construction of high-quality NE labelled datasets at minimal cost.",2017,True,False,False,True,False,False,False,"A, D",316,3,319
S17-2064,{D}uluth at {S}em{E}val-2017 Task 6: Language Models in Humor Detection,"This paper describes the Duluth system that participated in SemEval-2017 Task 6 #HashtagWars: Learning a Sense of Humor. The system participated in Subtasks A and B using N-gram language models, ranking highly in the task evaluation. This paper discusses the results of our system in the development and evaluation stages and from two post-evaluation runs.",2017,False,False,False,True,False,False,True,"G, D",192,3,195
I17-1055,Combining Lightly-Supervised Text Classification Models for Accurate Contextual Advertising,"In this paper we propose a lightlysupervised framework to rapidly build text classifiers for contextual advertising. In contextual advertising, advertisers often want to target to a specific class of webpages most relevant to their product, which may not be covered by a pre-trained classifier. Moreover, the advertisers are only interested in the target class. Therefore, it is more suitable to model as a oneclass classification problem, in contrast to traditional classification problems where disjoint classes are defined a priori. We first apply two state-of-the-art lightlysupervised classification models, generalized expectation (GE) criteria (Druck et al., 2008) and multinomial naïve Bayes (MNB) with priors (Settles, 2011) to oneclass classification where the user only provides a small list of labeled words for the target class. We fuse the two models together by using MNB to automatically enrich the constraints for GE training. We also explore ensemble method to further improve the accuracy. On a corpus of real-time bidding requests, the proposed model achieves the highest average F 1 of 0.69 and closes half of the gap between previous state-of-the-art lightlysupervised models to a fully-supervised MaxEnt model.",2017,False,False,False,True,False,False,True,"D, G",362,3,365
W17-5036,Language Based Mapping of Science Assessment Items to Skills,"Knowledge of the association between assessment questions and the skills required to solve them is necessary for analysis of student learning. This association, often represented as a Q-matrix, is either handlabeled by domain experts or learned as latent variables given a large student response data set. As a means of automating the match to formal standards, this paper uses neural text classification methods, leveraging the language in the standards documents to identify online text for a proxy training task. Experiments involve identifying the topic and crosscutting concepts of middle school science questions leveraging multi-task training. Results show that it is possible to automatically build a Q-matrix without student response data and using a modest number of handlabeled questions.",2017,False,False,False,True,False,False,True,"D, G",258,3,261
W17-7532,{``}A pessimist sees the difficulty in every opportunity; an optimist sees the opportunity in every difficulty{''} {--} Understanding the psycho-sociological influences to it,"This paper presents an empirical study to understand how psycho-sociological factors influence on optimism/pessimism at the individual level. Optimists believe that future events are going to work out for the best; pessimists expect the worst. Their expectations manifest in their day-to-day behaviour and also reflects the way a person tweets or behaves in online social media. To this end, we have identified optimist/pessimist users from Twitter, analyzed their personality (psychological) and values & ethics (sociological) at the community level. Empirical analysis reveals some interesting insights and behavioral patterns related to user level optimism/pessimism in different combinations of psychological and sociological factors, are reported.",2017,False,False,False,False,True,False,True,"E, G",258,3,261
S17-2051,{S}im{B}ow at {S}em{E}val-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering,"This paper describes the SimBow system submitted at SemEval2017-Task3, for the question-question similarity subtask B. The proposed approach is a supervised combination of different unsupervised textual similarities. These textual similarities rely on the introduction of a relation matrix in the classical cosine similarity between bag-of-words, so as to get a softcosine that takes into account relations between words. According to the type of relation matrix embedded in the soft-cosine, semantic or lexical relations can be considered. Our system ranked first among the official submissions of subtask B.",2017,False,True,False,True,False,False,False,"B, D",233,3,236
D17-1099,Zero-Shot Activity Recognition with Verb Attribute Induction,"In this paper, we investigate large-scale zero-shot activity recognition by modeling the visual and linguistic attributes of action verbs. For example, the verb ""salute"" has several properties, such as being a light movement, a social act, and short in duration. We use these attributes as the internal mapping between visual and textual representations to reason about a previously unseen action. In contrast to much prior work that assumes access to gold standard attributes for zero-shot classes and focuses primarily on object attributes, our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations. Experimental results confirm that action attributes inferred from language can provide a predictive signal for zero-shot prediction of previously unseen activities.",2017,False,False,False,True,True,False,False,"D, E",254,3,257
W17-6814,Exploring Substitutability through Discourse Adverbials and Multiple Judgments,"In his systematic analysis of discourse connectives, Knott (1996) introduced the notion of substitutability and the conditions under which one connective (e.g., when) can substitute for another (e.g., if ) to express the same meaning. Knott only uses examples which he constructed and judged himself. This paper describes a new multi-judgment study on naturally occurring passages, on which substitutability claims can be tested. While some of our findings support Knott's claims, other pairs of connectives that Knott predicts to be exclusive are in fact judged to substitute felicitously for one another. These findings show that discourse adverbials in the immediate context play a role in connective choice.",2017,False,False,False,False,True,True,False,"E,F",260,2,262
W17-3407,Why We Speak,"We explain the relevance of Nash, Hoare and others in explaining Gricean implicature and cheap talk. We also develop a general model to address cases where communication is not cooperative, i..e cases of deception as well as cases where there is common knowledge of different interests in speaker and hearer. Tow models, one qualitative and one quantitative are introduced.",2017,False,True,True,False,False,False,False,"C, B",190,3,193
P17-1126,Learning to Generate Market Comments from Stock Prices,"This paper presents a novel encoderdecoder model for automatically generating market comments from stock prices. The model first encodes both short-and long-term series of stock prices so that it can mention short-and long-term changes in stock prices. In the decoding phase, our model can also generate a numerical value by selecting an appropriate arithmetic operation such as subtraction or rounding, and applying it to the input stock prices. Empirical experiments show that our best model generates market comments at the fluency and the informativeness approaching human-generated reference texts.",2017,False,True,False,True,False,False,False,"B, D",222,3,225
P17-2107,How (not) to train a dependency parser: The curious case of jackknifing part-of-speech taggers,"In dependency parsing, jackknifing taggers is indiscriminately used as a simple adaptation strategy. Here, we empirically evaluate when and how (not) to use jackknifing in parsing. On 26 languages, we reveal a preference that conflicts with, and surpasses the ubiquitous ten-folding. We show no clear benefits of tagging the training data in cross-lingual parsing.",2017,False,False,False,False,True,True,False,"E,F",199,2,201
D17-1209,Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,"We present a simple and effective approach to incorporating syntactic structure into neural attention-based encoderdecoder models for machine translation. We rely on graph-convolutional networks (GCNs), a recent class of neural networks developed for modeling graph-structured data. Our GCNs use predicted syntactic dependency trees of source sentences to produce representations of words (i.e. hidden states of the encoder) that are sensitive to their syntactic neighborhoods. GCNs take word representations as input and produce word representations as output, so they can easily be incorporated as layers into standard encoders (e.g., on top of bidirectional RNNs or convolutional neural networks). We evaluate their effectiveness with English-German and English-Czech translation experiments for different types of encoders and observe substantial improvements over their syntax-agnostic versions in all the considered setups.",2017,False,True,False,True,False,False,False,"B, D",286,3,289
E17-2090,Predicting Emotional Word Ratings using Distributional Representations and Signed Clustering,"Inferring the emotional content of words is important for text-based sentiment analysis, dialogue systems and psycholinguistics, but word ratings are expensive to collect at scale and across languages or domains. We develop a method that automatically extends word-level ratings to unrated words using signed clustering of vector space word representations along with affect ratings. We use our method to determine a word's valence and arousal, which determine its position on the circumplex model of affect, the most popular dimensional model of emotion. Our method achieves superior out-of-sample word rating prediction on both affective dimensions across three different languages when compared to state-of-theart word similarity based methods. Our method can assist building word ratings for new languages and improve downstream tasks such as sentiment analysis and emotion detection.",2017,False,True,False,True,False,False,False,"B, D",272,3,275
E17-1107,Authorship Attribution Using Text Distortion,"Authorship attribution is associated with important applications in forensics and humanities research. A crucial point in this field is to quantify the personal style of writing, ideally in a way that is not affected by changes in topic or genre. In this paper, we present a novel method that enhances authorship attribution effectiveness by introducing a text distortion step before extracting stylometric measures. The proposed method attempts to mask topicspecific information that is not related to the personal style of authors. Based on experiments on two main tasks in authorship attribution, closed-set attribution and authorship verification, we demonstrate that the proposed approach can enhance existing methods especially under cross-topic conditions, where the training and test corpora do not match in topic.",2017,False,False,False,True,False,False,True,"D, G",259,3,262
W17-4740,{XMU} Neural Machine Translation Systems for {WMT} 17,"This paper describes the Neural Machine Translation systems of Xiamen University for the translation tasks of WMT 17. Our systems are based on the Encoder-Decoder framework with attention. We participated in three directions of shared news translation tasks: English→German and Chinese↔English. We experimented with deep architectures, different segmentation models, synthetic training data and targetbidirectional translation models. Experiments show that all methods can give substantial improvements.",2017,False,False,False,True,False,False,True,"D, G",205,3,208
W17-2702,Detecting Changes in {T}witter Streams using Temporal Clusters of Hashtags,"Detecting events from social media data has important applications in public security, political issues, and public health. Many studies have focused on detecting specific or unspecific events from Twitter streams. However, not much attention has been paid to detecting changes, and their impact, in online conversations related to an event. We propose methods for detecting such changes, using clustering of temporal profiles of hashtags, and three change point detection algorithms. The methods were tested on two Twitter datasets: one covering the 2014 Ottawa shooting event, and one covering the Sochi winter Olympics. We compare our approach to a baseline consisting of detecting change from raw counts in the conversation. We show that our method produces large gains in change detection accuracy on both datasets.",2017,False,False,False,True,False,False,True,"D, G",263,3,266
K17-2009,Character Sequence-to-Sequence Model with Global Attention for Universal Morphological Reinflection,"This paper presents a neural network based approach for the CoNLL-SIGMORPHON-2017 Shared Task 1 on morphological reinflection. We propose an encoder-decoder architecture to model this morphological reinflection problem. For an input word, every character is encoded through a Bi-directional Gated Recurrent Unit (GRU) network. Another GRU network is deployed as a decoder to generate the inflection. We participate in Task 1, which includes 52 languages without using external resources. In each language, three training sets are provided (high, medium, and low respectively represent the amount of training data; Scottish Gaelic only has medium and low), totally 155 training sets. Due to time constraints, we only search for optimized parameters of our model based on the Albanian dataset. The source code of our model is available at https://github.com/valdersoul/conll2017.",2017,False,True,False,False,False,False,True,"B, G",304,3,307
K17-1002,Rational Distortions of Learners{'} Linguistic Input,"Language acquisition can be modeled as a statistical inference problem: children use sentences and sounds in their input to infer linguistic structure. However, in many cases, children learn from data whose statistical structure is distorted relative to the language they are learning. Such distortions can arise either in the input itself, or as a result of children's immature strategies for encoding their input. This work examines several cases in which the statistical structure of children's input differs from the language being learned. Analyses show that these distortions of the input can be accounted for with a statistical learning framework by carefully considering the inference problems that learners solve during language acquisition Bio: Naomi Feldman is an associate professor in the Department of Linguistics and the Institute for Advanced Computer Studies at the University of Maryland. She received her PhD in Cognitive Science from Brown University in 2011. Her research lies at the intersection of cognitive science, computer science, and linguistics. She uses methods from machine learning to create formal models of how people learn and represent the structure of their language, and has been developing methods that take advantage of naturalistic speech corpora to study how listeners encode information from their linguistic environment.",2017,False,False,False,False,True,True,False,"E, F",348,3,351
W17-1804,{U}niversal {D}ependencies to Logical Form with Negation Scope,"Many language technology applications would benefit from the ability to represent negation and its scope on top of widelyused linguistic resources. In this paper, we investigate the possibility of obtaining a first-order logic representation with negation scope marked using Universal Dependencies. To do so, we enhance UDe-pLambda, a framework that converts dependency graphs to logical forms. The resulting UDepLambda¬ is able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to negation but also to universal quantification and other complex semantic phenomena. The initial conversion we did for English is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as universal quantifiers.",2017,False,True,False,True,False,False,False,"B, D",262,3,265
W17-6812,Extracting hypernym relations from {W}ikipedia disambiguation pages : comparing symbolic and machine learning approaches,"Extracting hypernym relations from text is one of the key steps in the construction and enrichment of semantic resources. Several methods have been exploited in a variety of propositions in the literature. However, the strengths of each approach on a same corpus are still poorly identified in order to better take advantage of their complementarity. In this paper, we study how complementary two approaches of different nature are when identifying hypernym relations on a structured corpus containing both well-written text and syntactically poor formulations, together with a rich formatting. A symbolic approach based on lexico-syntactic patterns and a statistical approach using a supervised learning method are applied to a sub-corpus of Wikipedia in French, composed of disambiguation pages. These pages, particularly rich in hypernym relations, contain both kinks of formulations. We compared the results of each approach independently of each other and compared the performance when combining together their individual results. We obtain the best results in the latter case, with an F-measure of 0.75. In addition, 55% of the identified relations, with respect to a reference corpus, are not expressed in the French DBPedia and could be used to enrich this resource.",2017,False,False,False,True,True,False,False,"D, E",356,3,359
S17-2132,{T}ake{L}ab at {S}em{E}val-2017 Task 4: Recent Deaths and the Power of Nostalgia in Sentiment Analysis in {T}witter,"This paper describes the system we submitted to SemEval-2017 Task 4 (Sentiment Analysis in Twitter), specifically subtasks A, B, and D. Our main focus was topic-based message polarity classification on a two-point scale (subtask B). The system we submitted uses a Support Vector Machine classifier with rich set of features, ranging from standard to more creative, task-specific features, including a series of rating-based features as well as features that account for sentimental reminiscence of past topics and deceased famous people. Our system ranked 14th out of 39 submissions in subtask A, 5th out of 24 submissions in subtask B, and 3rd out of 16 submissions in subtask D.",2017,False,False,False,True,False,False,True,"D, G",266,3,269
U17-1005,A Hybrid Model for Quality Assessment of {W}ikipedia Articles,"The task of document quality assessment is a highly complex one, which draws on analysis of aspects including linguistic content, document structure, fact correctness, and community norms. We explore the task in the context of a Wikipedia article assessment task, and propose a hybrid approach combining deep learning with features proposed in the literature. Our method achieves 6.5% higher accuracy than the state of the art in predicting the quality classes of English Wikipedia articles over a novel dataset of around 60k Wikipedia articles. We also discuss limitations with this task setup, and possible directions for establishing more robust document quality assessment evaluations.",2017,True,False,False,True,False,False,False,"A, D",237,3,240
W17-0233,{D}ep{\_}search: Efficient Search Tool for Large Dependency Parsebanks,"We present an updated and improved version of our syntactic analysis query toolkit, dep search, geared towards morphologically rich languages and large parsebanks. The query language supports complex searches on dependency graphs, including for example boolean logic and nested queries. Improvements we present here include better data indexing, especially better database backend and document metadata support, API access and improved web user interface. All contributions are available under open licences.",2017,False,False,False,True,False,False,True,"D, G",200,3,203
2017.jeptalnrecital-court.7,D{\'e}tection de cor{\'e}f{\'e}rences de bout en bout en fran{\c{c}}ais (End-to-end coreference resolution for {F}rench),"Notre objectif est l'élaboration d'un système de détection automatique de relations de coréférence le plus général possible, pour le traitement des anaphores pronominales et les coréférences directes. Nous décrivons dans cet article les différentes étapes de traitement des textes dans le système que nous avons développé : (i) l'annotation en traits lexicaux et syntaxiques par le système Macaon ; (ii) le repérage des mentions par un modèle obtenu par apprentissage sur le corpus ANCOR ; (iii) l'annotation sémantique des mentions à partir de deux ressources : le DEM et le LVF ; (iv) l'annotation en coréférences par un système à base de règles. Le système est évalué sur le corpus ANCOR.",2017,True,False,False,False,False,False,True,"A, G",282,3,285
E17-2087,Negative Sampling Improves Hypernymy Extraction Based on Projection Learning,"We present a new approach to extraction of hypernyms based on projection learning and word embeddings. In contrast to classification-based approaches, projection-based methods require no candidate hyponym-hypernym pairs. While it is natural to use both positive and negative training examples in supervised relation extraction, the impact of negative examples on hypernym prediction was not studied so far. In this paper, we show that explicit negative examples used for regularization of the model significantly improve performance compared to the stateof-the-art approach of Fu et al. ( 2014 ) on three datasets from different languages.",2017,False,True,False,False,False,True,False,"B, F",235,3,238
D17-1286,Word Etymology as Native Language Interference,"We present experiments that show the influence of native language on lexical choice when producing text in another language -in this particular case English. We start from the premise that non-native English speakers will choose lexical items that are close to words in their native language. This leads us to an etymologybased representation of documents written by people whose mother tongue is an Indo-European language. Based on this representation we grow a language family tree, that matches closely the Indo-European language tree.",2017,False,False,False,False,True,True,False,"E, F",212,3,215
W17-7542,A Modified Cosine-Similarity based Log Kernel for Support Vector Machines in the Domain of Text Classification,"The popularity of the internet is increasing day-by-day, which makes tough for the end-user to get desired pages from the web in a short time. Text classification, a branch of machine learning can shed light on this problem. State-of-the-art classifier like Support Vector Machines (SVM) has become very popular in the domain of text classification. This paper studies the effect of SVM using different kernel methods and proposes a modified cosine distance based log kernel (log cosine) for text classification which is proved as Conditional Positive Definite (CPD). Its classification performance is compared with other CPDs and Positive Definite (PD) kernels. A novel feature selection technique is proposed which improves the effectiveness of the classification and gathers the crux of the terms in the corpus without deteriorating the outcome in the construction process. From the experimental results, it is observed that CPD kernels provide better results for text classification when used with SVMs compared to PD kernels, and the performance of the proposed log-cosine is better than the existing kernel methods.",2017,False,False,True,True,False,False,False,"C, D",327,3,330
K17-1017,Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring,"Neural network models have recently been applied to the task of automatic essay scoring, giving promising results. Existing work used recurrent neural networks and convolutional neural networks to model input essays, giving grades based on a single vector representation of the essay. On the other hand, the relative advantages of RNNs and CNNs have not been compared. In addition, different parts of the essay can contribute differently for scoring, which is not captured by existing models. We address these issues by building a hierarchical sentence-document model to represent essays, using the attention mechanism to automatically decide the relative weights of words and sentences. Results show that our model outperforms the previous stateof-the-art methods, demonstrating the effectiveness of the attention mechanism.",2017,False,True,False,False,False,True,False,"B, F",262,3,265
D17-1297,Neural Sequence-Labelling Models for Grammatical Error Correction,"We propose an approach to N -best list reranking using neural sequence-labelling models. We train a compositional model for error detection that calculates the probability of each token in a sentence being correct or incorrect, utilising the full sentence as context. Using the error detection model, we then re-rank the N best hypotheses generated by statistical machine translation systems. Our approach achieves state-of-the-art results on error correction for three different datasets, and it has the additional advantage of only using a small set of easily computed features that require no linguistic input.",2017,False,True,False,True,False,False,False,"B, D",229,3,232
W17-3603,A Distributional View of Discourse Encapsulation: Multifactorial Prediction of Coreference Density in {RST},"Early formulations of discourse coherence constraints postulated a connection between coreference likelihood and distance within a discourse parse, e.g. in the framework of Veins Theory (Cristea et al. 1998%CristeaIdeRomary1998), which proposes that coreference is expected to be encapsulated within tightly linked areas of discourse parses, called Domains of Referential Accessibility (DRAs). Using an RST dependency representation, this paper expands on previous work showing the relevance of DRAs to coreference likelihood. We develop a multifactorial model using both rhetorical and surface distance metrics, as well as confounds such as unit length and genre, and direct versus indirect rhetorical paths. We also explore coreferential accessibility as it applies to less studied types of coreference, including bridging and lexical coreference. The results show that rhetorical and surface distance, as well as direct linking, all influence coreference likelihood, and should not be treated as mutually exclusive or redundant metrics. Finally, we incorporate RST relation-specific tendencies that offer a more fine-grained model of coreference accessibility.",2017,False,False,False,False,True,True,False,"E, F",335,3,338
P17-2020,Hybrid Neural Network Alignment and Lexicon Model in Direct {HMM} for Statistical Machine Translation,"Recently, the neural machine translation systems showed their promising performance and surpassed the phrase-based systems for most translation tasks. Retreating into conventional concepts machine translation while utilizing effective neural models is vital for comprehending the leap accomplished by neural machine translation over phrase-based methods. This work proposes a direct hidden Markov model (HMM) with neural network-based lexicon and alignment models, which are trained jointly using the Baum-Welch algorithm. The direct HMM is applied to rerank the n-best list created by a state-of-the-art phrase-based translation system and it provides improvements by up to 1.0% BLEU scores on two different translation tasks.",2017,False,True,True,False,False,False,False,"B, C",249,3,252
E17-2029,Latent Variable Dialogue Models and their Diversity,"We present a dialogue generation model that directly captures the variability in possible responses to a given input, which reduces the 'boring output' issue of deterministic dialogue models. Experiments show that our model generates more diverse outputs than baseline models, and also generates more consistently acceptable output than sampling from a deterministic encoder-decoder model.",2017,False,True,False,False,False,True,False,"B, F",182,3,185
D17-1232,Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences,"We present an unsupervised model of dialogue act sequences in conversation. By modeling topical themes as transitioning more slowly than dialogue acts in conversation, our model de-emphasizes contentrelated words in order to focus on conversational function words that signal dialogue acts. We also incorporate speaker tendencies to use some acts more than others as an additional predictor of dialogue act prevalence beyond temporal dependencies. According to the evaluation presented on two dissimilar corpora, the CNET forum and NPS Chat corpus, the effectiveness of each modeling assumption is found to vary depending on characteristics of the data. De-emphasizing contentrelated words yields improvement on the CNET corpus, while utilizing speaker tendencies is advantageous on the NPS corpus. The components of our model complement one another to achieve robust performance on both corpora and outperform state-of-the-art baseline models.",2017,False,True,False,False,False,True,False,"B, F",283,3,286
W17-4736,The Karlsruhe Institute of Technology Systems for the News Translation Task in {WMT} 2017,"We present our experiments in the scope of the news translation task in WMT 2017, in three directions: German→English, English→German and English→Latvian. The core of our systems is the encoderdecoder based neural machine translation models , enhanced with various modeling features, additional source side augmentation and output rescoring. We also experiment various methods in data selection and adaptation.",2017,False,True,False,True,False,False,False,"B, D",196,3,199
I17-1102,Multilingual Hierarchical Attention Networks for Document Classification,"Hierarchical attention networks have recently achieved remarkable performance for document classification in a given language. However, when multilingual document collections are considered, training such models separately for each language entails linear parameter growth and lack of cross-language transfer. Learning a single multilingual model with fewer parameters is therefore a challenging but potentially beneficial objective. To this end, we propose multilingual hierarchical attention networks for learning document structures, with shared encoders and/or shared attention mechanisms across languages, using multi-task learning and an aligned semantic space as input. We evaluate the proposed models on multilingual document classification with disjoint label sets, on a large dataset which we provide, with 600k news documents in 8 languages, and 5k labels. The multilingual models outperform monolingual ones in low-resource as well as full-resource settings, and use fewer parameters, thus confirming their computational efficiency and the utility of cross-language transfer.",2017,True,True,False,False,False,False,False,"B, A",294,3,297
I17-2032,A Statistical Framework for Product Description Generation,"We present in this paper a statistical framework that generates accurate and fluent product description from product attributes. Specifically, after extracting templates and learning writing knowledge from attribute-description parallel data, we use the learned knowledge to decide what to say and how to say for product description generation. To evaluate accuracy and fluency for the generated descriptions, in addition to BLEU and Recall, we propose to measure what to say (in terms of attribute coverage) and to measure how to say (by attribute-specified generation) separately. Experimental results show that our framework is effective.",2017,False,True,False,True,False,False,False,"B, D",228,3,231
W17-1222,{A}rabic Dialect Identification Using i{V}ectors and {ASR} Transcripts,"This paper presents the systems submitted by the MAZA team to the Arabic Dialect Identification (ADI) shared task at the VarDial Evaluation Campaign 2017. The goal of the task is to evaluate computational models to identify the dialect of Arabic utterances using both audio and text transcriptions. The ADI shared task dataset included Modern Standard Arabic (MSA) and four Arabic dialects: Egyptian, Gulf, Levantine, and North-African. The three systems submitted by MAZA are based on combinations of multiple machine learning classifiers arranged as (1) voting ensemble; (2) mean probability ensemble; (3) meta-classifier. The best results were obtained by the meta-classifier achieving 71.7% accuracy, ranking second among the six teams which participated in the ADI shared task.",2017,False,False,False,True,False,False,True,"D, G",280,3,283
E17-1066,Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching,"This work studies comparatively two typical sentence matching tasks: textual entailment (TE) and answer selection (AS), observing that weaker phrase alignments are more critical in TE, while stronger phrase alignments deserve more attention in AS. The key to reach this observation lies in phrase detection, phrase representation, phrase alignment, and more importantly how to connect those aligned phrases of different matching degrees with the final classifier. Prior work (i) has limitations in phrase generation and representation, or (ii) conducts alignment at word and phrase levels by handcrafted features or (iii) utilizes a single framework of alignment without considering the characteristics of specific tasks, which limits the framework's effectiveness across tasks. We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific attentive pooling of phrase alignments between two sentences. Experimental results on TE and AS match our observation and show the effectiveness of our approach.",2017,False,True,False,False,False,True,False,"B, F",309,3,312
E17-1119,Neural Architectures for Fine-grained Entity Type Classification,"In this work, we investigate several neural network architectures for fine-grained entity type classification and make three key contributions. Despite being a natural comparison and addition, previous work on attentive neural architectures have not considered hand-crafted features and we combine these with learnt features and establish that they complement each other. Additionally, through quantitative analysis we establish that the attention mechanism learns to attend over syntactic heads and the phrase containing the mention, both of which are known to be strong hand-crafted features for our task. We introduce parameter sharing between labels through a hierarchical encoding method, that in lowdimensional projections show clear clusters for each type hierarchy. Lastly, despite using the same evaluation dataset, the literature frequently compare models trained using different data. We demonstrate that the choice of training data has a drastic impact on performance, which decreases by as much as 9.85% loose micro F1 score for a previously proposed method. Despite this discrepancy, our best model achieves state-of-the-art results with 75.36% loose micro F1 score on the well-established FIGER (GOLD) dataset and we report the best results for models trained using publicly available data for the OntoNotes dataset with 64.93% loose micro F1 score. a match series against New Zealand is held on Monday Output Word Embeddings LSTM Layers A9en:ons Context Representa:on Men:on Representa:on /organiza)on, /organiza)on/sports_team Figure 1: An illustration of the attentive encoder neural model predicting fine-grained semantic types for the mention ""New Zealand"" in the expression ""a match series against New Zealand is held on Monday"".",2017,False,True,False,False,False,True,False,"B, F",449,3,452
W17-0231,Multilingwis{\mbox{$^2$}} {--} Explore Your Parallel Corpus,"We present Multilingwis 2 , a web based search engine for exploration of wordaligned parallel and multiparallel corpora. Our application extends the search facilities by Clematide et al. ( 2016 ) and is designed to be easily employable on any parallel corpus comprising universal part-ofspeech tags, lemmas and word alignments. In addition to corpus exploration, it has proven useful for the assessment of word alignment quality. Loading the results of different alignment methods on the same corpus as different corpora into Multilingwis 2 alleviates their comparison.",2017,False,False,False,False,True,False,True,"E, G",233,3,236
W17-3506,What is the Role of Recurrent Neural Networks ({RNN}s) in an Image Caption Generator?,"In neural image captioning systems, a recurrent neural network (RNN) is typically viewed as the primary 'generation' component. This view suggests that the image features should be 'injected' into the RNN. This is in fact the dominant view in the literature. Alternatively, the RNN can instead be viewed as only encoding the previously generated words. This view suggests that the RNN should only be used to encode linguistic features and that only the final representation should be 'merged' with the image features at a later stage. This paper compares these two architectures. We find that, in general, late merging outperforms injection, suggesting that RNNs are better viewed as encoders, rather than generators.",2017,False,False,False,False,True,True,False,"F, E",262,3,265
S17-2031,"{LIPN}-{IIMAS} at {S}em{E}val-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity","In this paper we report our attempt to use, on the one hand, state-of-the-art neural approaches that are proposed to measure Semantic Textual Similarity (STS). On the other hand, we propose an unsupervised cross-word alignment approach, which is linguistically motivated. The neural approaches proposed herein are divided into two main stages. The first stage deals with constructing neural word embeddings, the components of sentence embeddings. The second stage deals with constructing a semantic similarity function relating pairs of sentence embeddings. Unfortunately our competition results were poor in all tracks, therefore we concentrated our research to improve them for Track 5 (EN-EN).",2017,False,False,False,True,False,True,False,"D, F",245,3,248
E17-2057,Improving Evaluation of Document-level Machine Translation Quality Estimation,"Meaningful conclusions about the relative performance of NLP systems are only possible if the gold standard employed in a given evaluation is both valid and reliable. In this paper, we explore the validity of human annotations currently employed in the evaluation of document-level quality estimation for machine translation (MT). We demonstrate the degree to which MT system rankings are dependent on weights employed in the construction of the gold standard, before proposing direct human assessment as a valid alternative. Experiments show direct assessment (DA) scores for documents to be highly reliable, achieving a correlation of above 0.9 in a self-replication experiment, in addition to a substantial estimated cost reduction through quality controlled crowdsourcing. The original gold standard based on post-edits incurs a 10-20 times greater cost than DA.",2017,False,False,False,False,True,False,True,"E, G",273,3,276
W17-4780,Variable Mini-Batch Sizing and Pre-Trained Embeddings,"This paper describes our submission to the WMT 2017 Neural MT Training Task. We modified the provided NMT system in order to allow for interrupting and continuing the training of models. This allowed mid-training batch size decrementation and incrementation at variable rates. In addition to the models with variable batch size, we tried different setups with pre-trained word2vec embeddings. Aside from batch size incrementation, all our experiments performed below the baseline.",2017,False,True,False,True,False,False,False,"B, D",208,3,211
E17-2115,Effective shared representations with Multitask Learning for Community Question Answering,"An important asset of using Deep Neural Networks (DNNs) for text applications is their ability to automatically engineer features. Unfortunately, DNNs usually require a lot of training data, especially for high-level semantic tasks such as community Question Answering (cQA). In this paper, we tackle the problem of data scarcity by learning the target DNN together with two auxiliary tasks in a multitask learning setting. We exploit the strong semantic connection between selection of comments relevant to (i) new questions and (ii) forum questions. This enables a global representation for comments, new and previous questions. The experiments of our model on a SemEval challenge dataset for cQA show a 20% relative improvement over standard DNNs.",2017,False,False,False,True,False,False,True,"D, G",264,3,267
J17-3003,A Kernel Independence Test for Geographical Language Variation,"Quantifying the degree of spatial dependence for linguistic variables is a key task for analyzing dialectal variation. However, existing approaches have important drawbacks. First, they are based on parametric models of dependence, which limits their power in cases where the underlying parametric assumptions are violated. Second, they are not applicable to all types of linguistic data: Some approaches apply only to frequencies, others to boolean indicators of whether a linguistic variable is present. We present a new method for measuring geographical language variation, which solves both of these problems. Our approach builds on Reproducing Kernel Hilbert Space (RKHS) representations for nonparametric statistics, and takes the form of a test statistic that is computed from pairs of individual geotagged observations without aggregation into predefined geographical bins. We compare this test with prior work using synthetic data as well as a diverse set of real data sets: a corpus of Dutch tweets, a Dutch syntactic atlas, and a data set of letters to the editor in North American newspapers. Our proposed test is shown to support robust inferences across a broad range of scenarios and types of data.",2017,False,False,True,False,True,False,False,"C, E",340,3,343
W17-6904,Living a discrete life in a continuous world: Reference in cross-modal entity tracking,"Reference is a crucial property of language that allows us to connect linguistic expressions to the world. Modeling it requires handling both continuous and discrete aspects of meaning. Data-driven models excel at the former, but struggle with the latter, and the reverse is true for symbolic models. This paper (a) introduces a concrete referential task to test both aspects, called cross-modal entity tracking; (b) proposes a neural network architecture that uses external memory to build an entity library inspired in the DRSs of DRT, with a mechanism to dynamically introduce new referents or add information to referents that are already in the library. Our model shows promise: it beats traditional neural network architectures on the task. However, it is still outperformed by Memory Networks, another model with external memory.",2017,True,True,False,False,False,False,False,"A, B",274,3,277
O17-1028,Opinion Target Extraction for Student Course Feedback,"Student feedback is an essential part of the instructor -student relationship. Traditionally student feedback is manually summarized by instructors, which is time consuming. Automatic student feedback summarization provides a potential solution to this. For summarizing student feedback, first, the opinion targets should be identified and extracted. In this context, opinion targets such as ""lecture slides"", ""teaching style"" are the important key points in the feedback that the students have shown their sentiment towards. In this paper, we focus on the opinion target extraction task of general student feedback. We model this problem as an information extraction task and extract opinion targets using a Conditional Random Fields (CRF) classifier. Our results show that this classifier outperforms the state-of-the-art techniques for student feedback summarization.",2017,True,False,False,True,False,False,False,"A, D",270,3,273
D17-1271,Classification of telicity using cross-linguistic annotation projection,"This paper addresses the automatic recognition of telicity, an aspectual notion. A telic event includes a natural endpoint (she walked home), while an atelic event does not (she walked around). Recognizing this difference is a prerequisite for temporal natural language understanding. In English, this classification task is difficult, as telicity is a covert linguistic category. In contrast, in Slavic languages, aspect is part of a verb's meaning and even available in machine-readable dictionaries. Our contributions are as follows. We successfully leverage additional silver standard training data in the form of projected annotations from parallel English-Czech data as well as context information, improving automatic telicity classification for English significantly compared to previous work. We also create a new data set of English texts manually annotated with telicity.",2017,True,False,False,True,False,False,False,"A, D",274,3,277
I17-4027,{ADAPT} at {IJCNLP}-2017 Task 4: A Multinomial Naive {B}ayes Classification Approach for Customer Feedback Analysis task,"In this age of the digital economy, promoting organisations attempt their best to engage the customers in the feedback provisioning process. With the assistance of customer insights, an organisation can develop a better product and provide a better service to its customer. In this paper, we analyse the real world samples of customer feedback from Microsoft Office customers in four languages, i.e., English, French, Spanish and Japanese and conclude a five-plus-one-classes categorisation (comment, request, bug, complaint, meaningless and undetermined) for meaning classification. The task is to determine what class(es) the customer feedback sentences should be annotated as in four languages. We propose following approaches to accomplish this task: (i) a multinomial naive bayes (MNB) approach for multilabel classification, (ii) MNB with one-vsrest classifier approach, and (iii) the combination of the multilabel classificationbased and the sentiment classificationbased approach. Our best system produces F-scores of 0.67, 0.83, 0.72 and 0.7 for English, Spanish, French and Japanese, respectively. The results are competitive to the best ones for all languages and secure 3 rd and 5 th position for Japanese and French, respectively, among all submitted systems.",2017,True,False,False,False,False,False,True,"A, G",375,3,378
W17-6201,A Feature Structure Algebra for {FTAG},"FTAG, the extension of TAG with feature structures, lags behind other featurebased grammar formalisms in the availability of efficient chart parsers. This is in part because of the complex interaction of adjunction and unification, which makes such parsers inconvenient to implement. We present a novel, simple algebra for feature structures and show how FTAG can be encoded as an Interpreted Regular Tree Grammar using this algebra. This yields a straightforward, efficient chart parsing algorithm for FTAG.",2017,False,True,True,False,False,False,False,"C, B",216,3,219
S17-1021,Logical Metonymy in a Distributional Model of Sentence Comprehension,"In theoretical linguistics, logical metonymy is defined as the combination of an event-subcategorizing verb with an entity-denoting direct object (e.g., The author began the book), so that the interpretation of the VP requires the retrieval of a covert event (e.g., writing). Psycholinguistic studies have revealed extra processing costs for logical metonymy, a phenomenon generally explained with the introduction of new semantic structure. In this paper, we present a general distributional model for sentence comprehension inspired by the Memory, Unification and Control model by Hagoort (2013 Hagoort ( , 2016)) . We show that our distributional framework can account for the extra processing costs of logical metonymy and can identify the covert event in a classification task.",2017,False,True,False,False,False,True,False,"B, F",275,3,278
D17-1241,Multi-View Unsupervised User Feature Embedding for Social Media-based Substance Use Prediction,"In this paper, we demonstrate how the state-of-the-art machine learning and text mining techniques can be used to build effective social media-based substance use detection systems. Since a substance use ground truth is difficult to obtain on a large scale, to maximize system performance, we explore different unsupervised feature learning methods to take advantage of a large amount of unsupervised social media data. We also demonstrate the benefit of using multi-view unsupervised feature learning to combine heterogeneous user information such as Facebook ""likes"" and ""status updates"" to enhance system performance. Based on our evaluation, our best models achieved 86% AUC for predicting tobacco use, 81% for alcohol use and 84% for illicit drug use, all of which significantly outperformed existing methods. Our investigation has also uncovered interesting relations between a user's social media behavior (e.g., word usage) and substance use.",2017,False,False,False,True,True,False,False,"D, E",296,3,299
I17-4028,{O}hio{S}tate at {IJCNLP}-2017 Task 4: Exploring Neural Architectures for Multilingual Customer Feedback Analysis,"This paper describes our systems for IJC-NLP 2017 Shared Task on Customer Feedback Analysis. We experimented with simple neural architectures that gave competitive performance on certain tasks. This includes shallow CNN and Bi-Directional LSTM architectures with Facebook's Fasttext as a baseline model. Our best performing model was in the Top 5 systems using the Exact-Accuracy and Micro-Average-F1 metrics for the Spanish (85.28% for both) and French (70% and 73.17% respectively) task, and outperformed all the other models on comment (87.28%) and meaningless (51.85%) tags using Micro Average F1 by Tags metric for the French task.",2017,False,False,False,True,False,False,True,"D, G",257,3,260
W17-7510,Quantitative Characterization of Code Switching Patterns in Complex Multi-Party Conversations: A Case Study on {H}indi Movie Scripts,"In this paper, we present a framework for quantitative characterization of codeswitching patterns in multi-party conversations, which allows us to compare and contrast the socio-cultural and functional aspects of code-switching within a set of cultural contexts. Our method applies some of the proposed metrics for quantification of code-switching (Gamback and Das, 2016; Guzman et al., 2017) at the level of entire conversations, dyads and participants. We apply this technique to analyze the conversations from 18 recent Hindi movies. In the process, we are able to tease apart the use of code-switching as a device for establishing identity, sociocultural contexts of the characters and the events in a movie.",2017,False,False,False,False,True,False,True,"E,G",262,2,264
I17-3012,Automatic Difficulty Assessment for {C}hinese Texts,"We present a web-based interface that automatically assesses reading difficulty of Chinese texts. The system performs word segmentation, part-of-speech tagging and dependency parsing on the input text, and then determines the difficulty levels of the vocabulary items and grammatical constructions in the text. Furthermore, the system highlights the words and phrases that must be simplified or re-written in order to conform to the user-specified target difficulty level. Evaluation results show that the system accurately identifies the vocabulary level of 89.9% of the words, and detects grammar points at 0.79 precision and 0.83 recall.",2017,False,False,False,True,False,False,True,"G, D",236,3,239
W17-0237,"Word vectors, reuse, and replicability: Towards a community repository of large-text resources","This paper describes an emerging shared repository of large-text resources for creating word vectors, including pre-processed corpora and pre-trained vectors for a range of frameworks and configurations. This will facilitate reuse, rapid experimentation, and replicability of results.",2017,True,False,False,False,False,False,True,"A, G",166,3,169
D17-1214,Accurate Supervised and Semi-Supervised Machine Reading for Long Documents,"We introduce a hierarchical architecture for machine reading capable of extracting precise information from long documents. The model divides the document into small, overlapping windows and encodes all windows in parallel with an RNN. It then attends over these window encodings, reducing them to a single encoding, which is decoded into an answer using a sequence decoder. This hierarchical approach allows the model to scale to longer documents without increasing the number of sequential steps. In a supervised setting, our model achieves state of the art accuracy of 76.8 on the WikiReading dataset. We also evaluate the model in a semi-supervised setting by downsampling the WikiReading training set to create increasingly smaller amounts of supervision, while leaving the full unlabeled document corpus to train a sequence autoencoder on document windows. We evaluate models that can reuse autoencoder states and outputs without finetuning their weights, allowing for more efficient training and inference.",2017,False,True,False,True,False,False,False,"B, D",298,3,301
W17-1006,Ultra-Concise Multi-genre Summarisation of Web2.0: towards Intelligent Content Generation,"The electronic Word of Mouth has become the most powerful communication channel thanks to the wide usage of the Social Media. Our research proposes an approach towards the production of automatic ultraconcise summaries from multiple Web 2.0 sources. We exploit user-generated content from reviews and microblogs in different domains, and compile and analyse four types of ultra-concise summaries: a) positive information, b) negative information; c) both or d) objective information. The appropriateness and usefulness of our model is demonstrated by its successful results and great potential in real-life applications, thus meaning a relevant advancement of the state-of-the-art approaches.",2017,True,False,False,False,False,False,True,"A, G",245,3,248
D17-1273,Learning Fine-grained Relations from {C}hinese User Generated Categories,"User generated categories (UGCs) are short texts that reflect how people describe and organize entities, expressing rich semantic relations implicitly. While most methods on UGC relation extraction are based on pattern matching in English circumstances, learning relations from Chinese UGCs poses different challenges due to the flexibility of expressions. In this paper, we present a weakly supervised learning framework to harvest relations from Chinese UGCs. We identify is-a relations via word embedding based projection and inference, extract non-taxonomic relations and their category patterns by graph mining. We conduct experiments on Chinese Wikipedia and achieve high accuracy, outperforming state-of-the-art methods.",2017,True,False,False,True,False,False,False,"A, D",243,3,246
W17-5711,Ensemble and Reranking: Using Multiple Models in the {NICT}-2 Neural Machine Translation System at {WAT}2017,"In this paper, we describe the NICT-2 neural machine translation system evaluated at WAT2017. This system uses multiple models as an ensemble and combines models with opposite decoding directions by reranking (called bi-directional reranking). In our experimental results on small data sets, the translation quality improved when the number of models was increased to 32 in total and did not saturate. In the experiments on large data sets, improvements of 1.59-3.32 BLEU points were achieved when six-model ensembles were combined by the bi-directional reranking.",2017,False,False,False,True,False,False,True,"D, G",234,3,237
W17-5713,Comparison of {SMT} and {NMT} trained with large Patent Corpora: {J}apio at {WAT}2017,"Japan Patent Information Organization (Japio) participates in patent subtasks (JPC-EJ/JE/CJ/KJ) with phrase-based statistical machine translation (SMT) and neural machine translation (NMT) systems which are trained with its own patent corpora in addition to the subtask corpora provided by organizers of WAT2017. In EJ and CJ subtasks, SMT and NMT systems whose sizes of training corpora are about 50 million and 10 million sentence pairs respectively achieved comparable scores for automatic evaluations, but NMT systems were superior to SMT systems for both official and in-house human evaluations.",2017,False,False,False,True,False,False,True,"D, G",243,3,246
P17-1068,Beyond Binary Labels: Political Ideology Prediction of {T}witter Users,"Automatic political preference prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US. This study examines users' political ideology using a sevenpoint scale which enables us to identify politically moderate and neutral usersgroups which are of particular interest to political scientists and pollsters. Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the political groups of users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users. Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords. Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups.",2017,True,False,False,True,False,False,False,"A, D",273,3,276
D17-1251,Never Abandon Minorities: Exhaustive Extraction of Bursty Phrases on Microblogs Using Set Cover Problem,"We propose a language-independent datadriven method to exhaustively extract bursty phrases of arbitrary forms (e.g., phrases other than simple noun phrases) from microblogs. The burst (i.e., the rapid increase of the occurrence) of a phrase causes the burst of overlapping Ngrams including incomplete ones. In other words, bursty incomplete N-grams inevitably overlap bursty phrases. Thus, the proposed method performs the extraction of bursty phrases as the set cover problem in which all bursty N-grams are covered by a minimum set of bursty phrases. Experimental results using Japanese Twitter data showed that the proposed method outperformed word-based, noun phrase-based, and segmentation-based methods both in terms of accuracy and coverage.",2017,True,False,True,False,False,False,False,"A, C",263,3,266
E17-1116,"Aye or naw, whit dae ye hink? {S}cottish independence and linguistic identity on social media","Political surveys have indicated a relationship between a sense of Scottish identity and voting decisions in the 2014 Scottish Independence Referendum. Identity is often reflected in language use, suggesting the intuitive hypothesis that individuals who support Scottish independence are more likely to use distinctively Scottish words than those who oppose it. In the first large-scale study of sociolinguistic variation on social media in the UK, we identify distinctively Scottish terms in a data-driven way, and find that these terms are indeed used at a higher rate by users of pro-independence hashtags than by users of anti-independence hashtags. However, we also find that in general people are less likely to use distinctively Scottish words in tweets with referendum-related hashtags than in their general Twitter activity. We attribute this difference to style-shifting relative to audience, aligning with previous work showing that Twitter users tend to use fewer local variants when addressing a broader audience.",2017,False,False,False,False,True,False,True,"E,G",300,2,302
W17-6817,Comprehensive annotation of cross-linguistic variation in tense and aspect categories,"In this paper, we present part of a new, cross-linguistically valid annotation scheme for annotating tense and aspect information on a syntactic and semantic level, focussing on the category of tense. Primarily, the annotation maps morphosyntactic information to representations of eventualities. We specify mapping conventions which are represented as inference rules expressing language specific variations of the syntax/semantics interface. Eventualities are expressed in terms of a cluster of features whose values can each be mapped to a formal description based on insights from the tense and aspect semantics literature. The annotation is integrated into a broader effort of achieving cross-linguistically viable temporal annotation and combines recent efforts of bringing together computational and formal approaches to temporal semantics. This allows for an overall comprehensive representation of syntax, semantics and the syntax/semantics interface regarding tense and aspect. The annotation scheme is especially well suited for computational research seeking to understand and extract tense/aspect information across languages.",2017,True,False,False,False,True,False,False,"A, E",308,3,311
P17-1113,Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme,"Joint extraction of entities and relations is an important task in information extraction. To tackle this problem, we firstly propose a novel tagging scheme that can convert the joint extraction task to a tagging problem. Then, based on our tagging scheme, we study different end-toend models to extract entities and their relations directly, without identifying entities and relations separately. We conduct experiments on a public dataset produced by distant supervision method and the experimental results show that the tagging based methods are better than most of the existing pipelined and joint learning methods. What's more, the end-to-end model proposed in this paper, achieves the best results on the public dataset.",2017,False,True,False,True,False,False,False,"B, D",245,3,248
W17-6609,Processo de constru{\c{c}}{\~a}o de um corpus anotado com Entidades Geol{\'o}gicas visando {REN} (Building an annotated corpus with geological entities for {NER})[In {P}ortuguese],"This article presents the building process of GeoCorpus, developed for the Geology domain, more specifically for the Bacia Sedimentar Brasileira subarea. The annotation is focused on Geological Entities in Portuguese text, and aims at Named Entity Recognition in the proposed domain. A case study validated both the annotation process and a tool which supported the specialists in the identification and classification of Geological Entities. Resumo. Este artigo apresenta o processo de construc ¸ão do GeoCorpus, desenvolvido para o domínio de Geologia, mais especificamente, para a subárea Bacia Sedimentar Brasileira. A anotac ¸ão restringe-se às Entidades Geológicas contidas nos textos em Português e visa o Reconhecimento de Entidades Nomeadas no domínio proposto. Um estudo de caso validou o processo de anotac ¸ão desse corpus e de uma ferramenta que auxiliou os especialistas na identificac ¸ão e classificac ¸ão das Entidades Geológicas.",2017,True,False,False,False,False,False,True,"A, G",313,3,316
Y17-1018,{BTG}-based Machine Translation with Simple Reordering Model using Structured Perceptron,"In this paper, we present a novel statistical machine translation method which employs a BTG-based reordering model during decoding. BTG-based reordering models for preordering have been widely explored, aiming to improve the standard phrase-based statistical machine translation system. Less attention has been paid to incorporating such a reordering model into decoding directly. Our reordering model differs from previous models built using a syntactic parser or directly from annotated treebanks. Here, we train without using any syntactic information. The experiment results on an English-Japanese translation task show that our BTG-based decoder achieves comparable or better performance than the more complex state-of-the-art SMT decoders.",2017,False,True,True,False,False,False,False,"B, C",250,3,253
W17-3002,Constructive Language in News Comments,"We discuss the characteristics of constructive news comments, and present methods to identify them. First, we define the notion of constructiveness. Second, we annotate a corpus for constructiveness. Third, we explore whether available argumentation corpora can be useful to identify constructiveness in news comments. Our model trained on argumentation corpora achieves a top accuracy of 72.59% (baseline=49.44%) on our crowdannotated test data. Finally, we examine the relation between constructiveness and toxicity. In our crowd-annotated data, 21.42% of the non-constructive comments and 17.89% of the constructive comments are toxic, suggesting that non-constructive comments are not much more toxic than constructive comments.",2017,True,False,False,False,True,False,False,"A, E",269,3,272
P17-1067,{E}mo{N}et: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks,"Accurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding individuals and their lives. However, progress on emotion detection has been hampered by the absence of large labeled datasets. In this work, we build a very large dataset for fine-grained emotions and develop deep learning models on it. We achieve a new state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58%). We also extend the task beyond emotion types to model Robert Plutchik's 8 primary emotion dimensions, acquiring a superior accuracy of 95.68%.",2017,True,True,False,False,False,False,False,"A, B",242,3,245
O17-3002,語音文件檢索使用類神經網路技術 (On the Use of Neural Network Modeling Techniques for Spoken Document Retrieval) [In {C}hinese],"Due to ever-increasing amounts of publicly available multimedia associated with speech information, spoken document retrieval (SDR) has been an active area of research that captures significant interest from both academic and industrial communities. Beyond the continuing effort in the development of robust indexing and effective retrieval methods to quantify the relevance degree between a pair of query and spoken document, how to accurately and efficiently model the query content plays a vital role for improving SDR performance. In view of this, we present in this paper a novel neural relevance-aware model (NRM) to infer an enhanced query representation, extricating the conventional time-consuming pseudo-relevance feedback (PRF) process. In addition, we incorporate the notion of query intent classification into our proposed NRM modeling framework to obtain more sophisticated query representations. Preliminary experiments conducted on the TDT-2 collection confirm the utility of our methods in relation to a few state-of-the-art ones.",2017,False,True,False,True,False,False,False,"B, D",299,3,302
W17-4405,Constructing an Alias List for Named Entities during an Event,"In certain fields, real-time knowledge from events can help in making informed decisions. In order to extract pertinent realtime knowledge related to an event, it is important to identify the named entities and their corresponding aliases related to the event. The problem of identifying aliases of named entities that spike has remained unexplored. In this paper, we introduce an algorithm, EntitySpike, that identifies entities that spike in popularity in tweets from a given time period, and constructs an alias list for these spiked entities. EntitySpike uses a temporal heuristic to identify named entities with similar context that occur in the same time period (within minutes) during an event. Each entity is encoded as a vector using this temporal heuristic. We show how these entityvectors can be used to create a named entity alias list. We evaluated our algorithm on a dataset of temporally ordered tweets from a single event, the 2013 Grammy Awards show. We carried out various experiments on tweets that were published in the same time period and show that our algorithm identifies most entity name aliases and outperforms a competitive baseline.",2017,True,False,True,False,False,False,False,"A, C",331,3,334
W17-5027,A Shallow Neural Network for Native Language Identification with Character N-grams,This paper describes the systems submitted by GadjahMada team to the Native Language Identification (NLI) Shared Task 2017. Our models used a continuous representation of character n-grams which are learned jointly with feed-forward neural network classifier. Character n-grams have been proved to be effective for stylebased identification tasks including NLI. Results on the test set demonstrate that the proposed model performs very well on essay and fusion tracks by obtaining more than 0.8 on both F-macro score and accuracy.,2017,False,True,False,True,False,False,False,"B, D",222,3,225
D17-2006,{S}tru{AP}: A Tool for Bundling Linguistic Trees through Structure-based Abstract Pattern,"We present a tool for developing tree structure patterns that makes it easy to define the relations among textual phrases and create a search index for these newly defined relations. By using the proposed tool, users develop tree structure patterns through abstracting syntax trees. The tool features (1) intuitive pattern syntax, (2) unique functions such as recursive call of patterns and lexicon reference, and (3) whole workflow support for relation development and validation. We report the current implementation of the tool and its effectiveness.",2017,False,False,False,True,False,False,True,"D, G",217,3,220
D17-1307,No Need to Pay Attention: Simple Recurrent Neural Networks Work!,"First-order factoid question answering assumes that the question can be answered by a single fact in a knowledge base (KB). While this does not seem like a challenging task, many recent attempts that apply either complex linguistic reasoning or deep neural networks achieve 65%-76% accuracy on benchmark sets. Our approach formulates the task as two machine learning problems: detecting the entities in the question, and classifying the question as one of the relation types in the KB. We train a recurrent neural network to solve each problem. On the SimpleQuestions dataset, our approach yields substantial improvements over previously published results -even neural networks based on much more complex architectures. The simplicity of our approach also has practical advantages, such as efficiency and modularity, that are valuable especially in an industry setting. In fact, we present a preliminary analysis of the performance of our model on real queries from Comcast's X1 entertainment platform with millions of users every day.",2017,False,False,False,True,False,False,True,"D, G",304,3,307
E17-1095,Exploring Convolutional Neural Networks for Sentiment Analysis of {S}panish tweets,"Spanish is the third-most used language on the Internet, after English and Chinese, with a total of 7.7% of Internet users (more than 277 million of users) and a huge users growth of more than 1,400%. However, most work on sentiment analysis has focused on English. This paper describes a deep learning system for Spanish sentiment analysis. To the best of our knowledge, this is the first work that explores the use of a convolutional neural network to polarity classification of Spanish tweets.",2017,False,True,False,False,False,False,True,"B, G",221,3,224
S17-1008,Deep Active Learning for Dialogue Generation,"We propose an online, end-to-end, neural generative conversational model for opendomain dialogue. It is trained using a unique combination of offline two-phase supervised learning and online human-inthe-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on hamming-diverse beam search for response generation and one-character userfeedback at each step. Experiments show that our model inherently promotes the generation of semantically relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles.",2017,False,True,True,False,False,False,False,"B, C",237,3,240
Q17-1024,{G}oogle{'}s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,"We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT'14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German. Similarly, a single multilingual model surpasses stateof-the-art results for French→English and German→English on WMT'14 and WMT'15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zeroshot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.",2017,False,False,False,True,False,True,False,"D, F",345,3,348
W17-6916,Situating Word Senses in their Historical Context with Linked Data,"In this article we present a Semantic Web-based model for creating lexical resources in which the diachronic and, more broadly, contextual dimensions of word meaning can be explicitly represented as part of a graph-based data structure. We start by discussing why Linked Data is the right publishing approach for such diachronic datasets. We then describe our model, lemonEty, which utilizes the ontology engineering technique of perdurants in order to model lexical entries as dynamic processes. Next we go onto explain how to represent etymologies using our model, and in particular how to associate temporal information with word senses, taking examples from two different lexicographic resources. In addition, we will show how our model deals with cognates and attestations.",2017,True,True,False,False,False,False,False,"A, B",264,3,267
W17-0402,{S}wedish Prepositions are not Pure Function Words,"As for any categorial scheme used for annotation, UD abound with borderline cases. The main instruments to resolve them are the UD design principles and, of course, the linguistic facts of the matter. UD makes a fundamental distinction between content words and function words, and a, perhaps less fundamental, distinction between pure function words and the rest. It has been suggested that adpositions are to be included among the pure function words. In this paper I discuss the case of prepositions in Swedish and related languages in the light of these distinctions. It relates to a more general problem: How should we resolve cases where the linguistic intuitions and UD design principles are in conflict?",2017,False,False,False,False,True,True,False,"E,F",250,2,252
