acl_id,title,abstract,year,A,B,C,D,E,F,G,raw_response,input_tokens,output_tokens,total_tokens
U13-1021,e-Learning with {K}aggle in Class: Adapting the {ALTA} Shared Task 2013 to a Class Project,"The 2013 ALTA Shared Task was utilised as a class project for a subject taught at The University of Melbourne in the second semester of 2013. This paper reviews the experience of using an on-line, Kaggle in Class-based shared task for class work. Adoption of the shared task enables a blended learning paradigm that engages students in problem-based learning in a shared and open context.",2013,False,False,False,True,False,False,True,"G, D",196,3,199
R13-2017,{K}orean Word-Sense Disambiguation Using Parallel Corpus as Additional Resource,"Most previous research on Korean Word-Sense Disambiguation (WSD) were focusing on unsupervised corpus-based or knowledge-based approach because they suffered from lack of sense-tagged Korean corpora.Recently, along with great effort of constructing sense-tagged Korean corpus by government and researchers, finding appropriate features for supervised learning approach and improving its prediction accuracy became an issue. To achieve higher word-sense prediction accuracy, this paper aimed to find most appropriate features for Korean WSD based on Conditional Random Field (CRF) approach. Also, we utilized Korean-Japanese parallel corpus to enlarge size of sensetagged corpus, and improved prediction accuracy with it. Experimental result reveals that our method can achieve 95.67% of prediction accuracy.",2013,False,False,False,True,False,False,True,"D, G",267,3,270
P13-1055,Identifying Bad Semantic Neighbors for Improving Distributional Thesauri,"Distributional thesauri are now widely used in a large number of Natural Language Processing tasks. However, they are far from containing only interesting semantic relations. As a consequence, improving such thesaurus is an important issue that is mainly tackled indirectly through the improvement of semantic similarity measures. In this article, we propose a more direct approach focusing on the identification of the neighbors of a thesaurus entry that are not semantically linked to this entry. This identification relies on a discriminative classifier trained from unsupervised selected examples for building a distributional model of the entry in texts. Its bad neighbors are found by applying this classifier to a representative set of occurrences of each of these neighbors. We evaluate the interest of this method for a large set of English nouns with various frequencies.",2013,False,False,False,True,True,False,False,"D, E",271,3,274
P13-2075,Minimum {B}ayes Risk based Answer Re-ranking for Question Answering,"This paper presents two minimum Bayes risk (MBR) based Answer Re-ranking (MBRAR) approaches for the question answering (QA) task. The first approach re-ranks single QA system's outputs by using a traditional MBR model, by measuring correlations between answer candidates; while the second approach reranks the combined outputs of multiple QA systems with heterogenous answer extraction components by using a mixture model-based MBR model. Evaluations are performed on factoid questions selected from two different domains: Jeopardy! and Web, and significant improvements are achieved on all data sets.",2013,False,False,False,True,False,False,True,"D, G",234,3,237
S13-2001,"{S}em{E}val-2013 Task 1: {T}emp{E}val-3: Evaluating Time Expressions, Events, and Temporal Relations","Within the SemEval-2013 evaluation exercise, the TempEval-3 shared task aims to advance research on temporal information processing. It follows on from TempEval-1 and -2, with: a three-part structure covering temporal expression, event, and temporal relation extraction; a larger dataset; and new single measures to rank systems -in each task and in general. In this paper, we describe the participants' approaches, results, and the observations from the results, which may guide future research in this area.",2013,True,False,False,False,True,False,False,"A, E",221,3,224
S13-2002,{C}lear{TK}-{T}ime{ML}: A minimalist approach to {T}emp{E}val 2013,"The ClearTK-TimeML submission to Temp-Eval 2013 competed in all English tasks: identifying events, identifying times, and identifying temporal relations. The system is a pipeline of machine-learning models, each with a small set of features from a simple morpho-syntactic annotation pipeline, and where temporal relations are only predicted for a small set of syntactic constructions and relation types. ClearTK-TimeML ranked 1 st for temporal relation F1, time extent strict F1 and event tense accuracy.",2013,False,False,False,True,False,False,True,"D, G",219,3,222
W13-2713,The (Un)faithful Machine Translator,"Applying machine translation (MT) to literary texts involves the same domain shift challenges that arise for any sublanguage (e.g. medical or scientific). However, it also introduces additional challenges. One focus in the discussion of translation theory in the humanities has been on the human translator's role in staying faithful to an original text versus adapting it to make it more familiar to readers. In contrast to other domains, one objective in literary translation is to preserve the experience of reading a text when moving to the target language. We use existing MT systems to translate samples of French literature into English. We then use qualitative analysis grounded in translation theory and real example outputs in order to address what makes literary translation particularly hard and the potential role of the machine in it.",2013,False,False,False,False,True,False,True,"E, G",266,3,269
W13-2903,The {C}-Score {--} Proposing a Reading Comprehension Metrics as a Common Evaluation Measure for Text Simplification,"This article addresses the lack of common approaches for text simplification evaluation, by presenting the first attempt for a common evaluation metrics. The article proposes reading comprehension evaluation as a method for evaluating the results of Text Simplification (TS). An experiment, as an example application of the evaluation method, as well as three formulae to quantify reading comprehension, are presented. The formulae produce an unique score, the C-score, which gives an estimation of user's reading comprehension of a certain text. The score can be used to evaluate the performance of a text simplification engine on pairs of complex and simplified texts, or to compare the performances of different TS methods using the same texts. The approach can be particularly useful for the modern crowdsourcing approaches, such as those employing the Amazon's Mechanical Turk 1 or CrowdFlower 2 . The aim of this paper is thus to propose an evaluation approach and to motivate the TS community to start a relevant discussion, in order to come up with a common evaluation metrics for this task.",2013,True,False,False,True,False,False,False,"A, D",319,3,322
P13-2148,Identifying Sentiment Words Using an Optimization-based Model without Seed Words,"Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.",2013,False,True,False,True,False,False,False,"B, D",206,3,209
P13-2078,Measuring semantic content in distributional vectors,"Some words are more contentful than others: for instance, make is intuitively more general than produce and fifteen is more 'precise' than a group. In this paper, we propose to measure the 'semantic content' of lexical items, as modelled by distributional representations. We investigate the hypothesis that semantic content can be computed using the Kullback-Leibler (KL) divergence, an informationtheoretic measure of the relative entropy of two distributions. In a task focusing on retrieving the correct ordering of hyponym-hypernym pairs, the KL divergence achieves close to 80% precision but does not outperform a simpler (linguistically unmotivated) frequency measure. We suggest that this result illustrates the rather 'intensional' aspect of distributions.",2013,False,False,True,False,True,False,False,"C, E",273,3,276
2013.mtsummit-european.21,"trans{L}ectures: Transcription and Translation of Video Lectures {TTC}: Terminology Extraction, Translation Tools and Comparable Corpora","Online repositories of video lectures are a rapidly growing feature of the Internet. One example is VideoLectures.NET, a free and open access educational video repository with more than 17,000 video objects at present count. Transcription and translation of these video lectures is needed to make them accessible to a wider audience. However, as with many other repositories, most of the lectures on this site are neither transcribed nor translated.",2013,True,False,False,False,False,False,True,"G, A",202,3,205
I13-1194,An Empirical Assessment of Contemporary Online Media in Ad-Hoc Corpus Creation for Social Events,"Social networking sites such as Facebook and Twitter have become favorite portals for users to discuss and express opinions. Research shows that topical discussions around events tend to evolve socially on microblogs. However, sources like Twitter have no explicit discussion thread which will link semantically similar posts. Moreover, the discussion may be evolving in multiple different threads (like Facebook). Researchers have proposed the use of online contemporary documents to act as external corpus to connect pairs of contextually related semantic topics. This motivates the question: given a significant social event, what is a good choice of external corpus to identify evolution of discussion topics around the event's context? In this work, we compare the effectiveness of contemporary blog posts, online news media and forum discussions in creating adhoc external corpus. Using social propensity of evolution of topical discussions on Twitter to assess the goodness of the creation, we find online news media as most effective. We evaluate on three large reallife Twitter datasets to affirm our findings.",2013,False,False,False,False,True,False,True,"E, G",309,3,312
D13-1004,Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech,"Children learn various levels of linguistic structure concurrently, yet most existing models of language acquisition deal with only a single level of structure, implicitly assuming a sequential learning process. Developing models that learn multiple levels simultaneously can provide important insights into how these levels might interact synergistically during learning. Here, we present a model that jointly induces syntactic categories and morphological segmentations by combining two well-known models for the individual tasks. We test on child-directed utterances in English and Spanish and compare to single-task baselines. In the morphologically poorer language (English), the model improves morphological segmentation, while in the morphologically richer language (Spanish), it leads to better syntactic categorization. These results provide further evidence that joint learning is useful, but also suggest that the benefits may be different for typologically different languages.",2013,False,False,False,True,True,False,False,"D,E",278,2,280
W13-5407,Expanding {V}erb{N}et with {S}ketch {E}ngine,"This research describes efforts to expand the lexical resource VerbNet with additional class members and completely new verb classes. Several approaches to this in the past have involved automatic methods for expansion, but this research focuses on the addition of frequent, yet particularly challenging verbs that require manual additions after a survey of each verb's syntactic behaviors and semantic features. Sketch Engine has been an invaluable tool in this process, allowing for a comprehensive, yet detailed view of the behavior of a given verb, along with efficient comparisons to the behaviors of other verbs that might be included in VerbNet already. The incorporation of light verbs into VerbNet has presented particular challenges to this process, these are described along with a proposed resource to supplement VerbNet with information on light verbs. Sketch Engine's (Kilgarriff et al., 2004 ) Word Sketch and Thesaurus functions were found to be extremely helpful in the process of considering these verbs for addition, because these resources give a detailed snapshot of syntactic and collocational tendencies. Particularly difficult cases for addition are those where common, polysemous verbs are used in their 'light' sense while combining with another predicating element; for example, Jessica made an offer to buy the house. These cases are especially problematic for VN to account for because the structure of the lexicon assumes that the verb is the primary predicating element. The steps and challenges of these additions are discussed in turn. The overall successes of this expansion demonstrate the value of utilizing both the complementary lexical resources included in SemLink, as well as Sketch Engine.",2013,True,False,False,False,True,False,False,"A, E",428,3,431
W13-4205,Modeling the Helpful Opinion Mining of Online Consumer Reviews as a Classification Problem,"The paper aims to address an opinion mining problem: to find the helpful reviews from online consumer reviews before mining the detail. This task can benefit both the consumers and the companies. Consumers can read only the helpful opinions from helpful reviews before they purchase a product, while the companies can acquire the true reason why one product is liked or hated. A system is built to assess the difficulty of the problem. The experiment results show that helpful reviews can be identified with high precision from unhelpful ones.",2013,True,False,False,False,False,False,True,"A, G",216,3,219
W13-4051,Open-domain Utterance Generation for Conversational Dialogue Systems using Web-scale Dependency Structures,"Even though open-domain conversational dialogue systems are required in many fields, their development is complicated because of the flexibility and variety of user utterances. To address this flexibility, previous research on conversational dialogue systems has selected system utterances from web articles based on surface cohesion and shallow semantic coherence; however, the generated utterances sometimes contain irrelevant sentences with respect to the input user utterance. We propose a template-based approach that fills templates with the most salient words in a user utterance and with related words that are extracted using web-scale dependency structures gathered from Twitter. Our open-domain conversational dialogue system outperforms retrieval-based conventional systems in chat experiments.",2013,False,True,False,True,False,False,False,"B, D",245,3,248
W13-4071,Dialog State Tracking using Conditional Random Fields,"This paper presents our approach to dialog state tracking for the Dialog State Tracking Challenge task. In our approach we use discriminative general structured conditional random fields, instead of traditional generative directed graphic models, to incorporate arbitrary overlapping features. Our approach outperforms the simple 1-best tracking approach.",2013,False,True,False,True,False,False,False,"B, D",176,3,179
Y13-1011,Towards a Revised Motor Theory of {L}2 Speech Perception,"This study aims to review, through experiment proof of a salient effect of articulatory gestures on L2 perception, the time-honored but still put-to-sideways motor theory of speech perception. On one",2013,False,False,False,False,True,True,False,"E,F",160,2,162
W13-2104,Enhancing the Expression of Contrast in the {SP}a{RK}y Restaurant Corpus,"We show that Nakatsu & White's (2010) proposed enhancements to the SPaRKy Restaurant Corpus (SRC; Walker et al., 2007) for better expressing contrast do indeed make it possible to generate better texts, including ones that make effective and varied use of contrastive connectives and discourse adverbials. After first presenting a validation experiment for naturalness ratings of SRC texts gathered using Amazon's Mechanical Turk, we present an initial experiment suggesting that such ratings can be used to train a realization ranker that enables higher-rated texts to be selected when the ranker is trained on a sample of generated restaurant recommendations with the contrast enhancements than without them. We conclude with a discussion of possible ways of improving the ranker in future work.",2013,False,False,False,True,False,True,False,"D, F",268,3,271
W13-0108,Generating Natural Language from Linked Data: Unsupervised template extraction,"We propose an architecture for generating natural language from Linked Data that automatically learns sentence templates and statistical document planning from parallel RDF datasets and text. We have built a proof-of-concept system (LOD-DEF) trained on un-annotated text from the Simple English Wikipedia and RDF triples from DBpedia, focusing exclusively on factual, non-temporal information. The goal of the system is to generate short descriptions, equivalent to Wikipedia stubs, of entities found in Linked Datasets. We have evaluated the LOD-DEF system against a simple generate-from-triples baseline and human-generated output. In evaluation by humans, LOD-DEF significantly outperforms the baseline on two of three measures: non-redundancy and structure and coherence. 1 http://www.w3.org/TR/owl2-overview/ 2 We describe RDF in more detail in the next section 3 See http://museum-api.pbworks.com for many examples. 4",2013,False,True,False,False,False,False,True,"B, G",309,3,312
W13-1703,Building a Large Annotated Corpus of Learner {E}nglish: The {NUS} Corpus of Learner {E}nglish,"We describe the NUS Corpus of Learner English (NUCLE), a large, fully annotated corpus of learner English that is freely available for research purposes. The goal of the corpus is to provide a large data resource for the development and evaluation of grammatical error correction systems. Although NUCLE has been available for almost two years, there has been no reference paper that describes the corpus in detail. In this paper, we address this need. We describe the annotation schema and the data collection and annotation process of NUCLE. Most importantly, we report on an unpublished study of annotator agreement for grammatical error correction. Finally, we present statistics on the distribution of grammatical errors in the NUCLE corpus.",2013,True,False,False,False,True,False,False,"A, E",259,3,262
W13-2124,{G}en{N}ext: A Consolidated Domain Adaptable {NLG} System,"We introduce GenNext, an NLG system designed specifically to adapt quickly and easily to different domains. Given a domain corpus of historical texts, GenNext allows the user to generate a template bank organized by semantic concept via derived discourse representation structures in conjunction with general and domain-specific entity tags. Based on various features collected from the training corpus, the system statistically learns template representations and document structure and produces well-formed texts (as evaluated by crowdsourced and expert evaluations). In addition to domain adaptation, Gen-Next's hybrid approach significantly reduces complexity as compared to traditional NLG systems by relying on templates (consolidating micro-planning and surface realization) and minimizing the need for domain experts. In this description, we provide details of GenNext's theoretical perspective, architecture and evaluations of output.",2013,False,True,False,True,False,False,False,"B, D",275,3,278
W13-4826,"Corpus-amostra Coelho Netto: compila{\c{c}}{\~a}o, anota{\c{c}}{\~a}o e ocorr{\^e}ncias em textos liter{\'a}rios dos s{\'e}c. {XIX} e {XX} (Corpus-sample Coelho Netto: Compilation, Annotation and Occurrences in Literary Texts from {XIX} and {XX} Centuries) [in {P}ortuguese]","This paper presents doctoral thesis in progress of formation of corpus-sample Coelho Netto, a corpus compiled, annotated and analyzed morphosyntactically occurrences and opulence of verbs, adjectives and adverbs in-ly compared the texts of the same period, as well as observation the accuracy of automatic labeler Aelius (free software in Python), model Hunpos, trained at Corpus of Historical Portuguese Tycho Brahe (CHPTB) in literary texts by this author: two novels and three short stories of the period between the end of the 19th century and early 20th century. The Corpus is approximately forty-seven thousand tokens (words and punctuations). Resumo. Este trabalho apresenta a tese de doutoramento em andamento da constituição do corpus-amostra Coelho Netto, um corpus compilado, anotado morfossintaticamente e analisadas as ocorrências e opulência de verbos, adjetivos e advérbios em -mente em comparação a textos do mesmo período, além de observação da acurácia do etiquetador automático Aelius (software livre em Python), modelo Hunpos, treinado no Corpus Histórico do Português Tycho Brahe (CHPTB) em textos literários desse autor: dois romances e três contos do período entre final do século XIX e início do século XX. O Corpus tem aproximadamente quarenta e sete mil tokens (palavras e pontuações).",2013,True,False,False,False,True,False,False,"A, E",408,3,411
W13-2003,{TEES} 2.1: Automated Annotation Scheme Learning in the {B}io{NLP} 2013 Shared Task,"We participate in the BioNLP 2013 Shared Task with Turku Event Extraction System (TEES) version 2.1. TEES is a support vector machine (SVM) based text mining system for the extraction of events and relations from natural language texts. In version 2.1 we introduce an automated annotation scheme learning system, which derives task-specific event rules and constraints from the training data, and uses these to automatically adapt the system for new corpora with no additional programming required. TEES 2.1 is shown to have good generalizability and good performance across the BioNLP 2013 task corpora, achieving first place in four out of eight tasks.",2013,False,True,False,True,False,False,False,"B, D",258,3,261
W13-4034,Learning Dialogue Management Models for Task-Oriented Dialogue with Parallel Dialogue and Task Streams,"Learning dialogue management models poses significant challenges. In a complex taskoriented domain in which information is exchanged via parallel, interleaved dialogue and task streams, effective dialogue management models should be able to make dialogue moves based on both the dialogue and the task context. This paper presents a data-driven approach to learning dialogue management models that determine when to make dialogue moves to assist users' task completion activities, as well as the type of dialogue move that should be selected for a given user interaction context. Combining features automatically extracted from the dialogue and the task, we compare two alternate modeling approaches. The results of an evaluation indicate the learned models are effective in predicting both the timing and the type of system dialogue moves.",2013,False,False,False,True,False,False,True,"D, G",258,3,261
S13-1025,{DLS}@{CU}-{CORE}: A Simple Machine Learning Model of Semantic Textual Similarity,"We present a system submitted in the Semantic Textual Similarity (STS) task at the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013). Given two short text fragments, the goal of the system is to determine their semantic similarity. Our system makes use of three different measures of text similarity: word n-gram overlap, character n-gram overlap and semantic overlap. Using these measures as features, it trains a support vector regression model on SemEval STS 2012 data. This model is then applied on the STS 2013 data to compute textual similarities. Two different selections of training data result in very different performance levels: while a correlation of 0.4135 with gold standards was observed in the official evaluation (ranked 63 rd among all systems) for one selection, the other resulted in a correlation of 0.5352 (that would rank 21 st ).",2013,False,False,False,True,False,False,True,"D, G",303,3,306
R13-1023,Effective Spell Checking Methods Using Clustering Algorithms,"This paper presents a novel approach to spell checking using dictionary clustering. The main goal is to reduce the number of times distances have to be calculated when finding target words for misspellings. The method is unsupervised and combines the application of anomalous pattern initialization and partition around medoids (PAM). To evaluate the method, we used an English misspelling list compiled using real examples extracted from the Birkbeck spelling error corpus.",2013,False,False,True,False,False,False,True,"C, G",206,3,209
R13-1073,Information Spreading in Expanding {W}ordnet Hypernymy Structure,"The paper presents a wordnet expansion algorithm, which is based on lexicosemantic relations extracted from large text corpora. We do not assume that the extracted relation instances (i.e. word pairs) are described by probabilities. Thus, results produced by any method, including pattern-based and Distributional Semantics approaches can be used. The algorithm is based on a general spreading activation model. Support for word-to-word semantic associations is first mapped on the existing wordnet structure. Next, the support is spread over the wordnet network in order to find attachment areas for a new word. Evaluation and comparison with other approaches in experiments on Princeton WordNet 3.0 is presented.",2013,False,False,True,True,False,False,False,"C, D",255,3,258
W13-2242,Referential Translation Machines for Quality Estimation,"We introduce referential translation machines (RTM) for quality estimation of translation outputs. RTMs are a computational model for identifying the translation acts between any two data sets with respect to a reference corpus selected in the same domain, which can be used for estimating the quality of translation outputs, judging the semantic similarity between text, and evaluating the quality of student answers. RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality. RTMs remove the need to access any SMT system specific information or prior knowledge of the training data or models used when generating the translations. We develop novel techniques for solving all subtasks in the WMT13 quality estimation (QE) task (QET 2013) based on individual RTM models. Our results achieve improvements over last year's QE task results (QET 2012), as well as our previous results, provide new features and techniques for QE, and rank 1st or 2nd in all of the subtasks.",2013,False,True,False,True,False,False,False,"B, D",328,3,331
D13-1069,Automatically Determining a Proper Length for Multi-Document Summarization: A {B}ayesian Nonparametric Approach,"Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ""reconstruction"" by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.",2013,False,True,True,False,False,False,False,"B, C",307,3,310
W13-1905,Corpus-Driven Terminology Development: Populating {S}wedish {SNOMED} {CT} with Synonyms Extracted from Electronic Health Records,"The various ways in which one can refer to the same clinical concept needs to be accounted for in a semantic resource such as SNOMED CT. Developing terminological resources manually is, however, prohibitively expensive and likely to result in low coverage, especially given the high variability of language use in clinical text. To support this process, distributional methods can be employed in conjunction with a large corpus of electronic health records to extract synonym candidates for clinical terms. In this paper, we exemplify the potential of our proposed method using the Swedish version of SNOMED CT, which currently lacks synonyms. A medical expert inspects two thousand term pairs generated by two semantic spacesone of which models multiword terms in addition to single words -for one hundred preferred terms of the semantic types disorder and finding.",2013,False,False,False,True,False,False,True,"D, G",276,3,279
N13-2006,Ontology Label Translation,"Our research investigates the translation of ontology labels, which has applications in multilingual knowledge access. Ontologies are often defined only in one language, mostly English. To enable knowledge access across languages, such monolingual ontologies need to be translated into other languages. The primary challenge in ontology label translation is the lack of context, which makes this task rather different than document translation. The core objective therefore, is to provide statistical machine translation (SMT) systems with additional context information. In our approach, we first extend standard SMT by enhancing a translation model with context information that keeps track of surrounding words for each translation. We compute a semantic similarity between the phrase pair context vector from the parallel corpus and a vector of noun phrases that occur in surrounding ontology labels. We applied our approach to the translation of a financial ontology, translating from English to German, using Europarl as parallel corpus. This experiment showed that our approach can provide a slight improvement over standard SMT for this task, without exploiting any additional domain-specific resources.",2013,False,False,False,True,False,False,True,"D, G",320,3,323
N13-1038,Minibatch and Parallelization for Online Large Margin Structured Learning,"Online learning algorithms such as perceptron and MIRA have become popular for many NLP tasks thanks to their simpler architecture and faster convergence over batch learning methods. However, while batch learning such as CRF is easily parallelizable, online learning is much harder to parallelize: previous efforts often witness a decrease in the converged accuracy, and the speedup is typically very small (∼3) even with many (10+) processors. We instead present a much simpler architecture based on ""mini-batches"", which is trivially parallelizable. We show that, unlike previous methods, minibatch learning (in serial mode) actually improves the converged accuracy for both perceptron and MIRA learning, and when combined with simple parallelization, minibatch leads to very significant speedups (up to 9x on 12 processors) on stateof-the-art parsing and tagging systems.",2013,False,True,False,True,False,False,False,"B, D",295,3,298
W13-2240,Selecting Feature Sets for Comparative and Time-Oriented Quality Estimation of Machine Translation Output,"This paper describes a set of experiments on two sub-tasks of Quality Estimation of Machine Translation (MT) output. Sentence-level ranking of alternative MT outputs is done with pairwise classifiers using Logistic Regression with blackbox features originating from PCFG Parsing, language models and various counts. Post-editing time prediction uses regression models, additionally fed with new elaborate features from the Statistical MT decoding process. These seem to be better indicators of post-editing time than blackbox features. Prior to training the models, feature scoring with ReliefF and Information Gain is used to choose feature sets of decent size and avoid computational complexity.",2013,False,False,False,True,False,False,True,"D, G",240,3,243
W13-3521,Exploiting multiple hypotheses for Multilingual Spoken Language Understanding,"In this work, we present an approach for multilingual portability of Spoken Language Understanding systems. The goal of this approach is to avoid the effort of acquiring and labeling new corpora to learn models when changing the language. The work presented in this paper is focused on the learning of a specific translator for the task and the mechanism of transmitting the information among the modules by means of graphs. These graphs represent a set of hypotheses (a language) that is the input to the statistical semantic decoder that provides the meaning of the sentence. Some experiments in a Spanish task evaluated with input French utterances and text are presented. They show the good behavior of the system, mainly when speech input is considered.",2013,False,False,False,True,False,False,True,"D, G",254,3,257
W13-2231,Coping with the Subjectivity of Human Judgements in {MT} Quality Estimation,"Supervised approaches to NLP tasks rely on high-quality data annotations, which typically result from expensive manual labelling procedures. For some tasks, however, the subjectivity of human judgements might reduce the usefulness of the annotation for real-world applications. In Machine Translation (MT) Quality Estimation (QE), for instance, using humanannotated data to train a binary classifier that discriminates between good (useful for a post-editor) and bad translations is not trivial. Focusing on this binary task, we show that subjective human judgements can be effectively replaced with an automatic annotation procedure. To this aim, we compare binary classifiers trained on different data: the human-annotated dataset from the 7 th Workshop on Statistical Machine Translation (WMT-12), and an automatically labelled version of the same corpus. Our results show that human labels are less suitable for the task.",2013,False,False,False,False,True,False,True,"E, G",293,3,296
F13-2007,"{ANCOR}, the first large {F}rench speaking corpus of conversational speech annotated in coreference to be freely available ({ANCOR}, premier corpus de fran{\c{c}}ais parl{\'e} d{'}envergure annot{\'e} en cor{\'e}f{\'e}rence et distribu{\'e} librement) [in {F}rench]","%&'()*+,*)'-.)(/0'1*'2)3453,0'(3)67' 18*49*):/)*'344.;7'*4'-.)727)*4-*'*;'1,0;),</7' 6,<)*+*4;' =/1,;>'?/@*)*66* A &'!43B0'C*2*/9)* D &'=*34EF9*0'!4;.,4* D &'G++34/*6'H->34: A &'I*4,0'''''' ?3/)*6 D &'=*344*'J,6634*3/ K &'L),0'G0>M.6 A ' ' NAO'CCC'$)67340&'P4,9*)0,;7'18$)67340' NDO'P4,9*)0,;7'Q)345.,0'%3<*63,0'R./)0&'CL&'K'(63-*'=*34'=3/)S0&'TAUUU'V6.,0' 'NKO'L%LH!&'P4,9*)0,;7'G/).(7*44*'1*'V)*;3:4*&'WXAUU'C.),*4;'",2013,True,False,False,False,False,False,True,"A, G",405,3,408
W13-0105,Sentiment Composition Using a Parabolic Model,"In this paper, we propose a computational model that accounts for the effects of negation and modality on opinion expressions. Based on linguistic experiments informed by native speakers, we distil these effects according to the type of modality and negation. The model relies on a parabolic representation where an opinion expression is represented as a point on a parabola. Negation is modelled as functions over this parabola whereas modality through a family of parabolas of different slopes; each slope corresponds to a different certainty degree. The model is evaluated using two experiments, one involving direct strength judgements on a 7-point scale and the other relying on a sentiment annotated corpus. The empirical evaluation of our model shows that it matches the way humans handle negation and modality in opinionated sentences.",2013,False,True,True,False,False,False,False,"B, C",273,3,276
W13-2905,Text Modification for {B}ulgarian {S}ign {L}anguage Users,"The paper discusses the main issues regarding the reading skills and comprehension proficiency in written Bulgarian of people with communication difficulties, and deaf people, in particular. We consider several key components of text comprehension which pose a challenge for deaf readers and propose a rule-based system for automatic modification of Bulgarian texts intended to facilitate comprehension by deaf people, to assist education, etc. In order to demonstrate the benefits of such a system and to evaluate its performance, we have carried out a study among a group of deaf people who use Bulgarian Sign Language (BulSL) as their primary language (primary BulSL users), which compares the comprehensibility of original texts and their modified versions. The results shows a considerable improvement in readability when using modified texts, but at the same time demonstrates that the level of comprehension is still low, and that a complex set of modifications will have to be implemented to attain satisfactory results.",2013,False,False,False,True,False,False,True,"D, G",294,3,297
N13-1096,Measuring the Structural Importance through Rhetorical Structure Index,"In this paper, we propose a novel Rhetorical Structure Index (RSI) to measure the structural importance of a word or a phrase. Unlike TF-IDF and other content-driven measurements, RSI identifies words or phrases that are structural cues in an unstructured document. We show structurally motivated features with high RSI values are more useful than content-driven features for applications such as segmenting unstructured lecture transcripts into meaningful segments. Experiments show that using RSI significantly improves the segmentation accuracy compared to TF-IDF, a traditional content-based feature weighting scheme.",2013,True,False,False,True,False,False,False,"A, D",228,3,231
D13-1006,{A}nimacy Detection with Voting Models,"Animacy detection is a problem whose solution has been shown to be beneficial for a number of syntactic and semantic tasks. We present a state-of-the-art system for this task which uses a number of simple classifiers with heterogeneous data sources in a voting scheme. We show how this framework can give us direct insight into the behavior of the system, allowing us to more easily diagnose sources of error.",2013,False,False,False,True,False,True,False,"D, F",196,3,199
P13-2112,Simpler unsupervised {POS} tagging with bilingual projections,"We present an unsupervised approach to part-of-speech tagging based on projections of tags in a word-aligned bilingual parallel corpus. In contrast to the existing state-of-the-art approach of Das and Petrov, we have developed a substantially simpler method by automatically identifying ""good"" training sentences from the parallel corpus and applying self-training. In experimental results on eight languages, our method achieves state-of-the-art results.",2013,False,False,False,True,False,False,True,"D, G",201,3,204
S13-2110,{UWM}-{TRIADS}: Classifying Drug-Drug Interactions with Two-Stage {SVM} and Post-Processing,"We describe our system for the DDIExtraction-2013 shared task of classifying Drug-Drug interactions (DDIs) given labeled drug mentions. The challenge called for a five-way classification of all drug pairs in each sentence: a drug pair is either non-interacting, or interacting as one of four types. Our approach begins with the use of a two-stage weighted SVM classifier to handle the highly unbalanced class distribution: the first stage for a binary classification of drug pairs as interacting or non-interacting, and the second stage for further classification of interacting pairs from the first stage into one of the four interacting types. Our SVM features exploit stemmed words, lemmas, bigrams, part of speech tags, verb lists, and similarity measures, among others. For each stage, we also developed a set of post-processing rules based on observations in the training data. Our best system achieved 0.472 Fmeasure.",2013,False,False,False,True,False,False,True,"D, G",306,3,309
P13-2121,Scalable Modified {K}neser-{N}ey Language Model Estimation,"We present an efficient algorithm to estimate large modified Kneser-Ney models including interpolation. Streaming and sorting enables the algorithm to scale to much larger models by using a fixed amount of RAM and variable amount of disk. Using one machine with 140 GB RAM for 2.8 days, we built an unpruned model on 126 billion tokens. Machine translation experiments with this model show improvement of 0.8 BLEU point over constrained systems for the 2013 Workshop on Machine Translation task in three language pairs. Our algorithm is also faster for small models: we estimated a model on 302 million tokens using 7.7% of the RAM and 14.0% of the wall time taken by SRILM. The code is open source as part of KenLM.",2013,False,False,True,False,False,False,True,"C, G",277,3,280
I13-1074,Prosody-Based Unsupervised Speech Summarization with Two-Layer Mutually Reinforced Random Walk,"This paper presents a graph-based model that integrates prosodic features into an unsupervised speech summarization framework without any lexical information. In particular it builds on previous work using mutually reinforced random walks, in which a two-layer graph structure is used to select the most salient utterances of a conversation. The model consists of one layer of utterance nodes and another layer of prosody nodes. The random walk algorithm propagates scores between layers to use shared information for selecting utterance nodes with highest scores as summaries. A comparative evaluation of our prosody-based model against several baselines on a corpus of academic multi-party meetings reveals that it performs competitively on very short summaries, and better on longer summaries according to ROUGE scores as well as the average relevance of selected utterances.",2013,False,True,True,False,False,False,False,"B, C",273,3,276
J13-1004,Morphological and Syntactic Case in Statistical Dependency Parsing,"Most morphologically rich languages with free word order use case systems to mark the grammatical function of nominal elements, especially for the core argument functions of a verb. The standard pipeline approach in syntactic dependency parsing assumes a complete disambiguation of morphological (case) information prior to automatic syntactic analysis. Parsing experiments on Czech, German, and Hungarian show that this approach is susceptible to propagating morphological annotation errors when parsing languages displaying syncretism in their morphological case paradigms. We develop a different architecture where we use case as a possibly underspecified filtering device restricting the options for syntactic analysis. Carefully designed morpho-syntactic constraints can delimit the search space of a statistical dependency parser and exclude solutions that would violate the restrictions overtly marked in the morphology of the words in a given sentence. The constrained system outperforms a state-of-the-art data-driven pipeline architecture, as we show experimentally, and, in addition, the parser output comes with guarantees about local and global morpho-syntactic wellformedness, which can be useful for downstream applications.",2013,False,True,False,True,False,False,False,"B, D",329,3,332
R13-2019,{GF} {M}odern {G}reek Resource Grammar,"The paper describes the Modern Greek (MG) Grammar, implemented in Grammatical Framework (GF) as part of the Grammatical Framework Resource Grammar Library (RGL). GF is a special-purpose language for multilingual grammar applications. The RGL is a reusable library for dealing with the morphology and syntax of a growing number of natural languages. It is based on the use of an abstract syntax, which is common for all languages, and different concrete syntaxes implemented in GF. Both GF itself and the RGL are open-source. RGL currently covers more than 30 languages. MG is the 35th language that is available in the RGL. For the purpose of the implementation, a morphologydriven approach was used, meaning a bottomup method, starting from the formation of words before moving to larger units (sentences). We discuss briefly the main characteristics and grammatical features of MG, and present some of the major difficulties we encountered during the process of implementation and how these are handled in the MG grammar.",2013,True,False,False,False,True,False,False,"A, E",321,3,324
D13-1158,Single-Document Summarization as a Tree Knapsack Problem,"Recent studies on extractive text summarization formulate it as a combinatorial optimization problem such as a Knapsack Problem, a Maximum Coverage Problem or a Budgeted Median Problem. These methods successfully improved summarization quality, but they did not consider the rhetorical relations between the textual units of a source document. Thus, summaries generated by these methods may lack logical coherence. This paper proposes a single document summarization method based on the trimming of a discourse tree. This is a two-fold process. First, we propose rules for transforming a rhetorical structure theorybased discourse tree into a dependency-based discourse tree, which allows us to take a treetrimming approach to summarization. Second, we formulate the problem of trimming a dependency-based discourse tree as a Tree Knapsack Problem, then solve it with integer linear programming (ILP). Evaluation results showed that our method improved ROUGE scores.",2013,False,True,True,False,False,False,False,"B, C",291,3,294
S13-2100,{LIMSIILES}: Basic {E}nglish Substitution for Student Answer Assessment at {S}em{E}val 2013,"In this paper, we describe a method for assessing student answers, modeled as a paraphrase identification problem, based on substitution by Basic English variants. Basic English paraphrases are acquired from the Simple English Wiktionary. Substitutions are applied both on reference answers and student answers in order to reduce the diversity of their vocabulary and map them to a common vocabulary. The evaluation of our approach on the SemEval 2013 Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge data shows promising results, and this work is a first step toward an opendomain system able to exhibit deep text understanding capabilities.",2013,False,False,False,True,False,False,True,"D, G",244,3,247
N13-1115,Multi-Metric Optimization Using Ensemble Tuning,"This paper examines tuning for statistical machine translation (SMT) with respect to multiple evaluation metrics. We propose several novel methods for tuning towards multiple objectives, including some based on ensemble decoding methods. Pareto-optimality is a natural way to think about multi-metric optimization (MMO) and our methods can effectively combine several Pareto-optimal solutions, obviating the need to choose one. Our best performing ensemble tuning method is a new algorithm for multi-metric optimization that searches for Pareto-optimal ensemble models. We study the effectiveness of our methods through experiments on multiple as well as single reference(s) datasets. Our experiments show simultaneous gains across several metrics (BLEU, RIBES), without any significant reduction in other metrics. This contrasts the traditional tuning where gains are usually limited to a single metric. Our human evaluation results confirm that in order to produce better MT output, optimizing multiple metrics is better than optimizing only one.",2013,False,False,True,True,False,False,False,"C,D",306,2,308
W13-4032,Verbal indicators of psychological distress in interactive dialogue with a virtual human,"We explore the presence of indicators of psychological distress in the linguistic behavior of subjects in a corpus of semistructured virtual human interviews. At the level of aggregate dialogue-level features, we identify several significant differences between subjects with depression and PTSD when compared to nondistressed subjects. At a more fine-grained level, we show that significant differences can also be found among features that represent subject behavior during specific moments in the dialogues. Finally, we present statistical classification results that suggest the potential for automatic assessment of psychological distress in individual interactions with a virtual human dialogue system.",2013,False,False,False,False,True,False,True,"E, G",230,3,233
W13-2232,Online Polylingual Topic Models for Fast Document Translation Detection,"Many tasks in NLP and IR require efficient document similarity computations. Beyond their common application to exploratory data analysis, latent variable topic models have been used to represent text in a low-dimensional space, independent of vocabulary, where documents may be compared. This paper focuses on the task of searching a large multilingual collection for pairs of documents that are translations of each other. We present (1) efficient, online inference for representing documents in several languages in a common topic space and (2) fast approximations for finding near neighbors in the probability simplex. Empirical evaluations show that these methods are as accurate as-and significantly faster than-Gibbs sampling and brute-force all-pairs search.",2013,False,True,False,True,False,False,False,"B, D",251,3,254
S13-2089,{U}o{M}: Using Explicit Semantic Analysis for Classifying Sentiments,"In this paper, we describe our system submitted for the Sentiment Analysis task at Se-mEval 2013 (Task 2). We implemented a combination of Explicit Semantic Analysis (ESA) with Naive Bayes classifier. ESA represents text as a high dimensional vector of explicitly defined topics, following the distributional semantic model. This approach is novel in the sense that ESA has not been used for Sentiment Analysis in the literature, to the best of our knowledge.",2013,False,False,False,True,False,False,True,"G, D",211,3,214
W13-1901,Earlier Identification of Epilepsy Surgery Candidates Using Natural Language Processing,"This research analyzed the clinical notes of epilepsy patients using techniques from corpus linguistics and machine learning and predicted which patients are candidates for neurosurgery, i.e. have intractable epilepsy, and which are not. Information-theoretic and machine learning techniques are used to determine whether and how sets of clinic notes from patients with intractable and nonintractable epilepsy are different. The results show that it is possible to predict from an early stage of treatment which patients will fall into one of these two categories based only on text data. These results have broad implications for developing clinical decision support systems.",2013,False,False,False,True,False,False,True,"D, G",238,3,241
I13-1129,Phrase-based Parallel Fragments Extraction from Comparable Corpora,"We present a phrase-based method to extract parallel fragments from the comparable corpora. We do this by introducing a force decoder based on the hierarchical phrase-based (HPB) translation model to detect the alignments in comparable sentence pairs. This method enables us to extract useful training data for statistical machine translation (SMT) system. We evaluate our method by fragment detection and large-scale translation tasks, which show that our method can effectively extract parallel fragments and improve the performance of the state-of-the-art SMT system.",2013,True,False,False,True,False,False,False,"A, D",219,3,222
D13-1091,Is {T}witter A Better Corpus for Measuring Sentiment Similarity?,"Extensive experiments have validated the effectiveness of the corpus-based method for classifying the word's sentiment polarity. However, no work is done for comparing different corpora in the polarity classification task. Nowadays, Twitter has aggregated huge amount of data that are full of people's sentiments. In this paper, we empirically evaluate the performance of different corpora in sentiment similarity measurement, which is the fundamental task for word polarity classification. Experiment results show that the Twitter data can achieve a much better performance than the Google, Web1T and Wikipedia based methods.",2013,False,False,False,False,True,False,True,"E,G",226,2,228
D13-1131,This Text Has the Scent of {S}tarbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics,"We propose a Laplacian structured sparsity model to study computational branding analytics. To do this, we collected customer reviews from Starbucks, Dunkin' Donuts, and other coffee shops across 38 major cities in the Midwest and Northeastern regions of USA. We study the brand related language use through these reviews, with focuses on the brand satisfaction and gender factors. In particular, we perform three tasks: automatic brand identification from raw text, joint brand-satisfaction prediction, and joint brandgender-satisfaction prediction. This work extends previous studies in text classification by incorporating the dependency and interaction among local features in the form of structured sparsity in a log-linear model. Our quantitative evaluation shows that our approach which combines the advantages of graphical modeling and sparsity modeling techniques significantly outperforms various standard and stateof-the-art text classification algorithms. In addition, qualitative analysis of our model reveals important features of the language uses associated with the specific brands.",2013,False,True,False,False,True,False,False,"B, E",305,3,308
S13-1028,{SOFTCARDINALITY}-{CORE}: Improving Text Overlap with Distributional Measures for Semantic Textual Similarity,"Soft cardinality has been shown to be a very strong text-overlapping baseline for the task of measuring semantic textual similarity (STS), obtaining 3 rd place in SemEval-2012. At *SEM-2013 shared task, beside the plain textoverlapping approach, we tested within soft cardinality two distributional word-similarity functions derived from the ukWack corpus. Unfortunately, we combined these measures with other features using regression, obtaining positions 18 th , 22 nd and 23 rd among the 90 participants systems in the official ranking. Already after the release of the gold standard annotations of the test data, we observed that using only the similarity measures without combining them with other features would have obtained positions 6 th , 7 th and 8 th ; moreover, an arithmetic average of these similarity measures would have been 4 th (mean=0.5747). This paper describes both the 3 systems as they were submitted and the similarity measures that would obtained those better results.",2013,False,False,False,True,False,True,False,"D, F",321,3,324
W13-5624,Morphological Analysis with Limited Resources: {L}atvian Example,"We describe an approach for morphological analysis combining a rule-based word level morphological analyzer with statistical tagging, detailing its application to Latvian language. Latvian is a highly inflective Indo-European language with a rich morphology. The tools described here include an implementation of Latvian inflectional paradigms, a morphological analysis tool with a guessing module for out-of-vocabulary words, and a statistical POS/morphology tagger for disambiguation of multiple analysis possibilities. Currently achieved accuracy with a training set of only ~40 000 words is 97.9% for part of speech tagging and 93.6% for the full morphological feature tag set, which is better than any previously publicly available taggers for Latvian. We also describe the construction and methodology of the necessary linguistic resources -a morphological dictionary and an annotated morphological corpus, and evaluate the effect of resource size on analysis accuracy, showing what results can be achieved with limited linguistic resources.",2013,True,False,False,False,False,False,True,"A, G",307,3,310
N13-1123,A Latent Variable Model for Viewpoint Discovery from Threaded Forum Posts,"Threaded discussion forums provide an important social media platform. Its rich user generated content has served as an important source of public feedback. To automatically discover the viewpoints or stances on hot issues from forum threads is an important and useful task. In this paper, we propose a novel latent variable model for viewpoint discovery from threaded forum posts. Our model is a principled generative latent variable model which captures three important factors: viewpoint specific topic preference, user identity and user interactions. Evaluation results show that our model clearly outperforms a number of baseline models in terms of both clustering posts based on viewpoints and clustering users with different viewpoints.",2013,False,True,True,False,False,False,False,"B, C",243,3,246
2013.mtsummit-wpt.5,Exploiting multiple resources for {J}apanese to {E}nglish patent translation,"This paper describes the development of a Japanese to English translation system using multiple resources and NTCIR-10 Patent translation collection. The MT system is based on different training data, the Wiktionary as a bilingual dictionary and Moses decoder. Due to the lack of parallel data on the patent domain, additional training data of the general domain was extracted from Wikipedia. Experiments using NTCIR-10 Patent translation data collection showed an improvement of the BLEU score when using a 5-grams language model and when adding the data extracted from Wikipedia but no improvement when adding the Wiktionary.",2013,False,False,False,True,False,False,True,"D,G",236,2,238
P13-1048,Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis,"We propose a novel approach for developing a two-stage document-level discourse parser. Our parser builds a discourse tree by applying an optimal parsing algorithm to probabilities inferred from two Conditional Random Fields: one for intrasentential parsing and the other for multisentential parsing. We present two approaches to combine these two stages of discourse parsing effectively. A set of empirical evaluations over two different datasets demonstrates that our discourse parser significantly outperforms the stateof-the-art, often by a wide margin.",2013,False,True,True,False,False,False,False,"B, C",214,3,217
R13-1024,Normalization of {D}utch User-Generated Content,"This paper describes a phrase-based machine translation approach to normalize Dutch user-generated content (UGC). We compiled a corpus of three different social media genres (text messages, message board posts and tweets) to have a sample of this recent domain. We describe the various characteristics of this noisy text material and explain how it has been manually normalized using newly developed guidelines. For the automatic normalization task we focus on text messages, and find that a cascaded SMT system where a token-based module is followed by a translation at the character level gives the best word error rate reduction. After these initial experiments, we investigate the system's robustness on the complete domain of UGC by testing it on the other two social media genres, and find that the cascaded approach performs best on these genres as well. To our knowledge, we deliver the first proof-of-concept system for Dutch UGC normalization, which can serve as a baseline for future work.",2013,True,False,False,False,False,False,True,"A, G",303,3,306
W13-2313,Generic noun phrases and annotation of coreference and bridging relations in the {P}rague Dependency Treebank,"This paper discusses the problem of annotating coreference relations with generic expressions in a large scale corpus. We present and analyze some existing theories of genericity, compare them to the approaches to generics that are used in the state-of-the-art coreference annotation guidelines and discuss how coreference of generic expressions is processed in the manual annotation of the Prague Dependency Treebank. After analyzing some typical problematic issues we propose some partial solutions that can be used to enhance the quality and consistency of the annotation.",2013,False,False,False,True,True,False,False,"E, D",216,3,219
N13-1091,{T}ruth{T}eller: Annotating Predicate Truth,"We propose a novel semantic annotation type of assigning truth values to predicate occurrences, and present TruthTeller, a standalone publiclyavailable tool that produces such annotations. TruthTeller integrates a range of semantic phenomena, such as negation, modality, presupposition, implicativity, and more, which were dealt only partly in previous works. Empirical evaluations against human annotations show satisfactory results and suggest the usefulness of this new type of tool for NLP.",2013,True,True,False,False,False,False,False,"A, B",207,3,210
I13-1170,{K}y{SS} 1.0: a Framework for Automatic Evaluation of {C}hinese Input Method Engines,"Chinese Input Method Engine (IME) plays an important role in Chinese language processing. However, it has been subjected to lacking a proper evaluation metric for a long time. The natural metric for IME is user experience, which is a rather vague goal for research purpose. We propose a novel approach of quantifying user experience by using keystroke count and then correspondingly develop a framework of IME evaluation, which is fast and accurate. With the underlying linguistic background, the proposed evaluation framework can properly model the user behavior as Chinese is input through English keyboard. It is helpful to point out a way to improve the current Chinese IME performance. 1",2013,True,False,False,False,True,False,False,"A, E",249,3,252
W13-1407,An initial study of topical poetry segmentation,"This work performs some basic research upon topical poetry segmentation in a pilot study designed to test some initial assumptions and methodologies. Nine segmentations of the poem titled Kubla Khan (Coleridge, 1816, pp. 55-58) are collected and analysed, producing low but comparable inter-coder agreement. Analyses and discussions of these codings focus upon how to improve agreement and outline some initial results on the nature of topics in this poem.",2013,False,False,False,False,True,True,False,"E, F",209,3,212
S13-1038,Exploring Vector Space Models to Predict the Compositionality of {G}erman Noun-Noun Compounds,"This paper explores two hypotheses regarding vector space models that predict the compositionality of German noun-noun compounds: (1) Against our intuition, we demonstrate that window-based rather than syntax-based distributional features perform better predictions, and that not adjectives or verbs but nouns represent the most salient part-of-speech. Our overall best result is state-of-the-art, reaching Spearman's ρ = 0.65 with a wordspace model of nominal features from a 20word window of a 1.5 billion word web corpus. (2) While there are no significant differences in predicting compound-modifier vs. compound-head ratings on compositionality, we show that the modifier (rather than the head) properties predominantly influence the degree of compositionality of the compound.",2013,False,False,False,False,True,True,False,"E,F",274,2,276
N13-1025,Large-Scale Discriminative Training for Statistical Machine Translation Using Held-Out Line Search,"We introduce a new large-scale discriminative learning algorithm for machine translation that is capable of learning parameters in models with extremely sparse features. To ensure their reliable estimation and to prevent overfitting, we use a two-phase learning algorithm. First, the contribution of individual sparse features is estimated using large amounts of parallel data. Second, a small development corpus is used to determine the relative contributions of the sparse features and standard dense features. Not only does this two-phase learning approach prevent overfitting, the second pass optimizes corpus-level BLEU of the Viterbi translation of the decoder. We demonstrate significant improvements using sparse rule indicator features in three different translation tasks. To our knowledge, this is the first large-scale discriminative training algorithm capable of showing improvements over the MERT baseline with only rule indicator features in addition to the standard MERT features.",2013,False,True,True,False,False,False,False,"B, C",287,3,290
S13-2007,{S}em{E}val-2013 Task 5: Evaluating Phrasal Semantics,"This paper describes the SemEval-2013 Task 5: ""Evaluating Phrasal Semantics"". Its first subtask is about computing the semantic similarity of words and compositional phrases of minimal length. The second one addresses deciding the compositionality of phrases in a given context. The paper discusses the importance and background of these subtasks and their structure. In succession, it introduces the systems that participated and discusses evaluation results.",2013,True,False,False,False,True,False,False,"A, E",205,3,208
W13-3610,Grammatical Error Correction as Multiclass Classification with Single Model,This paper describes our system in the shared task of CoNLL-2013. We illustrate that grammatical error detection and correction can be transformed into a multiclass classification task and implemented as a single-model system regardless of various error types with the aid of maximum entropy modeling. Our system achieves the F1 score of 17.13% on the standard test set.,2013,False,False,False,True,False,False,True,"D, G",191,3,194
W13-4031,Multimodality and Dialogue Act Classification in the {R}obo{H}elper Project,"We describe the annotation of a multimodal corpus that includes pointing gestures and haptic actions (force exchanges). Haptic actions are rarely analyzed as fullfledged components of dialogue, but our data shows haptic actions are used to advance the state of the interaction. We report our experiments on recognizing Dialogue Acts in both offline and online modes. Our results show that multimodal features and the dialogue game aid in DA classification.",2013,True,False,False,False,True,False,False,"A, E",201,3,204
P13-4005,Detecting Event-Related Links and Sentiments from Social Media Texts,"Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public's perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.",2013,False,False,False,True,False,False,True,"G, D",295,3,298
P13-2111,Efficient Implementation of Beam-Search Incremental Parsers,"Beam search incremental parsers are accurate, but not as fast as they could be. We demonstrate that, contrary to popular belief, most current implementations of beam parsers in fact run in O(n 2 ), rather than linear time, because each statetransition is actually implemented as an O(n) operation. We present an improved implementation, based on Tree Structured Stack (TSS), in which a transition is performed in O(1), resulting in a real lineartime algorithm, which is verified empirically. We further improve parsing speed by sharing feature-extraction and dotproduct across beam items. Practically, our methods combined offer a speedup of ∼2x over strong baselines on Penn Treebank sentences, and are orders of magnitude faster on much longer sentences.",2013,False,False,True,True,False,False,False,"C, D",275,3,278
W13-5512,Towards the establishment of a linguistic linked data network for {I}talian,"This paper describes the conversion of ItalwordNet and of a domain WordNet into RDF and their linking to the (L)LOD cloud and to other existing resources. A brief presentation of the resources is given, and the conversion and resulting datasets are described.",2013,True,False,False,False,False,False,True,"A, G",169,3,172
F13-2009,Complex terminologies management - the case of acronyms (Gestion des terminologies riches : l{'}exemple des acronymes) [in {F}rench],"La gestion des terminologies pose encore des problèmes, en particulier pour des constructions complexes comme les acronymes. Dans cet article, nous proposons une solution en reliant plusieurs termes différents à un seul référent via les notions de pivot et de prolexème. Ces notions permettent par exemple de faire le lien entre plusieurs termes qui désignent un même et unique référent : Nations Unies, ONU, Organisation des Nations Unies et onusien. Il existe Jibiki, une plate-forme générique de gestion de bases lexicales permettant de gérer n'importe quel type de structure (macro et microstructure). Nous avons implémenté une nouvelle macrostructure de ProAxie dans la plate-forme Jibiki pour réaliser la gestion des acronymes.",2013,True,False,False,False,False,False,True,"A, G",268,3,271
F13-2030,An iterative topic segmentation algorithm with intra-content term weighting (Segmentation th{\'e}matique : processus it{\'e}ratif de pond{\'e}ration intra-contenu) [in {F}rench],"%&'&()%*&+,$'&(-.""* * * */*01)2""33.3*(&,1'&( /*01)2""33.3*(&,1'&( /*01)2""33.3*(&,1'&( /*01)2""33.3*(&,1'&(4 4 4 4* * * *5""*0)%5,1'&()%* 5""*0)%5,1'&()%* 5""*0)%5,1'&()%* 5""*0)%5,1'&()%* (%&1' (%&1' (%&1' (%&1'6 6 6 62)%&""%. 2)%&""%. 2)%&""%. 2)%&""%.",2013,False,False,False,False,True,True,False,"E, F",293,3,296
I13-1043,Readability Indices for Automatic Evaluation of Text Simplification Systems: A Feasibility Study for {S}panish,"This paper addresses the problem of automatic evaluation of text simplification systems for Spanish. We test whether already-existing readability formulae would be suitable for this task. We adapt three existing readability indices (two measuring lexical complexity and one measuring syntactic complexity) to be computed automatically, which are then applied to a corpus of original news texts and their manual simplifications aimed at people with cognitive disabilities. We show that there is a significant correlation between each of the three readability indices and several linguistically motivated features which might be seen as reading obstacles for various target populations. Furthermore, we show that there is a significant correlation between the two readability indices which measure lexical complexity.",2013,False,False,False,False,True,False,True,"E, G",248,3,251
W13-4025,A Multithreaded Conversational Interface for Pedestrian Navigation and Question Answering,"We demonstrate a conversational interface that assists pedestrian users in navigating within urban environments and acquiring tourist information by combining spoken dialogue system, question-answering (QA), and geographic information system (GIS) technologies. In contrast to existing mobile applications which treat these problems independently, our Android agent addresses the problem of navigation and touristic question-answering in an integrated fashion using a shared dialogue context with multiple interleaved dialogue threads. In this paper, we present the architecture and features of our latest system, extended from an earlier version which was built and evaluated with real users (Janarthanam et al., 2013) . The new features include navigation based on visible landmarks, navigation adapted to the user's previous route knowledge, and tourist information pushing based on visible and proximal points-of-interest. The system also uses social media to infer ""popularity"" of geographical entities.",2013,False,False,False,True,False,False,True,"D, G",288,3,291
W13-3505,Graph-Based Posterior Regularization for Semi-Supervised Structured Prediction,"We present a flexible formulation of semisupervised learning for structured models, which seamlessly incorporates graphbased and more general supervision by extending the posterior regularization (PR) framework. Our extension allows for any regularizer that is a convex, differentiable function of the appropriate marginals. We show that surprisingly, non-linearity of such regularization does not increase the complexity of learning, provided we use multiplicative updates of the structured exponentiated gradient algorithm. We illustrate the extended framework by learning conditional random fields (CRFs) with quadratic penalties arising from a graph Laplacian. On sequential prediction tasks of handwriting recognition and part-ofspeech (POS) tagging, our method makes significant gains over strong baselines.",2013,False,False,True,True,False,False,False,"C, D",260,3,263
W13-4409,A Hybrid {C}hinese Spelling Correction Using Language Model and Statistical Machine Translation with Reranking,"We describe the Nara Institute of Science and Technology (NAIST) spelling check system in the shared task. Our system contains three components: a word segmentation based language model to generate correction candidates; a statistical machine translation model to provide correction candidates and a Support Vector Machine (SVM) classifier to rerank the candidates provided by the previous two components. The experimental results show that the kbest language model and the statistical machine translation model could generate almost all the correction candidates, while the precision is very low. However, using the SVM classifier to rerank the candidates, we could obtain higher precision with a little recall dropping. To address the low resource problem of the Chinese spelling check, we generate 2 million artificial training data by simply replacing the character in the provided training sentence with the character in the confusion set.",2013,False,False,False,True,False,False,True,"D, G",281,3,284
P13-2016,Learning to Order Natural Language Texts,"Ordering texts is an important task for many NLP applications. Most previous works on summary sentence ordering rely on the contextual information (e.g. adjacent sentences) of each sentence in the source document. In this paper, we investigate a more challenging task of ordering a set of unordered sentences without any contextual information. We introduce a set of features to characterize the order and coherence of natural language texts, and use the learning to rank technique to determine the order of any two sentences. We also propose to use the genetic algorithm to determine the total order of all sentences. Evaluation results on a news corpus show the effectiveness of our proposed method.",2013,False,True,True,False,False,False,False,"B, C",242,3,245
2013.iwslt-evaluation.16,{EU}-{BRIDGE} {MT}: text translation of talks in the {EU}-{BRIDGE} project,"EU-BRIDGE 1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EU-BRIDGE to further advance the state of the art in machine translation between two European language pairs, English→French and German→English. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems.",2013,False,False,False,True,False,False,True,"D, G",339,3,342
W13-2814,A Hybrid Word Alignment Model for Phrase-Based Statistical Machine Translation,This paper proposes a hybrid word alignment model for Phrase-Based Statistical Machine translation (PB-SMT). The proposed hybrid alignment model provides most informative alignment links which are offered by both unsupervised and semi-supervised word alignment models. Two unsupervised word alignment models (GIZA++ and Berkeley aligner) and a rule based aligner are combined together. The rule based aligner only aligns named entities (NEs) and chunks. The NEs are aligned through transliteration using a joint source-channel model. Chunks are aligned employing a bootstrapping approach by translating the source chunks into the target language using a baseline PB-SMT system and subsequently validating the target chunks using a fuzzy matching technique against the target corpus. All the experiments are carried out after single-tokenizing the multi-word NEs. Our best system provided significant improvements over the baseline as measured by BLEU.,2013,False,True,False,True,False,False,False,"B, D",293,3,296
N13-1094,Graph-Based Seed Set Expansion for Relation Extraction Using Random Walk Hitting Times,"Iterative bootstrapping methods are widely employed for relation extraction, especially because they require only a small amount of human supervision. Unfortunately, a phenomenon known as semantic drift can affect the accuracy of iterative bootstrapping and lead to poor extractions. This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods.",2013,False,True,True,False,False,False,False,"B, C",229,3,232
S13-2013,{SUT}ime: Evaluation in {T}emp{E}val-3,"We analyze the performance of SUTIME, a temporal tagger for recognizing and normalizing temporal expressions, on TempEval-3 Task A for English. SUTIME is available as part of the Stanford CoreNLP pipeline and can be used to annotate documents with temporal information. Testing on the TempEval-3 evaluation corpus showed that this system is competitive with state-of-the-art techniques.",2013,False,False,False,False,False,True,True,"F, G",196,3,199
I13-1007,(Pre-)Annotation of Topic-Focus Articulation in {P}rague {C}zech-{E}nglish {D}ependency {T}reebank,"The objective of the present contribution is to give a survey of the annotation of information structure in the Czech part of the Prague Czech-English Dependency Treebank. We report on this first step in the process of building a parallel annotation of information structure in this corpus, and elaborate on the automatic pre-annotation procedure for the Czech part. The results of the pre-annotation are evaluated, based on the comparison of the automatic and manual annotation.",2013,False,False,False,False,True,False,True,"E, G",204,3,207
N13-1043,Learning to Relate Literal and Sentimental Descriptions of Visual Properties,"Language can describe our visual world at many levels, including not only what is literally there but also the sentiment that it invokes. In this paper, we study visual language, both literal and sentimental, that describes the overall appearance and style of virtual characters. Sentimental properties, including labels such as ""youthful"" or ""country western,"" must be inferred from descriptions of the more literal properties, such as facial features and clothing selection. We present a new dataset, collected to describe Xbox avatars, as well as models for learning the relationships between these avatars and their literal and sentimental descriptions. In a series of experiments, we demonstrate that such learned models can be used for a range of tasks, including predicting sentimental words and using them to rank and build avatars. Together, these results demonstrate that sentimental language provides a concise (though noisy) means of specifying low-level visual properties.",2013,True,True,False,False,False,False,False,"A, B",292,3,295
P13-1142,{BRAINSUP}: Brainstorming Support for Creative Sentence Generation,"We present BRAINSUP, an extensible framework for the generation of creative sentences in which users are able to force several words to appear in the sentences and to control the generation process across several semantic dimensions, namely emotions, colors, domain relatedness and phonetic properties. We evaluate its performance on a creative sentence generation task, showing its capability of generating well-formed, catchy and effective sentences that have all the good qualities of slogans produced by human copywriters.",2013,False,True,False,False,False,False,True,"B, G",210,3,213
S13-2051,unimelb: Topic Modelling-based Word Sense Induction,"This paper describes our system for shared task 13 ""Word Sense Induction for Graded and Non-Graded Senses"" of SemEval-2013. The task is on word sense induction (WSI), and builds on earlier SemEval WSI tasks in exploring the possibility of multiple senses being compatible to varying degrees with a single contextual instance: participants are asked to grade senses rather than selecting a single sense like most word sense disambiguation (WSD) settings. The evaluation measures are designed to assess how well a system perceives the different senses in a contextual instance. We adopt a previously-proposed WSI methodology for the task, which is based on a Hierarchical Dirichlet Process (HDP), a nonparametric topic model. Our system requires no parameter tuning, uses the English ukWaC as an external resource, and achieves encouraging results over the shared task.",2013,False,False,False,True,False,False,True,"D, G",296,3,299
P13-1074,Punctuation Prediction with Transition-based Parsing,"Punctuations are not available in automatic speech recognition outputs, which could create barriers to many subsequent text processing tasks. This paper proposes a novel method to predict punctuation symbols for the stream of words in transcribed speech texts. Our method jointly performs parsing and punctuation prediction by integrating a rich set of syntactic features when processing words from left to right. It can exploit a global view to capture long-range dependencies for punctuation prediction with linear complexity. The experimental results on the test data sets of IWSLT and TDT4 show that our method can achieve high-level performance in punctuation prediction over the stream of words in transcribed speech text.",2013,False,True,False,True,False,False,False,"B, D",245,3,248
2013.mtsummit-papers.20,Reverse Word Order Model,"In this work, we study the impact of the word order decoding direction for statistical machine translation (SMT). Both phrase-based and hierarchical phrasebased SMT systems are investigated by reversing the word order of the source and/or target language and comparing the translation results with the normal direction. Analysis are done on several components such as alignment model, language model and phrase table to see which of them accounts for the differences generated by various translation directions. Furthermore, we propose to use system combination, alignment combinations and phrase table combinations to take benefit from systems trained with different translation directions. Experimental results show improvements of up to 1.7 points in BLEU and 3.1 points in TER compared to the normal direction systems for the NTCIR-9 Japanese-English and Chinese-English tasks.",2013,False,False,False,True,False,True,False,"D, F",273,3,276
R13-1001,{ASMA}: A System for Automatic Segmentation and Morpho-Syntactic Disambiguation of {M}odern {S}tandard {A}rabic,"In this paper, we present ASMA, a fast and efficient system for automatic segmentation and fine grained part of speech (POS) tagging of Modern Standard Arabic (MSA). ASMA performs segmentation both of agglutinative and of inflectional morphological boundaries within a word. In this work, we compare ASMA to two state of the art suites of MSA tools: AMIRA 2.1 (Diab et al., 2007; Diab, 2009) and MADA+TOKAN 3.2. (Habash  et al., 2009). ASMA achieves comparable results to these two systems' state-of-theart performance. ASMA yields an accuracy of 98.34% for segmentation, and an accuracy of 96.26% for POS tagging with a rich tagset and 97.59% accuracy with an extremely reduced tagset.",2013,False,False,False,True,False,False,True,"D, G",301,3,304
P13-1014,A Transition-Based Dependency Parser Using a Dynamic Parsing Strategy,"We present a novel transition-based, greedy dependency parser which implements a flexible mix of bottom-up and top-down strategies. The new strategy allows the parser to postpone difficult decisions until the relevant information becomes available. The novel parser has a ∼12% error reduction in unlabeled attachment score over an arc-eager parser, with a slow-down factor of 2.8.",2013,False,True,True,False,False,False,False,"B, C",192,3,195
W13-2214,Towards Efficient Large-Scale Feature-Rich Statistical Machine Translation,"We present the system we developed to provide efficient large-scale feature-rich discriminative training for machine translation. We describe how we integrate with MapReduce using Hadoop streaming to allow arbitrarily scaling the tuning set and utilizing a sparse feature set. We report our findings on German-English and Russian-English translation, and discuss benefits, as well as obstacles, to tuning on larger development sets drawn from the parallel training data.",2013,False,True,False,True,False,False,False,"B, D",198,3,201
Y13-2002,i{P}ad Reading: An Innovative Approach to New Literacies,"This study aimed to investigate the use of iPads as a learning tool for college-level EFL students and to explore these language learners' perceptions of iPad reading. Drawn from an intermediate EFL reading class, three students with limited experiences of iPad reading participated in this study. Data from weekly journals and interviews showed that the iPads' palm size, light weight, and accessibility to the Internet through wireless connections not only promoted mobile learning outside the classroom but also achieved learning goals inside the classroom. The various iPad applications enabled students to learn English through games and easy access to helpful resources and thereby increased their motivation to learn. Students also improved their communication skills by using iPads to create videos. iPads have provided useful opportunities for new literacy instruction.",2013,False,False,False,False,True,False,True,"G, E",269,3,272
I13-1078,Construction of Emotional Lexicon Using Potts Model,"Emotion is an instinctive state of mind aroused by some specific objects or situation. Exchange of textual information is an important medium for communication and contains a rich set of emotional expressions. The computational approaches to emotion analysis in textual data require annotated lexicons with polarity tags. In this paper we propose a novel method for constructing emotion lexicon annotated with Ekman""s six basic emotion classes (anger, disgust, fear, happy, sad and surprise). We adopt the Potts model for the probability modeling of the lexical network. The lexical network has been constructed by connecting each pair of words in which one of the two words appears in the gloss of the other. Starting with a small number of emotional seed words, the emotional categories of other words have been determined. With manual checking of top 200 words from each class an average precision of 85.41% has been achieved.",2013,True,False,True,False,False,False,False,"A, C",292,3,295
W13-3008,Structure Learning in Weighted Languages,"We present Minimum Description Length techniques for learning the structure of weighted languages. MDL is already widely used both for segmentation and classification tasks, and here we show it can be used to formalize further important tools in the descriptive linguists' toolbox, including the distinction between accidental and systematic gaps in the data, the detection of ambiguity, the selective discarding of data, and the merging of categories.",2013,False,False,False,True,True,False,False,"D, E",197,3,200
2013.iwslt-evaluation.24,The {KIT} translation systems for {IWSLT} 2013,"In this paper, we present the KIT systems participating in all three official directions, namely English→German, German→English, and English→French, in translation tasks of the IWSLT 2013 machine translation evaluation. Additionally, we present the results for our submissions to the optional directions English→Chinese and English→Arabic. We used phrase-based translation systems to generate the translations. This year, we focused on adapting the systems towards ASR input. Furthermore, we investigated different reordering models as well as an extended discriminative word lexicon. Finally, we added a data selection approach for domain adaptation.",2013,False,False,False,True,False,False,True,"D, G",240,3,243
R13-2018,Towards {B}asque Oral Poetry Analysis: A Machine Learning Approach,"This work aims to study the narrative structure of Basque greeting verses from a text classification approach. We propose a set of thematic categories for the correct classification of verses, and then, use those categories to analyse the verses based on Machine Learning techniques. Classification methods such as Naive Bayes, k-NN, Support Vector Machines and Decision Tree Learner have been selected. Dimensionality reduction techniques have been applied in order to reduce the term space. The results shown by the experiments give an indication of the suitability of the proposed approach for the task at hands.",2013,False,False,False,True,False,False,True,"D, G",230,3,233
