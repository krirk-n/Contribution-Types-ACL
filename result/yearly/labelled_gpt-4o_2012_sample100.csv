acl_id,title,abstract,year,A,B,C,D,E,F,G,raw_response,input_tokens,output_tokens,total_tokens
W12-1603,"{``}Love ya, jerkface{''}: Using Sparse Log-Linear Models to Build Positive and Impolite Relationships with Teens","One challenge of implementing spoken dialogue systems for long-term interaction is how to adapt the dialogue as user and system become more familiar. We believe this challenge includes evoking and signaling aspects of long-term relationships such as rapport. For tutoring systems, this may additionally require knowing how relationships are signaled among non-adult users. We therefore investigate conversational strategies used by teenagers in peer tutoring dialogues, and how these strategies function differently among friends or strangers. In particular, we use annotated and automatically extracted linguistic devices to predict impoliteness and positivity in the next turn. To take into account the sparse nature of these features in real data we use models including Lasso, ridge estimator, and elastic net. We evaluate the predictive power of our models under various settings, and compare our sparse models with standard non-sparse solutions. Our experiments demonstrate that our models are more accurate than non-sparse models quantitatively, and that teens use unexpected kinds of language to do relationship work such as signaling rapport, but friends and strangers, tutors and tutees, carry out this work in quite different ways from one another.",2012,False,False,False,False,True,True,False,"E, F",337,3,340
W12-4807,{L}uit{P}ad: A fully {U}nicode compatible {A}ssamese writing software,"LuitPad is a stand-alone, fully Unicode compliant software designed for rapid typing of Assamese words and characters. There are two main typing options; one which is based on approximate sound of words and the other based on the sound of characters, both of which are efficient and user-friendly, even for a first-time user. In addition, LuitPad comes with an online spell-checker; on ""right-clock"" over a misspelt word, presents the user with a list of relevant appropriate corrections for replacements. Assamese is an Indic language, spoken throughout North-Eastern parts of India by approximately 30 million people. There is a severe lack of user-friendly software available for typing Assamese text. This is perhaps the underlying reason for the miniscule presence of Assamese based information storage and retrieval systems, both off-line and on-line. With LuitPad, the user can retrieve Assamese characters and words using an English alphabet based keyboard in an effective and intuitive way. LuitPad is compatible with Windows, Mac and Linux with a GUI. The software can store the contents in LuitPad file format ("".pad"" extension) that can store images and text. In addition, .pad files can be easily exported to pdf and html files.",2012,True,False,False,False,False,False,True,"G, A",367,3,370
W12-5116,{SEJFEK} - a Lexicon and a Shallow Grammar of {P}olish Economic Multi-Word Units,"We present a large-coverage lexical and grammatical resource of Polish economic terminology. It consists of two alternative modules. One is a grammatical lexicon of about 11,000 terminological multi-word units, where inflectional and syntactic variation, as well as nesting of terms, are described via graph-based rules. The other one is a fully lexicalized shallow grammar, obtained by an automatic conversion of the lexicon, and partly manually validated. Both resources have a good coverage, evaluated on a manually annotated corpus, and are freely available under the Creative Commons BY-SA license.",2012,True,False,False,False,True,False,False,"A, E",233,3,236
W12-2006,{HOO} 2012: A Report on the Preposition and Determiner Error Correction Shared Task,"Incorrect usage of prepositions and determiners constitute the most common types of errors made by non-native speakers of English. It is not surprising, then, that there has been a significant amount of work directed towards the automated detection and correction of such errors. However, to date, the use of different data sets and different task definitions has made it difficult to compare work on the topic. This paper reports on the HOO 2012 shared task on error detection and correction in the use of prepositions and determiners, where systems developed by 14 teams from around the world were evaluated on the same previously unseen errorful text.",2012,True,False,False,False,False,False,True,"A, G",243,3,246
O12-1016,{E}nglish-to-Traditional {C}hinese Cross-lingual Link Discovery in Articles with {W}ikipedia Corpus,"In this paper, we design a processing flow to produce linked data in articles, providing anchorbased term's additional information and related terms in different languages (English to Chinese). Wikipedia has been a very important corpus and knowledge bank. Although Wikipedia describes itself not a dictionary or encyclopedia, it is if high potential values in applications and data mining researches. Link discovery is a useful IR application, based on Data Mining and NLP algorithms and has been used in several fields. According to the results of our experiment, this method does make the result has improved.",2012,False,False,False,True,False,False,True,"D, G",226,3,229
P12-2068,Sentence Compression with Semantic Role Constraints,"For sentence compression, we propose new semantic constraints to directly capture the relations between a predicate and its arguments, whereas the existing approaches have focused on relatively shallow linguistic properties, such as lexical and syntactic information. These constraints are based on semantic roles and superior to the constraints of syntactic dependencies. Our empirical evaluation on the Written News Compression Corpus (Clarke and Lapata, 2008) demonstrates that our system achieves results comparable to other state-of-the-art techniques.",2012,False,False,False,True,True,False,False,"D, E",211,3,214
E12-2003,Collaborative Machine Translation Service for Scientific texts,"French researchers are required to frequently translate into French the description of their work published in English. At the same time, the need for French people to access articles in English, or to international researchers to access theses or papers in French, is incorrectly resolved via the use of generic translation tools. We propose the demonstration of an end-to-end tool integrated in the HAL open archive for enabling efficient translation for scientific texts. This tool can give translation suggestions adapted to the scientific domain, improving by more than 10 points the BLEU score of a generic system. It also provides a post-edition service which captures user post-editing data that can be used to incrementally improve the translations engines. Thus it is helpful for users which need to translate or to access scientific texts.",2012,False,False,False,True,False,False,True,"D, G",270,3,273
C12-2134,Identifying Temporal Relations by Sentence and Document Optimizations,"This paper presents a temporal relation identification method optimizing relations at sentence and document levels. Temporal relation identification is to identify temporal orders between events and time expressions. Various approaches of this task have been studied through the shared tasks TempEval (Verhagen et al., 2007 (Verhagen et al., , 2010)) . Not only identifying each temporal relation independently, some works also try to find multiple temporal relations jointly by logical constraints in Integer Linear Programming (Chambers",2012,False,False,False,True,False,False,True,"D, G",215,3,218
C12-2138,Cross-Lingual Identification of Ambiguous Discourse Connectives for Resource-Poor Language,"The lack of annotated corpora brings limitations in research of discourse classification for many languages. In this paper, we present the first effort towards recognizing ambiguities of discourse connectives, which is fundamental to discourse classification for resource-poor language such as Chinese. A language independent framework is proposed utilizing bilingual dictionaries, Penn Discourse Treebank and parallel data between English and Chinese. We start from translating the English connectives to Chinese using a bi-lingual dictionary. Then, the ambiguities in terms of senses a connective may signal are estimated based on the ambiguities of English connectives and word alignment information. Finally, the ambiguity between discourse usage and non-discourse usage were disambiguated using the co-training algorithm. Experimental results showed the proposed method not only built a high quality connective lexicon for Chinese but also achieved a high performance in recognizing the ambiguities. We also present a discourse corpus for Chinese which will soon become the first Chinese discourse corpus publicly available.",2012,True,False,False,True,False,False,False,"A, D",309,3,312
2012.eamt-1.63,Adjunct Alignment in Translation Data with an Application to Phrase Based Statistical Machine Translation,"Enriching statistical models with linguistic knowledge has been a major concern in Machine Translation (MT). In monolingual data, adjuncts are optional constituents contributing secondarily to the meaning of a sentence. One can therefore hypothesize that this secondary status is preserved in translation, and thus that adjuncts may align consistently with their adjunct translations, suggesting they form optional phrase pairs in parallel corpora. In this paper we verify this hypothesis on French-English translation data, and explore the utility of compiling adjunct-poor data for augmenting the training data of a phrase-based machine translation model.",2012,False,False,False,False,True,False,True,"E, G",233,3,236
W12-3717,On the Impact of Sentiment and Emotion Based Features in Detecting Online Sexual Predators,"According to previous work on pedophile psychology and cyberpedophilia, sentiments and emotions in texts could be a good clue to detect online sexual predation. In this paper, we have suggested a list of high-level features, including sentiment and emotion based ones, for detection of online sexual predation. In particular, since pedophiles are known to be emotionally unstable, we were interested in investigating if emotion-based features could help in their detection. We have used a corpus of predators' chats with pseudo-victims downloaded from www.perverted-justice.com and two negative datasets of different nature: cybersex logs available online and the NPS chat corpus. Naive Bayes classification based on the proposed features achieves accuracies of up to 94% while baseline systems of word and character n-grams can only reach up to 72%.",2012,False,False,False,True,False,False,True,"D, G",286,3,289
W12-3208,Text Reuse with {ACL}: (Upward) Trends,"With rapidly increasing community, a plethora of conferences related to Natural Language Processing and easy access to their proceedings make it essential to check the integrity and novelty of the new submissions. This study aims to investigate the trends of text reuse in the ACL submissions, if any. We carried a set of analyses on two spans of five years papers (the past and the present) of ACL using a publicly available text reuse detection application to notice the behaviour. In our study, we found some strong reuse cases which can be an indicator to establish a clear policy to handle text reuse for the upcoming editions of ACL. The results are anonymised.",2012,False,False,False,False,True,True,False,"E, F",242,3,245
C12-3001,Complex Predicates in {T}elugu: A Computational Perspective,"Complex predicates raise the question of how to encode them in computational lexicons. Their computational implementation in South Asian languages is in its infancy. This paper examines in detail the variety of complex predicates in Telugu revealing the syntactic process of their composition and the constraints on their formation. The framework used is First Phase Syntax (Ramchand 2008) . In this lexical semantic approach that ties together the constraints on the meaning and the argument structure of complex predicates, each verb breaks down into 3 sub-event heads which determine the nature of the verb. Complex predicates are formed by one verb subsuming the sub-event heads of another verb, and this is constrained in principled ways. The data analysed and the constraints developed in the paper are of use to linguists working on computational solutions for Telugu and other languages, for design and development of predicate structure functions in linguistic processors.",2012,False,False,False,False,True,False,True,"E, G",291,3,294
W12-5618,{H}indi Dependency Parsing using a combined model of Malt and {MST},"In this paper we present our experiments in parsing Hindi. We first explored Malt and MST parsers. Considering pros of both these parsers, we developed a hybrid approach combining the output of these two parsers in an intuitive manner. We report our results on both development and test data provided in the Hindi Shared Task on Parsing at workshop on MT and parsing in Indian Languages, Coling 2012. Our system secured labeled attachment score of 90.66% and 80.77% for gold standard and automatic tracks respectively. These accuracies are 3 rd best and 5 th best for gold standard and automatic tracks respectively.",2012,False,False,False,True,False,False,True,"D, G",245,3,248
N12-4001,100 Things You Always Wanted to Know about Linguistics But Were Afraid to Ask*,"Many NLP tasks have at their core a subtask of extracting the dependencies---who did what to whom---from natural language sentences. This task can be understood as the inverse of the problem solved in different ways by diverse human languages, namely, how to indicate the relationship between different parts of a sentence. Understanding how languages solve the problem can be extremely useful in both feature design and error analysis in the application of machine learning to NLP. Likewise, understanding cross-linguistic variation can be important for the design of MT systems and other multilingual applications. The purpose of this tutorial is to present in a succinct and accessible fashion information about the structure of human languages that can be useful in creating more linguistically sophisticated, more language independent, and thus more successful NLP systems.",2012,False,False,False,False,True,True,False,"E, F",269,3,272
P12-2023,Topic Models for Dynamic Translation Model Adaptation,"We propose an approach that biases machine translation systems toward relevant translations based on topic-specific contexts, where topics are induced in an unsupervised way using topic models; this can be thought of as inducing subcorpora for adaptation without any human annotation. We use these topic distributions to compute topic-dependent lexical weighting probabilities and directly incorporate them into our translation model as features. Conditioning lexical probabilities on the topic biases translations toward topicrelevant output, resulting in significant improvements of up to 1 BLEU and 3 TER on Chinese to English translation over a strong baseline.",2012,False,False,False,True,False,False,True,"D, G",229,3,232
F12-1095,Masques acoustiques et masques linguistiques de diff{\'e}rentes langues sur la reconnaissance de mots en fran{\c{c}}ais (Acoustical and linguistic masking effects of different languages on the comprehension of {F}rench words) [in {F}rench],"Nos recherches visent à explorer les interférences linguistiques qui ont lieu dans la situation de compréhension de la parole dans la parole. Pour cela, l'intensité, la nature et la langue du bruit de fond concurrent ont été manipulées. Des participants français ont réalisé une tâche de décision lexicale sur des items cibles français insérés à 0 dB et à -5 dB dans des masqueurs de parole ou des masqueurs de bruit fluctuant générés en français, gaélique irlandais et italien. A -5 dB, les résultats ont montré que le français et l'italien ont davantage masqué la parole cible que l'irlandais. La comparaison des performances obtenues entre les deux types de masqueurs (paroliers versus bruit fluctuant) a révélé que pour le français, la dégradation produite sur la parole cible était à la fois de nature acoustique et linguistique alors qu'elle n'a été que de nature acoustique pour l'italien et l'irlandais.",2012,False,False,False,False,True,False,True,"E, G",328,3,331
C12-2015,Phrase Structures and Dependencies for End-to-End Coreference Resolution,"We present experiments in data-driven coreference resolution comparing the effect of different syntactic representations provided as features in the coreference classification step: no syntax, phrase structure representations, dependency representations, and combinations of the representation types. We compare the end-to-end performance of a parametrized state-of-the-art coreference resolution system on the English data from the CoNLL 2012 shared task. On their own, phrase structures are more useful than dependencies, but the combinations yield highest performance and a significant improvement on the resolution of pronouns. Enriching phrase structure with dependency trees obtained from an independent parser is most helpful, but an extension of the predicted phrase structure using just pattern-based phraseto-dependency conversion seems to provide signals for the machine learning that cannot be distilled from phrase structure alone (despite intense feature selection). This is an interesting result for a highly configurational language: It is easier to learn generalizations over grammatical constraints on coreference when grammatical relations are explicitly provided.",2012,False,False,False,False,True,True,False,"E, F",315,3,318
2012.amta-commercial.1,Integrating {MT} with Digital Collections for Multilingual Information Access,"This paper describes the role of machine translation (MT) for multilingual information access, a service that is desired by digital libraries that wish to provide cross-cultural access to their collections. To understand the performance of MT, we have developed HeMT: an integrated multilingual evaluation platform (http://txcdk-v10.unt.edu/HeMT/) to facilitate human evaluation of machine translation. The results of human evaluation using HeMT on three online MT services are reported. Challenges and benefits of crowdsourcing and collaboration based on our experience are discussed. Additionally, we present the analysis of the translation errors and propose Multi-engine MT strategies to improve translation performance. Multilingual Information Access and Machine Translation Multilingual Information Access (MLIA) is a broad term referring to technologies that enable users to retrieve and use information from multilingual collections. The key of MLIA is to",2012,False,False,False,True,True,False,False,"D, E",288,3,291
P12-3009,A Web-based Evaluation Framework for Spatial Instruction-Giving Systems,"We demonstrate a web-based environment for development and testing of different pedestrian route instruction-giving systems. The environment contains a City Model, a TTS interface, a game-world, and a user GUI including a simulated street-view. We describe the environment and components, the metrics that can be used for the evaluation of pedestrian route instruction-giving systems, and the shared challenge which is being organised using this environment.",2012,True,False,False,False,False,False,True,"A, G",199,3,202
W12-4613,A Formal Model for Plausible Dependencies in {L}exicalized {T}ree {A}djoining {G}rammar,"Several authors have pointed out that the correspondence between LTAG derivation trees and dependency structures is not as direct as it may seem at first glance, and various proposals have been made to overcome this divergence. In this paper we propose to view the correspondence between derivation trees and dependency structures as a tree transformation during which the direction of some of the original edges is reversed. We show that, under this transformation, LTAG is able to induce both ill-nested dependency trees and dependency trees with gap-degree greater than 1, which is not possible under the direct reading of derivation trees as dependency trees.",2012,False,False,True,False,True,False,False,"E, C",238,3,241
2012.eamt-1.37,Hybrid Parallel Sentence Mining from Comparable Corpora,This paper presents a fast and accurate parallel sentence mining algorithm for comparable corpora called LEXACC based on the Cross-Language Information Retrieval framework combined with a trainable translation similarity measure that detects pairs of parallel and quasi-parallel sentences. LEXACC obtains state-of-the-art results in comparison with established approaches.,2012,False,False,True,True,False,False,False,"C, D",180,3,183
2012.eamt-1.21,{ACCEPT} - Automated Community Content Editing {P}or{T}al,"The use of machine translation (MT) is becoming more pervasive, and at the same time Web 2.0 paradigms are democratising content creation. However, right now these two trends are fairly incompatible since current MT engines cannot produce acceptable results for community content due to the extreme variability within the content. The ACCEPT project will address this issue by developing new technologies designed specifically to help MT work better in this environment. The research consists of three main strands: (i) new paradigms for ""minimally intrusive"" preediting content. (ii) the development of strategies for post-editing content which, rather than fully relying on trained translators, will also leverage the monolingual skills of volunteer domain experts. (iii) the use of the insights gained in the editing process and using innovative text analytics to improve the statistical MT engines themselves. The project brings together two of the world's leading research centres in applied MT (Universities of Edinburgh and Geneva), as well as the leading provider of content editing technologies (Acrolinx). In addition, there are two extremely experienced MT users in the project: the software company Symantec and the language services provider Lexcelera. Symantec and Lexcelera will also bring their community forum experience: Symantec through its user forums and Lexcelera through Traducteurs sans Frontières, a non-profit organisation supported by Lexcelera which provides pro bono humanitarian translations via a community of translators.",2012,True,False,False,True,False,False,False,"A, D",406,3,409
F12-1020,Les temps de traitement des voix de femmes et d{'}hommes sont-ils {\'e}quivalents ? (Are female and male voices processed equally fast?) [in {F}rench],"Cette étude a pour objet les temps de traitement des voix de femmes et d'hommes. Plusieurs auteurs ont mis en évidence la difficulté accrue de l'identification des voyelles lorsque ces dernières sont produites avec un F0 élevé (Ryalls & Lieberman, 1982) . Cela a-t-il des conséquences sur le traitement des mots ? Les voix de femmes sont-elles traitées plus lentement que les voix d'hommes ? Une expérience de détection de mots a été réalisée, afin de tester le temps de réponse des participants en fonction du genre du locuteur ayant produit le mot-cible. Les résultats suggèrent que les voix d'hommes et de femmes sont traitées par l'auditeur à vitesse équivalente, mais néanmoins comme deux entités différentes.",2012,False,False,False,False,True,True,False,"E,F",274,2,276
E12-1049,Experimenting with Distant Supervision for Emotion Classification,"We describe a set of experiments using automatically labelled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. By cross-validating between models trained on different labellings for the same six basic emotion classes, and testing on manually labelled data, we conclude that the method is suitable for some emotions (happiness, sadness and anger) but less able to distinguish others; and that different labelling conventions are more suitable for some emotions than others.",2012,False,False,False,False,True,False,True,"E, G",212,3,215
W12-1633,A Unified Probabilistic Approach to Referring Expressions,"This paper proposes a probabilistic approach to the resolution of referring expressions for task-oriented dialogue systems. The approach resolves descriptions, anaphora, and deixis in a unified manner. In this approach, the notion of reference domains serves an important role to handle context-dependent attributes of entities and references to sets. The evaluation with the REX-J corpus shows promising results.",2012,False,True,False,True,False,False,False,"B, D",191,3,194
W12-1623,A Reranking Model for Discourse Segmentation using Subtree Features,"This paper presents a discriminative reranking model for the discourse segmentation task, the first step in a discourse parsing system. Our model exploits subtree features to rerank Nbest outputs of a base segmenter, which uses syntactic and lexical features in a CRF framework. Experimental results on the RST Discourse Treebank corpus show that our model outperforms existing discourse segmenters in both settings that use gold standard Penn Treebank parse trees and Stanford parse trees.",2012,False,True,False,True,False,False,False,"B, D",211,3,214
E12-1085,Managing Uncertainty in Semantic Tagging,"Low interannotator agreement (IAA) is a well-known issue in manual semantic tagging (sense tagging). IAA correlates with the granularity of word senses and they both correlate with the amount of information they give as well as with its reliability. We compare different approaches to semantic tagging in WordNet, FrameNet, Prop-Bank and OntoNotes with a small tagged data sample based on the Corpus Pattern Analysis to present the reliable information gain (RG), a measure used to optimize the semantic granularity of a sense inventory with respect to its reliability indicated by the IAA in the given data set. RG can also be used as feedback for lexicographers, and as a supporting component of automatic semantic classifiers, especially when dealing with a very fine-grained set of semantic categories.",2012,False,False,False,True,True,False,False,"E, D",275,3,278
W12-2601,An Assessment of the Accuracy of Automatic Evaluation in Summarization,"Automatic evaluation has greatly facilitated system development in summarization. At the same time, the use of automatic evaluation has been viewed with mistrust by many, as its accuracy and correct application are not well understood. In this paper we provide an assessment of the automatic evaluations used for multi-document summarization of news. We outline our recommendations about how any evaluation, manual or automatic, should be used to find statistically significant differences between summarization systems. We identify the reference automatic evaluation metrics-ROUGE 1 and 2-that appear to best emulate human pyramid and responsiveness scores on four years of NIST evaluations. We then demonstrate the accuracy of these metrics in reproducing human judgements about the relative content quality of pairs of systems and present an empirical assessment of the relationship between statistically significant differences between systems according to manual evaluations, and the difference according to automatic evaluations. Finally, we present a case study of how new metrics should be compared to the reference evaluation, as we search for even more accurate automatic measures.",2012,False,False,False,False,True,True,False,"E, F",317,3,320
N12-1028,{NOMIT}: Automatic Titling by Nominalizing,"The important mass of textual documents is in perpetual growth and requires strong applications to automatically process information. Automatic titling is an essential task for several applications: 'No Subject' e-mails titling, text generation, summarization, and so forth. This study presents an original approach consisting in titling journalistic articles by nominalizing. In particular, morphological and semantic processing are employed to obtain a nominalized form which has to respect titles characteristics (in particular, relevance and catchiness). The evaluation of the approach, described in the paper, indicates that titles stemming from this method are informative and/or catchy.",2012,False,False,False,True,False,False,True,"D, G",238,3,241
P12-1081,Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations,"Prepositions and conjunctions are two of the largest remaining bottlenecks in parsing. Across various existing parsers, these two categories have the lowest accuracies, and mistakes made have consequences for downstream applications. Prepositions and conjunctions are often assumed to depend on lexical dependencies for correct resolution. As lexical statistics based on the training set only are sparse, unlabeled data can help ameliorate this sparsity problem. By including unlabeled data features into a factorization of the problem which matches the representation of prepositions and conjunctions, we achieve a new state-of-the-art for English dependencies with 93.55% correct attachments on the current standard. Furthermore, conjunctions are attached with an accuracy of 90.8%, and prepositions with an accuracy of 87.4%.",2012,False,False,False,True,False,True,False,"D, F",276,3,279
W12-5611,Morphological Processing for {E}nglish-{T}amil Statistical Machine Translation,"Various experiments from literature suggest that in statistical machine translation (SMT), applying either pre-processing or post-processing to morphologically rich languages leads to better translation quality. In this work, we focus on the English-Tamil language pair. We implement suffix-separation rules for both of the languages and evaluate the impact of this preprocessing on translation quality of the phrase-based as well as hierarchical model in terms of BLEU score and a small manual evaluation. The results confirm that our simple suffix-based morphological processing helps to obtain better translation performance. A by-product of our efforts is a new parallel corpus of 190k sentence pairs gathered from the web.",2012,True,False,False,False,False,False,True,"A, G",245,3,248
W12-3145,Kriya - The {SFU} System for Translation Task at {WMT}-12,"This paper describes our submissions for the WMT-12 translation task using Kriya -our hierarchical phrase-based system. We submitted systems in French-English and English-Czech language pairs. In addition to the baseline system following the standard MT pipeline, we tried ensemble decoding for French-English. The ensemble decoding method improved the BLEU score by 0.4 points over the baseline in newstest-2011. For English-Czech, we segmented the Czech side of the corpora and trained two different segmented models in addition to our baseline system.",2012,False,False,False,True,False,False,True,"D, G",227,3,230
D12-1019,Spectral Dependency Parsing with Latent Variables,"Recently there has been substantial interest in using spectral methods to learn generative sequence models like HMMs. Spectral methods are attractive as they provide globally consistent estimates of the model parameters and are very fast and scalable, unlike EM methods, which can get stuck in local minima. In this paper, we present a novel extension of this class of spectral methods to learn dependency tree structures. We propose a simple yet powerful latent variable generative model for dependency parsing, and a spectral learning method to efficiently estimate it. As a pilot experimental evaluation, we use the spectral tree probabilities estimated by our model to re-rank the outputs of a near state-of-theart parser. Our approach gives us a moderate reduction in error of up to 4.6% over the baseline re-ranker.",2012,False,True,True,False,False,False,False,"B, C",274,3,277
2012.freeopmt-1.1,The new machine translation: getting blood from a stone,"There is now a new sense of excitement in the air about machine translation. After fifty years of unfulfilled promises by linguists, the field has been taken over by computer scientists and reconstructed on scientific principles. A machine translation system requires massive amounts of data. Painstaking work with native informants, and playing examples off against counterexamples, takes far too long and is too unreliable. We now extract the massive amounts of data from massive quantities of naturally occurring text by sophisticated machine-learning techniques. If you doubt the value of this approach, you have only to look at Google Translate. We should be thankful for this new turn of events because massive amounts of data and sophisticated machine-learning techniques have a vital role to play in machine translation. But, as I will show in this talk, they are not enough to finish the job because much of the information required to build a creditable translation system cannot be extracted from examples, even in principle, however massive the number of them that one collects or how sophisticated the techniques one applies. It cannot be extracted because it is not there to be extracted. As my mother would say: ""You cannot get blood from a stone"".",2012,False,False,False,False,True,True,False,"E, F",349,3,352
W12-0101,Semantic Web based Machine Translation,"This paper describes the experimental combination of traditional Natural Language Processing (NLP) technology with the Semantic Web building stack in order to extend the expert knowledge required for a Machine Translation (MT) task. Therefore, we first give a short introduction in the state of the art of MT and the Semantic Web and discuss the problem of disambiguation being one of the common challenges in MT which can only be solved using world knowledge during the disambiguation process. In the following, we construct a sample sentence which demonstrates the need for world knowledge and design a prototypical program as a successful solution for the outlined translation problem. We conclude with a critical view on the developed approach.",2012,False,False,False,True,False,False,True,"D, G",252,3,255
W12-0407,Invited Talk: Current and Future Needs for Deception Detection in a Government Screening Environment,"The focus of this talk is on the applications and techniques currently used in government screening venues and on anticipated future applications. I will begin with a discussion of how and why the polygraph is used in a screening interview and touch on some of the newer techniques in deception detection using body movements, vocal and verbal behavior that are now being tested. We'll then look at some of the needs for deception detection and applications on our wish list. The talk will include cases where the current technology has been good and where it has not.",2012,False,False,False,False,True,False,True,"G, E",221,3,224
W12-4404,Latent Semantic Transliteration using {D}irichlet Mixture,"Transliteration has been usually recognized by spelling-based supervised models. However, a single model cannot deal with mixture of words with different origins, such as ""get"" in ""piaget"" and ""target"". Li et al. (2007) propose a class transliteration method, which explicitly models the source language origins and switches them to address this issue. In contrast to their model which requires an explicitly tagged training corpus with language origins, Hagiwara and Sekine (2011) have proposed the latent class transliteration model, which models language origins as latent classes and train the transliteration table via the EM algorithm. However, this model, which can be formulated as unigram mixture, is prone to overfitting since it is based on maximum likelihood estimation. We propose a novel latent semantic transliteration model based on Dirichlet mixture, where a Dirichlet mixture prior is introduced to mitigate the overfitting problem. We have shown that the proposed method considerably outperform the conventional transliteration models.",2012,False,True,True,False,False,False,False,"C, B",320,3,323
S12-1076,{ETS}: Discriminative Edit Models for Paraphrase Scoring,"Many problems in natural language processing can be viewed as variations of the task of measuring the semantic textual similarity between short texts. However, many systems that address these tasks focus on a single task and may or may not generalize well. In this work, we extend an existing machine translation metric, TERp (Snover et al., 2009a) , by adding support for more detailed feature types and by implementing a discriminative learning algorithm. These additions facilitate applications of our system, called PERP, to similarity tasks other than machine translation evaluation, such as paraphrase recognition. In the SemEval 2012 Semantic Textual Similarity task, PERP performed competitively, particularly at the two surprise subtasks revealed shortly before the submission deadline.",2012,False,False,False,True,False,False,True,"D, G",268,3,271
F12-2046,Transitions th{\'e}matiques : Annotation d{'}un corpus journalistique et premi{\`e}res analyses (Manual thematic annotation of a journalistic corpus : first observations and evaluation) [in {F}rench],"Le travail présenté dans cet article est centré sur la constitution d'un corpus de textes journalistiques annotés au niveau discursif d'un point de vue thématique. Le modèle d'annotation est une segmentation classique, à laquelle nous ajoutons un repérage de zones de transition entre unités thématiques. Nous faisons l'hypothèse que dans un texte bien construit, le scripteur fournit des indications aidant le lecteur à passer d'un sujet à un autre, l'identification de ces indices étant susceptible d'améliorer les procédures de segmentation automatique. Les annotations produites ont fait l'objet d'analyses quantitatives mettant en évidence un ensemble de propriétés des transitions entre thèmes.",2012,True,False,False,False,True,False,False,"A, E",256,3,259
W12-3122,Match without a Referee: Evaluating {MT} Adequacy without Reference Translations,"We address two challenges for automatic machine translation evaluation: a) avoiding the use of reference translations, and b) focusing on adequacy estimation. From an economic perspective, getting rid of costly hand-crafted reference translations (a) permits to alleviate the main bottleneck in MT evaluation. From a system evaluation perspective, pushing semantics into MT (b) is a necessity in order to complement the shallow methods currently used overcoming their limitations. Casting the problem as a cross-lingual textual entailment application, we experiment with different benchmarks and evaluation settings. Our method shows high correlation with human judgements and good results on all datasets without relying on reference translations.",2012,False,False,False,True,False,False,True,"D, G",246,3,249
C12-1176,Unsupervised Discriminative Induction of Synchronous Grammar for Machine Translation,"We present a global log-linear model for synchronous grammar induction, which is capable of incorporating arbitrary features. The parameters in the model are trained in an unsupervised fashion from parallel sentences without word alignments. To make parameter training tractable, we also propose a novel and efficient cube pruning based synchronous parsing algorithm. Using learned synchronous grammar rules with millions of features that contain rule level, word level and translation boundary information, we significantly outperform a competitive hierarchical phrased-based baseline system by +1.4 BLEU on average on three NIST test sets.",2012,False,True,True,False,False,False,False,"B, C",228,3,231
W12-6314,Rules-based {C}hinese Word Segmentation on {M}icro{B}log for {CIPS}-{SIGHAN} on {CLP}2012,"In this evaluation, we have taken part in the task of the Word Segmentation on Chinese MicroBlog. In this task, after analysing the feature of the MicroBlog and the result of our original Chinese word segmentation system, four Optimization Rules are proposed to optimize the segmentation algorithm for Chinese word segmentation on MicroBlog corpora. The optimized segmentation system is based on character-based and word-based Conditional Random Fields (CRFs). Experiments show that the optimized segmentation system can obviously improve the performance of CWS on MicroBlog corpora.",2012,False,False,False,True,False,False,True,"D, G",223,3,226
C12-1128,Exploiting Category-Specific Information for Multi-Document Summarization,"We show that by making use of information common to document sets belonging to a common category, we can improve the quality of automatically extracted content in multi-document summaries. This simple property is widely applicable in multi-document summarization tasks, and can be encapsulated by the concept of category-specific importance (CSI). Our experiments show that CSI is a valuable metric to aid sentence selection in extractive summarization tasks. We operationalize the computation CSI of sentences through the introduction of two new features that can be computed without needing any external knowledge. We also generalize this approach, showing that when manually-curated document-to-category mappings are unavailable, performing automatic categorization of document sets also improves summarization performance. We have incorporated these features into a simple, freely available, open-source extractive summarization system, called SWING. In the recent TAC-2011 guided summarization task, SWING outperformed all other participant summarization systems as measured by automated ROUGE measures.",2012,False,False,False,True,False,False,True,"D, G",310,3,313
W12-3120,Non-Linear Models for Confidence Estimation,"This paper describes our work with the data distributed for the WMT'12 Confidence Estimation shared task. Our contribution is twofold: i) we first present an analysis of the data which highlights the difficulty of the task and motivates our approach; ii) we show that using non-linear models, namely random forests, with a simple and limited feature set, succeeds in modeling the complex decisions required to assess translation quality and achieves results that are on a par with the second best results of the shared task.",2012,False,False,False,True,True,False,False,"E, D",218,3,221
W12-3153,{T}witter Translation using Translation-Based Cross-Lingual Retrieval,"Microblogging services such as Twitter have become popular media for real-time usercreated news reporting. Such communication often happens in parallel in different languages, e.g., microblog posts related to the same events of the Arab spring were written in Arabic and in English. The goal of this paper is to exploit this parallelism in order to eliminate the main bottleneck in automatic Twitter translation, namely the lack of bilingual sentence pairs for training SMT systems. We show that translation-based cross-lingual information retrieval can retrieve microblog messages across languages that are similar enough to be used to train a standard phrasebased SMT pipeline. Our method outperforms other approaches to domain adaptation for SMT such as language model adaptation, meta-parameter tuning, or self-translation.",2012,True,False,False,True,False,False,False,"A, D",268,3,271
W12-6313,Cascaded {C}hinese {W}eibo Segmentation Based on {CRF}s,"With the developments of Web2.0, the process for the data on Internet becomes necessary. This Paper reports our work for Chinese weibo segmentation in the 2012 CIPS-SIGHAN bakeoff. In order to improve the recognition accuracy of out-ofvocabulary words, we propose a cascaded model which first segments and disambiguates in-vocabulary words, then recovers out-of-vocabulary words from the fragments. Both the two process are trained by a character-based CRFs model with useredited external vocabulary. The final performance on the test data shows that our system achieves a promising result.",2012,False,True,False,True,False,False,False,"B, D",239,3,242
N12-1074,Predicting Responses to Microblog Posts,"Microblogging networks serve as vehicles for reaching and influencing users. Predicting whether a message will elicit a user response opens the possibility of maximizing the virality, reach and effectiveness of messages and ad campaigns on these networks. We propose a discriminative model for predicting the likelihood of a response or a retweet on the Twitter network. The approach uses features derived from various sources, such as the language used in the tweet, the user's social network and history. The feature design process leverages aggregate statistics over the entire social network to balance sparsity and informativeness. We use real-world tweets to train models and empirically show that they are capable of generating accurate predictions for a large number of tweets.",2012,False,False,False,True,False,False,True,"D, G",258,3,261
C12-1161,Semi-Supervised Semantic Role Labeling: Approaching from an Unsupervised Perspective,"Reducing the reliance of semantic role labeling (SRL) methods on human-annotated data has become an active area of research. However, the prior work has largely focused on either (1) looking into ways to improve supervised SRL systems by producing surrogate annotated data and reducing sparsity of lexical features or (2) considering completely unsupervised semantic role induction settings. In this work, we aim to link these two veins of research by studying how unsupervised techniques can be improved by exploiting small amounts of labeled data. We extend a state-of-the-art Bayesian model for unsupervised semantic role induction to better accommodate for annotated sentences. Our semi-supervised method outperforms a strong supervised baseline when only a small amount of labeled data is available.",2012,False,True,False,True,False,False,False,"B, D",270,3,273
C12-3015,"Dealing with the Grey Sheep of the {R}omanian Gender System, the Neuter","Romanian has been traditionally seen as bearing three lexical genders: masculine, feminine, and neuter, although it has always been known to have only two agreement patterns (for masculine and feminine). Previous machine learning classifiers which have attempted to discriminate Romanian nouns according to gender have taken as input only the singular form, either presupposing the traditional tripartite analysis, or using additional information from case inflected forms. We present here a tool based on two parallel support vector machines using n-gram features from the singular and from the plural, which distinguish the neuter.",2012,False,False,False,True,True,False,False,"D, E",231,3,234
S12-1093,{FCC}: Three Approaches for Semantic Textual Similarity,"In this paper we describe the three approaches we submitted to the Semantic Textual Similarity task of SemEval 2012. The first approach considers to calculate the semantic similarity by using the Jaccard coefficient with term expansion using synonyms. The second approach uses the semantic similarity reported by Mihalcea in (Mihalcea et al., 2006) . The third approach employs Random Indexing and Bag of Concepts based on context vectors. We consider that the first and third approaches obtained a comparable performance, meanwhile the second approach got a very poor behavior. The best ALL result was obtained with the third approach, with a Pearson correlation equal to 0.663.",2012,False,False,False,True,False,False,True,"D, G",252,3,255
F12-1070,Percol0 - un syst{\`e}me multimodal de d{\'e}tection de personnes dans des documents vid{\'e}o (Percol0 - A multimodal person detection system in video documents) [in {F}rench],"Identifier et nommer à chaque instant d'une vidéo l'ensemble des personnes présentes à l'image ou s'exprimant dans la bande son fait parti de ces nouveaux outils de fouille de données. D'un point de vue scientifique la reconnaissance de personnes dans des documents audiovisuels est un problème difficile à cause des différentes ambiguïtés que présentent l'audio, la vidéo et leur association. Nous présentons dans cette étude le système PERCOL0, développé dans le cadre du défi REPERE, permettant de détecter la présence de personnes (audible et/ou visuelle) dans des documents vidéo, sans utiliser de modèles de locuteurs a priori.",2012,True,False,False,False,False,False,True,"A, G",250,3,253
C12-1148,Improving Supervised Sense Disambiguation with Web-Scale Selectors,"This paper introduces a method to improve supervised word sense disambiguation performance by including a new class of features which leverage contextual information from large unannotated corpora. This new feature class, selectors, contains words that appear in other corpora with the same local context as a given lexical instance. We show that support vector sense classifiers trained with selectors achieve higher accuracy than those trained only with standard features, producing error reductions of 15.4% and 6.9% on standard coarse-grained and fine-grained disambiguation tasks respectively. Furthermore, we find an error reduction of 9.3% when including selectors for the classification step of named-entity recognition over a representative sample of OntoNotes. These significant improvements come free of any human annotation cost, only requiring unlabeled Web-Scale corpora.",2012,False,False,False,True,False,False,True,"D, G",283,3,286
C12-1015,{P}rague {D}ependency {T}reebank 2.5 {--} a Revisited Version of {PDT} 2.0,"We present the Prague Dependency Treebank 2.5, the newest version of PDT and the first to be released under a free license. We show the benefits of PDT 2.5 in comparison to other state-of-the-art treebanks. We present the new features of the 2.5 release, how they were obtained and how reliably they are annotated. We also show how they can be used in queries and how they are visualised with tools released alongside the treebank.",2012,True,False,False,False,True,False,False,"A, E",215,3,218
2012.amta-caas14.3,Developing an Open-domain {E}nglish-{F}arsi Translation System Using {AFEC}: Amirkabir Bilingual {F}arsi-{E}nglish Corpus,"The translation quality of Statistical Machine Translation (SMT) depends on the amount of input data especially for morphologically rich languages. Farsi (Persian) language is such a language which has few NLP resources. It also suffers from the non-standard written characters which causes a large variety in the written form of each character. Moreover, the structural difference between Farsi and English results in long range reorderings which cannot be modeled by common SMT reordering models. Here, we try to improve the existing English-Farsi SMT system focusing on these challenges first by expanding our bilingual limited-domain corpus to an open-domain one. Then, to alleviate the character variations, a new text normalization algorithm is offered. Finally, some handcrafted rules are applied to reduce the structural differences. Using the new corpus, the experimental results showed 8.82% BLEU improvement by applying new normalization method and 9.1% BLEU when rules are used.",2012,True,False,False,True,False,False,False,"A, D",304,3,307
W12-0116,Linguistically-Augmented {B}ulgarian-to-{E}nglish Statistical Machine Translation Model,"In this paper, we present our linguisticallyaugmented statistical machine translation model from Bulgarian to English, which combines a statistical machine translation (SMT) system (as backbone) with deep linguistic features (as factors). The motivation is to take advantages of the robustness of the SMT system and the linguistic knowledge of morphological analysis and the hand-crafted grammar through system combination approach. The preliminary evaluation has shown very promising results in terms of BLEU scores (38.85) and the manual analysis also confirms the high quality of the translation the system delivers.",2012,False,True,False,True,False,False,False,"B, D",226,3,229
S12-1039,{UC}oncordia: {CL}a{C} Negation Focus Detection at *{S}em 2012,"Simply detecting negation cues is not sufficient to determine the semantics of negation, scope and focus must be taken into account. While scope detection has recently seen repeated attention, the linguistic notion of focus is only now being introduced into computational work. The *Sem2012 Shared Task is pioneering this effort by introducing a suitable dataset and annotation guidelines. CLaC's NegFocus system is a solid baseline approach to the task.",2012,True,False,False,False,False,False,True,"A, G",202,3,205
P12-2056,Enhancing Statistical Machine Translation with Character Alignment,"The dominant practice of statistical machine translation (SMT) uses the same Chinese word segmentation specification in both alignment and translation rule induction steps in building Chinese-English SMT system, which may suffer from a suboptimal problem that word segmentation better for alignment is not necessarily better for translation. To tackle this, we propose a framework that uses two different segmentation specifications for alignment and translation respectively: we use Chinese character as the basic unit for alignment, and then convert this alignment to conventional word alignment for translation rule induction. Experimentally, our approach outperformed two baselines: fully word-based system (using word for both alignment and translation) and fully character-based system, in terms of alignment quality and translation performance.",2012,False,False,False,True,False,True,False,"D, F",256,3,259
W12-0901,Distinguishing Contact-Induced Change from Language Drift in Genetically Related Languages,"Languages evolve, undergoing repeated small changes, some with permanent effect and some not. Changes affecting a language may be independent or contactinduced. Independent changes arise internally or, if externally, from non-linguistic causes. En masse, such changes cause isolated languages to drift apart in lexical form and grammatical structure. Contactinduced changes can happen when languages share speakers, or when their speakers are in contact. Frequently, languages in contact are related, having a common ancestor from which they still retain visible structure. This relatedness makes it difficult to distinguish contact-induced change from inherited similarities. In this paper, we present a simulation of contact-induced change. We show that it is possible to distinguish contact-induced change from independent change given (a) enough data, and (b) that the contactinduced change is strong enough. For a particular model, we determine how much data is enough to distinguish these two cases at p < 0.05.",2012,False,False,False,False,True,True,False,"E,F",307,2,309
W12-3018,Annotated {G}igaword,"We have created layers of annotation on the English Gigaword v.5 corpus to render it useful as a standardized corpus for knowledge extraction and distributional semantics. Most existing large-scale work is based on inconsistent corpora which often have needed to be re-annotated by research teams independently, each time introducing biases that manifest as results that are only comparable at a high level. We provide to the community a public reference set based on current state-of-the-art syntactic analysis and coreference resolution, along with an interface for programmatic access. Our goal is to enable broader involvement in large-scale knowledge-acquisition efforts by researchers that otherwise may not have had the ability to produce such a resource on their own.",2012,True,False,False,False,True,False,False,"A, E",259,3,262
2012.tc-1.14,Beyond translation memories: finding similar documents in comparable corpora,"This paper presents our most recent research in the context of TTC, an EU funded research project, on using the Web to retrieve terminologically rich texts in a specific domain, and to find similar documents in such comparable corpora. The aim of this work is to provide tools for semi-automatic construction of bilingual term lists.",2012,True,False,False,False,False,False,True,"A, G",182,3,185
D12-1138,A Discriminative Model for Query Spelling Correction with Latent Structural {SVM},"Discriminative training in query spelling correction is difficult due to the complex internal structures of the data. Recent work on query spelling correction suggests a two stage approach a noisy channel model that is used to retrieve a number of candidate corrections, followed by discriminatively trained ranker applied to these candidates. The ranker, however, suffers from the fact the low recall of the first, suboptimal, search stage. This paper proposes to directly optimize the search stage with a discriminative model based on latent structural SVM. In this model, we treat query spelling correction as a multiclass classification problem with structured input and output. The latent structural information is used to model the alignment of words in the spelling correction process. Experiment results show that as a standalone speller, our model outperforms all the baseline systems. It also attains a higher recall compared with the noisy channel model, and can therefore serve as a better filtering stage when combined with a ranker.",2012,False,True,True,False,False,False,False,"B, C",309,3,312
P12-1035,A Joint Model for Discovery of Aspects in Utterances,"We describe a joint model for understanding user actions in natural language utterances. Our multi-layer generative approach uses both labeled and unlabeled utterances to jointly learn aspects regarding utterance's target domain (e.g. movies), intention (e.g., finding a movie) along with other semantic units (e.g., movie name). We inject information extracted from unstructured web search query logs as prior information to enhance the generative process of the natural language utterance understanding model. Using utterances from five domains, our approach shows up to 4.5% improvement on domain and dialog act performance over cascaded approach in which each semantic component is learned sequentially and a supervised joint learning model (which requires fully labeled data).",2012,False,True,False,True,False,False,False,"B, D",263,3,266
P12-1016,A Class-Based Agreement Model for Generating Accurately Inflected Translations,"When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders.",2012,False,True,False,True,False,False,False,"B, D",255,3,258
F12-5006,Solution Proxem d{'}analyse s{\'e}mantique verticale : adaptation au domaine des Ressources Humaines (How to adapt the Proxem semantic analysis engine to the Human Resources field) [in {F}rench],"Proxem développe depuis 2007 une plate-forme de traitement du langage, Antelope, qui permet de construire rapidement des applications sémantiques verticales (par exemple, pour l'e-réputation, la veille économique ou l'analyse d'avis de consommateurs). Antelope a servi à créer une solution pour les Ressources Humaines, utilisée notamment par l'APEC, permettant (1) d'extraire de l'information à partir d'offres et de CVs et (2) de trouver les offres d'emploi correspondant le mieux à un CV (ou réciproquement). Nous présentons ici l'adaptation d'Antelope à un domaine particulier, en l'occurrence les RH.",2012,False,False,False,True,False,False,True,"G, D",262,3,265
N12-1052,Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure,"It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure. While previous work has focused primarily on English, we extend these results to other languages along two dimensions. First, we show that these results hold true for a number of languages across families. Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction. Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.",2012,False,False,True,True,False,False,False,"C, D",294,3,297
W12-5603,{T}amil {NER} - Coping with Real Time Challenges,"This paper describes various challenges encountered while developing an automatic Named Entity Recognition (NER) using Conditional Random Fields (CRFs) for Tamil. We also discuss how we have overcome some of these challenges. Though most of the challenges in NER discussed here are common to many Indian languages, in this work the focus is on Tamil, a South Indian language belonging to Dravidian language family. The corpus used in this work is the web data. The web data consisted of news paper articles, articles on blog sites and other online web portals.",2012,False,False,False,False,True,False,True,"E, G",225,3,228
W12-4623,Incremental Derivations in {CCG},"This paper presents a research note on the degree to which strictly incremental derivations (that is derivations which are fully connected at each point in time) are possible in Combinatory Categorial Grammar (CCG). There has been a recent surge of interest in incremental parsing both from the psycholinguistic community in a bid to build psycholinguistically plausible models of language comprehension, and from the NLP community for building systems that process language greedily in order to achieve shorter response times in spoken dialogue systems, for speech recognition and machine translation. CCG allows for a variety of different derivations, including derivations that are almost fully incremental. This paper explores the syntactic constructions for which full incrementality is not possible in standard CCG, a point that recent work on incremental CCG parsing has glossed over.",2012,False,False,False,False,True,True,False,"E,F",283,2,285
F12-2016,Simplification syntaxique de phrases pour le fran{\c{c}}ais (Syntactic Simplification for {F}rench Sentences) [in {F}rench],"Cet article présente une méthode de simplification syntaxique de textes français. La simplification syntaxique a pour but de rendre des textes plus abordables en simplifiant les éléments qui posent problème à la lecture. La méthode mise en place à cette fin s'appuie tout d'abord sur une étude de corpus visant à étudier les phénomènes linguistiques impliqués dans la simplification de textes en français. Nous avons ainsi constitué un corpus parallèle à partir d'articles de Wikipédia et Vikidia, ce qui a permis d'établir une typologie de simplifications. Dans un second temps, nous avons implémenté un système qui opère des simplifications syntaxiques à partir de ces observations. Des règles de simplification ont été décrites afin de générer des phrases simplifiées. Un module sélectionne ensuite le meilleur ensemble de phrases. Enfin, nous avons mené une évaluation de notre système montrant qu'environ 80% des phrases générées sont correctes.",2012,True,False,False,True,False,False,False,"A, D",314,3,317
U12-1015,{L}a{BB}-{CAT}: an Annotation Store,"ONZE Miner"", an open-source tool for storing and automatically annotating Transcriber transcripts, has been redeveloped to use ""annotation graphs"" as its data model. The annotation graph framework provides the new software, ""LaBB-CAT"", greater flexibility for automatic and manual annotation of corpus data at various independent levels of granularity, and allows more sophisticated annotation structures, opening up new possibilities for corpus mining and conversion between tool formats.",2012,True,True,False,False,False,False,False,"A, B",204,3,207
O12-1018,Metaphor and Metonymy in Apple Daily{'}s Headlines,"The current study focuses on the similarities and differences of conceptual metaphor and metonymy between each genre in newspaper headlines. Headlines in news articles in Apple Daily from May 21 st to May 27 th were collected and analyzed. There are three basic findings. First, blocks for entertainment and sports used, in proportion, more metaphors and metonymies than any other blocks. Second, the idea of fighting was the most basic base for metaphors in Apple Daily. Third, TOPIC FOR SUBJECT was widely implemented to be economic in discourse. However, there may be more genres not included in Apple Daily. Also, the ways of categorization may not be specific enough for each block. Future studies are encouraged to further explore other genres excluded in the current study.",2012,False,False,False,False,True,True,False,"E,F",270,2,272
C12-1019,Thread Specific Features are Helpful for Identifying Subjectivity Orientation of Online Forum Threads,"Subjectivity analysis has been actively used in various applications such as opinion mining of customer reviews in online review sites, question-answering in CQA sites, multi-document summarization, etc. However, there has been very little focus on subjectivity analysis in the domain of online forums. Online forums contain huge amounts of user-generated data in the form of discussions between forum members on specific topics and are a valuable source of information. In this work, we perform subjectivity analysis of online forum threads. We model the task as a binary classification of threads in one of the two classes: subjective and nonsubjective. Unlike previous works on subjectivity analysis, we use several non-lexical threadspecific features for identifying subjectivity orientation of threads. We evaluate our methods by comparing them with several state-of-the-art subjectivity analysis techniques. Experimental results on two popular online forums demonstrate that our methods outperform strong baselines in most of the cases.",2012,True,False,False,True,False,False,False,"A, D",304,3,307
C12-2019,{C}hinese Noun Phrase Coreference Resolution: Insights into the State of the Art,"Compared to the amount of research on English coreference resolution, relatively little work has been done on Chinese coreference resolution. Worse still, it has been difficult to determine the state of the art in Chinese coreference resolution, owing in part to the lack of a standard evaluation dataset. The organizers of the CoNLL-2012 shared task, Modeling Unrestricted Multilingual Coreference in OntoNotes, have recently addressed this issue by providing standard training and test sets for developing and evaluating Chinese coreference resolvers. We aim to gain insights into the state of the art via extensive experimentation with our Chinese resolver, which is ranked first in the shared task on the Chinese test data.",2012,False,False,False,False,True,False,True,"E, G",254,3,257
2012.amta-commercial.7,An {LSP} Perspective: Business {\&} Process Challenges Implementing {MT} Solutions: Is {MT} Delivering Expected Value?,"Machine translation resurfaced as a viable business solution about 5 years ago, with much hype. With the amount of content requiring translation, and a mellowing of user expectations about translation quality, it seemed there was real business value in developing machine translation solutions. Since then, however, the discounts offered to enterprise customers have remained stubbornly meager in the 10-20% range, with high, up-front costs-far from the anticipated savings. This paper provides an overview of the challenges encountered in the value chain between customer and Language Service Provider (LSP) which keep translation costs high and limit machine translation adoption, discusses existing and potential solutions to these challenges, and offers suggestions on how to enlist the support of the LSP and freelance translator community to address these challenges.",2012,False,False,False,False,True,False,True,"E, G",273,3,276
S12-1027,An Evaluation of Graded Sense Disambiguation using Word Sense Induction,"Word Sense Disambiguation aims to label the sense of a word that best applies in a given context. Graded word sense disambiguation relaxes the single label assumption, allowing for multiple sense labels with varying degrees of applicability. Training multi-label classifiers for such a task requires substantial amounts of annotated data, which is currently not available. We consider an alternate method of annotating graded senses using Word Sense Induction, which automatically learns the senses and their features from corpus properties. Our work proposes three objective to evaluate performance on the graded sense annotation task, and two new methods for mapping between sense inventories using parallel graded sense annotations. We demonstrate that sense induction offers significant promise for accurate graded sense annotation.",2012,True,False,False,True,False,False,False,"A, D",257,3,260
F12-2017,{\'E}tude comparative entre trois approches de r{\'e}sum{\'e} automatique de documents arabes (Comparative Study of Three Approaches to Automatic Summarization of {A}rabic Documents) [in {F}rench],"Dans cet article, nous proposons une étude comparative entre trois approches pour le résumé automatique de documents arabes. Ainsi, nous avons proposé trois méthodes pour l'extraction des phrases les plus représentatives d'un document. La première méthode se base sur une approche symbolique, la deuxième repose sur une approche numérique et la troisième se base sur une approche hybride. Ces méthodes sont implémentées respectivement par le système ARSTResume, le système R.I.A et le système HybridResume. Nous présentons, par la suite, les résultats obtenus par les trois systèmes et nous procédons à une étude comparative entre les résultats obtenus afin de souligner les avantages et les limites de chaque méthode. Les résultats de l'évaluation ont montré que l'approche numérique est plus performante que l'approche symbolique au niveau des textes longs. Mais, l'intégration de ces deux approches en une approche hybride aboutit aux résultats les plus performants dans notre corpus de textes. ABSTRACT________________________________________________________________________________________________ Comparative study of three approaches to automatic summarization of Arabic documents In this paper, we propose a comparative study between three approaches for automatic summarization of Arabic documents. Thus, we proposed three methods for extracting most representative sentences of a document. The first method is based on a symbolic approach, the second is relied on a numerical approach and the third is based on a hybrid approach. These methods are implemented respectively by the ARSTResume, R.I.A and HybridResume systems. Then, we present the results obtained by the three systems and we conduct a comparative study between the obtained results in order to highlight the advantages and limitations of each method. The evaluation results showed that the numerical approach has better performances than the symbolic approach. But, combining into a hybrid approach achieved the best results for our text corpus. MOTS-CLES : Résumé automatique, approche symbolique, approche numérique, approche hybride, document arabe.",2012,False,False,False,True,False,True,False,"D, F",498,3,501
O12-5003,領域相關詞彙極性分析及文件情緒分類之研究 (Domain Dependent Word Polarity Analysis for Sentiment Classification) [In {C}hinese],The researches of sentiment analysis aim at exploring the emotional state of writers. The analysis highly depends on the application domains. Analyzing sentiments of,2012,False,False,False,False,True,False,True,"E, G",147,3,150
W12-0302,From Drafting Guideline to Error Detection: Automating Style Checking for Legislative Texts,"This paper reports on the development of methods for the automated detection of violations of style guidelines for legislative texts, and their implementation in a prototypical tool. To this aim, the approach of error modelling employed in automated style checkers for technical writing is enhanced to meet the requirements of legislative editing. The paper identifies and discusses the two main sets of challenges that have to be tackled in this process: (i) the provision of domain-specific NLP methods for legislative drafts, and (ii) the concretisation of guidelines for legislative drafting so that they can be assessed by machine. The project focuses on German-language legislative drafting in Switzerland.",2012,False,False,False,True,False,False,True,"D, G",243,3,246
W12-0104,An Empirical Evaluation of Stop Word Removal in Statistical Machine Translation,"In this paper we evaluate the possibility of improving the performance of a statistical machine translation system by relaxing the complexity of the translation task by removing the most frequent and predictable terms from the target language vocabulary. Afterwards, the removed terms are inserted back in the relaxed output by using an n-gram based word predictor. Empirically, we have found that when these words are omitted from the text, the perplexity of the text decreases, which may imply the reduction of confusion in the text. We conducted some machine translation experiments to see if this perplexity reduction produced a better translation output. While the word prediction results exhibits 77% accuracy in predicting 40% of the most frequent words in the text, the perplexity reduction did not help to produce better translations.",2012,False,False,False,True,False,True,False,"D, F",270,3,273
2012.amta-papers.19,Detailed Analysis of Different Strategies for Phrase Table Adaptation in {SMT},"This paper gives a detailed analysis of different approaches to adapt a statistical machine translation system towards a target domain using small amounts of parallel in-domain data. Therefore, we investigate the differences between the approaches addressing adaptation on the two main steps of building a translation model: The candidate selection and the phrase scoring. For the latter step we characterized the differences by four key aspects. We performed experiments on two different tasks of speech translation and analyzed the influence of the different aspects on the overall translation quality. On both tasks we could show significant improvements by using the presented adaptation techniques.",2012,False,False,False,True,True,False,False,"D, E",229,3,232
S12-1077,{S}bdlrhmn: A Rule-based Human Interpretation System for Semantic Textual Similarity Task,"In this paper, we describe the system architecture used in the Semantic Textual Similarity (STS) task 6 pilot challenge. The goal of this challenge is to accurately identify five levels of semantic similarity between two sentences: equivalent, mostly equivalent, roughly equivalent, not equivalent but sharing the same topic and no equivalence. Our participations were two systems. The first system (rule-based) combines both semantic and syntax features to arrive at the overall similarity. The proposed rules enable the system to adequately handle domain knowledge gaps that are inherent when working with knowledge resources. As such one of its main goals, the system suggests a set of domain-free rules to help the human annotator in scoring semantic equivalence of two sentences. The second system is our baseline in which we use the Cosine Similarity between the words in each sentence pair.",2012,False,False,False,True,False,False,True,"D, G",285,3,288
Y12-1053,{C}hinese Sentiments on the Clouds: A Preliminary Experiment on Corpus Processing and Exploration on Cloud Service,"This study aims to propose a novel pipeline architecture in building and analyzing largescaled linguistic data on the cloud-based environment, an experimental survey on Chinese Polarity Lexicon will be taken as an example. In this experiment, data are evaluated and tagged by applying crowd sourcing approach using online Google Form. All the data processing and analyzing procedures are completed on-the-fly with free cloud services automatically and dynamically.The paper shows the advantages of using cloud-based environment in collecting and processing linguistic data which can be easily scaled up and efficiently computed. In addition, the proposed pipeline architecture also brings out the potentials of merging with mashups from the web for representing and exploring corpus data of various types.",2012,False,True,False,False,False,False,True,"B, G",253,3,256
Y12-1067,Compositional Mechanisms of {J}apanese Numeral Classifiers,"This paper suggests that Generative Lexicon Theory (Pustejovsky, 1995 (Pustejovsky, , 2006 (Pustejovsky, , 2011) ) offers a new analysis of numeral classifiers, focusing on Japanese having various kinds of classifiers. It is often said that classifiers agree with quantified nouns, that is, the nouns have to match the semantic requirements of the classifiers. This paper examines their lexical structures and compositional mechanisms. Though Huang and Ahrens (2003) explain the compositional mechanisms between the classifiers and the quantified nouns using ""coercion"" instead of the agreement, this paper indicates that other mechanisms including Type Matching (Pustejovsky, 2011) also occur in Japanese depending on the type required by the classifier and the source type of the quantified noun, following Mano and Yonezawa's (to appear) suggestion.",2012,False,False,False,False,True,True,False,"E,F",299,2,301
W12-3213,Linking Citations to their Bibliographic references,"In this paper we describe our participation in the contributed task at ACL Special workshop 2012. We contribute to the goal of enriching the textual content of ACL Anthology by identifying the citation contexts in a paper and linking them to their corresponding references in the bibliography section. We use Parscit, to process the Bibliography of each paper. Pattern matching heuristics are then used to connect the citations with their references. Furthermore, we prepared a small evaluation dataset, to test the efficiency of our method. We achieved 95% precision and 80% recall on this dataset.",2012,True,False,False,False,False,False,True,"G, A",232,3,235
C12-1139,Bilingual Lexicon Construction from Comparable Corpora via Dependency Mapping,"Bilingual lexicon construction (BLC) from comparable corpora is based on the idea that bilingual similar words tend to occur in similar contexts, usually of words. This, however, introduces noise and leads to low performance. This paper proposes a bilingual dependency mapping model for BLC which encodes a word's context as a combination of its dependent words and their relationships. This combination can provide more reliable clues than mere context words for bilingual translation words. We further demonstrate that this kind of bilingual dependency mappings can be successfully generated and maximally exploited without human intervention. The experiments on BLC from English to Chinese show that, by mapping context words and their dependency relationships simultaneously when calculating the similarity between bilingual words, our approach significantly outperforms a state-of-the-art one by ~14 units in accuracy for frequently occurring noun pairs and similarly, though in a less degree, for nouns and verbs in a wide frequency range. This justifies the effectiveness of our dependency mapping model for BLC.",2012,False,True,True,False,False,False,False,"B, C",315,3,318
C12-1082,Towards a Generic and Flexible Citation Classifier Based on a Faceted Classification Scheme,"Citations are a valuable resource for characterizing scientific publications that has already been used in applications such as summarization and information retrieval. These applications could be even better served by expanding citation information. We aim to achieve this by extracting and classifying citation information from the text, so that subsequent applications may make use of it. We make three contributions to the advancement of fine-grained citation classification. First, our work uses a standard classification scheme for citations that was developed independently of automatic classification and therefore is not bound to any particular citation application. Second, to address the lack of available annotated corpora and reproducible results for citation classification, we are making available a manually-annotated corpus as a benchmark for further citation classification research. Third, we introduce new features designed for citation classification and compare them experimentally with previously proposed citation features, showing that these new features improve classification accuracy.",2012,True,False,False,True,False,False,False,"A, D",292,3,295
W12-0514,Incorporating Linguistic Knowledge in Statistical Machine Translation: Translating Prepositions,"Prepositions are hard to translate, because their meaning is often vague, and the choice of the correct preposition is often arbitrary. At the same time, making the correct choice is often critical to the coherence of the output text. In the context of statistical machine translation, this difficulty is enhanced due to the possible long distance between the preposition and the head it modifies, as opposed to the local nature of standard language models. In this work we use monolingual language resources to determine the set of prepositions that are most likely to occur with each verb. We use this information in a transfer-based Arabic-to-Hebrew statistical machine translation system. We show that incorporating linguistic knowledge on the distribution of prepositions significantly improves the translation quality.",2012,False,False,False,True,False,False,True,"D, G",266,3,269
J12-4003,Semantic Role Labeling of Implicit Arguments for Nominal Predicates,"Nominal predicates often carry implicit arguments. Recent work on semantic role labeling has focused on identifying arguments within the local context of a predicate; implicit arguments, however, have not been systematically examined. To address this limitation, we have manually annotated a corpus of implicit arguments for ten predicates from NomBank. Through analysis of this corpus, we find that implicit arguments add 71% to the argument structures that are present in NomBank. Using the corpus, we train a discriminative model that is able to identify implicit arguments with an F 1 score of 50%, significantly outperforming an informed baseline model. This article describes our investigation, explores a wide variety of features important for the task, and discusses future directions for work on implicit argument identification.",2012,True,False,False,True,False,False,False,"A, D",266,3,269
W12-2404,Temporal Classification of Medical Events,"We investigate the task of assigning medical events in clinical narratives to discrete time-bins. The time-bins are defined to capture when a medical event occurs relative to the hospital admission date in each clinical narrative. We model the problem as a sequence tagging task using Conditional Random Fields. We extract a combination of lexical, section-based and temporal features from medical events in each clinical narrative. The sequence tagging system outperforms a system that does not utilize any sequence information modeled using a Maximum Entropy classifier. We present results with both handtagged as well as automatically extracted features. We observe over 8% improvement in overall tagging accuracy with the inclusion of sequence information.",2012,True,False,False,True,False,False,False,"A, D",250,3,253
W12-1804,Dialogue Systems Using Online Learning: Beyond Empirical Methods,"We discuss a change of perspective for training dialogue systems, which requires a shift from traditional empirical methods to online learning methods. We motivate the application of online learning, which provides the benefit of improving the system's behaviour continuously often after each turn or dialogue rather than after hundreds of dialogues. We describe the requirements and advances for dialogue systems with online learning, and speculate on the future of these kinds of systems.",2012,False,False,False,True,False,True,False,"D, F",198,3,201
W12-3710,Unifying Local and Global Agreement and Disagreement Classification in Online Debates,"Online debate forums provide a powerful communication platform for individual users to share information, exchange ideas and express opinions on a variety of topics. Understanding people's opinions in such forums is an important task as its results can be used in many ways. It is, however, a challenging task because of the informal language use and the dynamic nature of online conversations. In this paper, we propose a new method for identifying participants' agreement or disagreement on an issue by exploiting information contained in each of the posts. Our proposed method first regards each post in its local context, then aggregates posts to estimate a participant's overall position. We have explored the use of sentiment, emotional and durational features to improve the accuracy of automatic agreement and disagreement classification. Our experimental results have shown that aggregating local positions over posts yields better performance than nonaggregation baselines when identifying users' global positions on an issue.",2012,False,False,False,True,False,False,True,"D, G",292,3,295
P12-1085,Structuring {E}-Commerce Inventory,"Large e-commerce enterprises feature millions of items entered daily by a large variety of sellers. While some sellers provide rich, structured descriptions of their items, a vast majority of them provide unstructured natural language descriptions. In the paper we present a 2 steps method for structuring items into descriptive properties. The first step consists in unsupervised property discovery and extraction. The second step involves supervised property synonym discovery using a maximum entropy based clustering algorithm. We evaluate our method on a year worth of ecommerce data and show that it achieves excellent precision with good recall.",2012,False,False,False,True,False,False,True,"D, G",228,3,231
F12-1028,Distorsions de l{'}espace vocalique : quelles mesures? Application {\`a} la dysarthrie (Distortions of vocalic space: which measurements? An application to dysarthria.) [in {F}rench],"Cet article présente différentes métriques dérivées de mesures F1/F2 pour la description et la quantification de variations observées sur un espace vocalique. 8 métriques issues de la littérature ou adaptées à nos données sont évaluées sur des productions des voyelles /a, e, i, u, o/ extraites d'un texte lu par 78 patients dysarthriques (parkinsoniens, cérébelleux et atteints de SLA) et par 26 locuteurs témoins sains. La capacité des métriques à décrire les altérations de l'espace vocalique associées aux différentes dysarthries par rapport au groupe témoin est comparée. L'interrelation entre les métriques et leur rapport avec l'intelligibilité perçue des patients est également discutée. Les résultats montrent la nécessité de prendre en compte plusieurs métriques complémentaires afin de rendre compte de la multidimensionnalité des altérations possibles dans un espace vocalique.",2012,False,False,False,False,True,False,True,"E, G",313,3,316
P12-3013,{BIUTEE}: A Modular Open-Source System for Recognizing Textual Entailment,"This paper introduces BIUTEE 1 , an opensource system for recognizing textual entailment. Its main advantages are its ability to utilize various types of knowledge resources, and its extensibility by which new knowledge resources and inference components can be easily integrated. These abilities make BIUTEE an appealing RTE system for two research communities: (1) researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch. Notable assistance for these researchers is provided by a visual tracing tool, by which researchers can refine and ""debug"" their knowledge resources and inference components.",2012,False,True,False,True,False,False,False,"B, D",266,3,269
S12-1091,{SRIUBC}: Simple Similarity Features for Semantic Textual Similarity,"We describe the systems submitted by SRI International and the University of the Basque Country for the Semantic Textual Similarity (STS) SemEval-2012 task. Our systems focused on using a simple set of features, featuring a mix of semantic similarity resources, lexical match heuristics, and part of speech (POS) information. We also incorporate precision focused scores over lexical and POS information derived from the BLEU measure, and lexical and POS features computed over split-bigrams from the ROUGE-S measure. These were used to train support vector regressors over the pairs in the training data. From the three systems we submitted, two performed well in the overall ranking, with splitbigrams improving performance over pairs drawn from the MSR Research Video Description Corpus. Our third system maintained three separate regressors, each trained specifically for the STS dataset they were drawn from. It used a multinomial classifier to predict which dataset regressor would be most appropriate to score a given pair, and used it to score that pair. This system underperformed, primarily due to errors in the dataset predictor.",2012,False,False,False,True,False,False,True,"D, G",336,3,339
F12-2001,Simplification de phrases pour l{'}extraction de relations (Sentence Simplification for Relation Extraction) [in {F}rench],"L'extraction de relations par apprentissage nécessite un corpus annoté de très grande taille pour couvrir toutes les variations d'expressions des relations. Pour contrer ce problème, nous proposons une méthode de simplification de phrases qui permet de réduire la variabilité syntaxique des relations. Elle nécessite l'annotation d'un petit corpus qui sera par la suite augmenté automatiquement. La première étape est l'annotation des simplifications grâce à un classifieur à base de CRF, puis l'extraction des relations, et ensuite une complétion automatique du corpus d'entraînement des simplifications grâce aux résultats de l'extraction des relations. Les premiers résultats que nous avons obtenus pour la tâche d'extraction de relations d'i2b2 2010 sont très encourageants.",2012,False,False,False,True,False,False,True,"D, G",273,3,276
E12-1021,Incorporating Lexical Priors into Topic Models,"Topic models have great potential for helping users understand document corpora. This potential is stymied by their purely unsupervised nature, which often leads to topics that are neither entirely meaningful nor effective in extrinsic tasks (Chang et al., 2009) . We propose a simple and effective way to guide topic models to learn topics of specific interest to a user. We achieve this by providing sets of seed words that a user believes are representative of the underlying topics in a corpus. Our model uses these seeds to improve both topicword distributions (by biasing topics to produce appropriate seed words) and to improve document-topic distributions (by biasing documents to select topics related to the seed words they contain). Extrinsic evaluation on a document clustering task reveals a significant improvement when using seed information, even over other models that use seed information naïvely.",2012,False,True,False,True,False,False,False,"D, B",288,3,291
C12-3044,{O}pen{W}ord{N}et-{PT}: An Open {B}razilian {W}ordnet for Reasoning,"Brazilian Portuguese needs a Wordnet that is open access, downloadable and changeable, so that it can be improved by the community interested in using it for knowledge representation and automated deduction. This kind of resource is also very valuable to linguists and computer scientists interested in extracting and representing knowledge obtained from texts. We discuss briefly the reasons for a Brazilian Portuguese Wordnet and the process we used to get a preliminary version of such a resource. Then we discuss possible steps to improving our preliminary version. 1",2012,True,False,False,False,True,False,False,"A, E",219,3,222
W12-3109,Black Box Features for the {WMT} 2012 Quality Estimation Shared Task,In this paper we introduce a number of new features for quality estimation in machine translation that were developed for the WMT 2012 quality estimation shared task. We find that very simple features such as indicators of certain characters are able to outperform complex features that aim to model the connection between two languages.,2012,True,False,False,False,True,False,False,"A, E",177,3,180
C12-1008,Comparative Quality Estimation: Automatic Sentence-Level Ranking of Multiple Machine Translation Outputs,"A machine learning mechanism is learned from human annotations in order to perform preference ranking. The mechanism operates on a sentence level and ranks the alternative machine translations of each source sentence. Rankings are decomposed into pairwise comparisons so that binary classifiers can be trained using black-box features of automatic linguistic analysis. In order to re-compose the pairwise decisions of the classifier, this work introduces weighing the decisions with their classification probabilities, which eliminates ranking ties and increases the coefficient of the correlation with the human rankings up to 80%. The authors also demonstrate several configurations of successful automatic ranking models; the best configuration achieves acceptable correlation with human judgments (tau=0.30), which is higher than that of state-of-the-art reference-aware automatic MT evaluation metrics such as METEOR and Levenshtein distance.",2012,False,False,True,True,False,False,False,"C, D",276,3,279
